my16dchbsdbebciuhfhqhThhhhhhhhhh ----- 32
 in the get_the_subtitles func
time taken in userKey decoding is -> 319  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746369721,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: -13274.900552 sec


 ==the user should be upgraded as it's time ran out ===

 
 message in the--> upgrade your key as it's time ran out


 testing env and the url is -> file:./localTest.db 


the db url is -> file:./localTest.db  and the url is -> file:./localTest.db
time taken in userKey decoding is -> 74  Microseconds
the user struct is -> {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746369721,"id_primary_key":78} 
there are no rows in the DB(err)
the user's tier in the key provided by them is -> free tier
the resultFromTheDB is false with no errr for the  monishsharma010@gmail.com  meaning there is no message
here we would give the user key and adjust it for the future time
the old user key is -> 1746369721
the time selected form env is -> 20h
>>>>>>the time selected for the key is after  72000000 ms  or  +2.000000e+001  hours or  +1.200000e+003  min
the old new key is -> 1746454995
adding time to new key and it is after :=> -13260000000000  min
creating the GCM mode
about to write to the result channel in the encryptedUserKey -> l2lFdN547iZwVfsVIXvPQXIjBKUccWF3ZBQUE/KppYVbY3gnJiHrOnwIJlveHdpksa1DvUtxP55D4J4C0/yX2ZNDAS8XxGTDfGMdqi49owB8RihKr1O8MLEqHDY/pCT1pJ62Y/8xpXO2JAEBvYno5DqJ6MDnn6RHmKEW0FsLtUySD4ajKo+ofEbZabD2E0Ywt0A9xkj2BRSWVz3agCWjFE38IG9FuGNvcccUP3e1/Z279NRBO82yGcH2exzEeLsOlQ2lloCNUv7N3YB3WPimQO6QDNIbcc6LNUasPU+wlGUJrmRCR3Y+vHQRzaCg
 in the get_the_subtitles func
time taken in userKey decoding is -> 67  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746369721,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: -13274.913576 sec


 ==the user should be upgraded as it's time ran out ===

 
 message in the--> upgrade your key as it's time ran out
in the auto generated track
in the auto generated track
formatting the transctipt.subtitles.text to be utf-8
[start 1.62] approach type pollution is a problem [Duration: 3.679]
[start 3.36] that can affect JavaScript applications [Duration: 4.8]
[start 5.299] but before we can talk about prototype [Duration: 4.601]
[start 8.16] pollution I think we need to spend a [Duration: 2.78]
[start 9.9] little bit of time talking about [Duration: 4.02]
[start 10.94] prototypes and what they are and then we [Duration: 5.32]
[start 13.92] can talk about prototype pollution so [Duration: 5.699]
[start 16.26] JavaScript has objects so we might have [Duration: 6.66]
[start 19.619] a car object for example [Duration: 6.66]
[start 22.92] and it might have a color property [Duration: 6.84]
[start 26.279] so we have a car that is red fairly [Duration: 4.4]
formatting the transctipt.subtitles.text to be utf-8
[start 29.76] simple [Duration: 3.72]
[start 30.679] and in some languages you get what's [Duration: 5.441]
[start 33.48] called classical inheritance where one [Duration: 6.18]
[start 36.12] class can inherit from another and gets [Duration: 5.52]
[start 39.66] to access its properties and that sort [Duration: 3.48]
[start 41.64] of thing JavaScript doesn't have [Duration: 3.3]
[start 43.14] classical inheritance but it does have [Duration: 4.04]
[start 44.94] something called prototypal inheritance [Duration: 5.52]
[start 47.18] and to show you what that is we might [Duration: 6.64]
[start 50.46] say our car wants to inherit from some [Duration: 6.3]
[start 53.82] kind of vehicle object so let's make a [Duration: 4.2]
[start 56.76] vehicle [Duration: 4.38]
[start 58.02] that's another object and we might say [Duration: 5.699]
[start 61.14] that Vehicles by default have [Duration: 4.5]
[start 63.719] four wheels [Duration: 4.521]
[start 65.64] and what we can do is say the car's [Duration: 4.92]
[start 68.24] prototype with this double underscore [Duration: 4.78]
[start 70.56] proton double underscore thing it's [Duration: 6]
[start 73.02] actually equal to vehicle [Duration: 6.18]
[start 76.56] uh and what that does for us is it means [Duration: 5.28]
[start 79.2] that not only is car dot color available [Duration: 6.12]
[start 81.84] but cardock Wheels is available too [Duration: 6.54]
[start 85.32] so when we try to access car.wheels [Duration: 4.979]
[start 88.38] JavaScript knows that the car object [Duration: 4.8]
[start 90.299] doesn't have a Wheels property so it [Duration: 6.421]
[start 93.18] uses the Prototype instead and that can [Duration: 5.1]
[start 96.72] happen more than once as well you can [Duration: 3.719]
[start 98.28] chase the Prototype chain all the way up [Duration: 3.839]
[start 100.439] to the top [Duration: 4.021]
[start 102.119] and we can access it directly as well [Duration: 4.401]
[start 1.62] approach type pollution is a problem [Duration: 3.679]
[start 3.36] that can affect JavaScript applications [Duration: 4.8]
[start 5.299] but before we can talk about prototype [Duration: 4.601]
[start 8.16] pollution I think we need to spend a [Duration: 2.78]
[start 9.9] little bit of time talking about [Duration: 4.02]
[start 10.94] prototypes and what they are and then we [Duration: 5.32]
[start 13.92] can talk about prototype pollution so [Duration: 5.699]
[start 16.26] JavaScript has objects so we might have [Duration: 6.66]
[start 19.619] a car object for example [Duration: 6.66]
[start 22.92] and it might have a color property [Duration: 6.84]
[start 26.279] so we have a car that is red fairly [Duration: 4.4]
[start 29.76] simple [Duration: 3.72]
[start 30.679] and in some languages you get what's [Duration: 5.441]
[start 33.48] called classical inheritance where one [Duration: 6.18]
[start 36.12] class can inherit from another and gets [Duration: 5.52]
[start 39.66] to access its properties and that sort [Duration: 3.48]
[start 41.64] of thing JavaScript doesn't have [Duration: 3.3]
[start 43.14] classical inheritance but it does have [Duration: 4.04]
[start 44.94] something called prototypal inheritance [Duration: 5.52]
[start 47.18] and to show you what that is we might [Duration: 6.64]
[start 50.46] say our car wants to inherit from some [Duration: 6.3]
[start 53.82] kind of vehicle object so let's make a [Duration: 4.2]
[start 56.76] vehicle [Duration: 4.38]
[start 58.02] that's another object and we might say [Duration: 5.699]
[start 61.14] that Vehicles by default have [Duration: 4.5]
[start 63.719] four wheels [Duration: 4.521]
[start 65.64] and what we can do is say the car's [Duration: 4.92]
[start 68.24] prototype with this double underscore [Duration: 4.78]
[start 70.56] proton double underscore thing it's [Duration: 6]
[start 73.02] actually equal to vehicle [Duration: 6.18]
[start 76.56] uh and what that does for us is it means [Duration: 5.28]
[start 79.2] that not only is car dot color available [Duration: 6.12]
[start 81.84] but cardock Wheels is available too [Duration: 6.54]
[start 85.32] so when we try to access car.wheels [Duration: 4.979]
[start 88.38] JavaScript knows that the car object [Duration: 4.8]
[start 90.299] doesn't have a Wheels property so it [Duration: 6.421]
[start 93.18] uses the Prototype instead and that can [Duration: 5.1]
[start 96.72] happen more than once as well you can [Duration: 3.719]
[start 98.28] chase the Prototype chain all the way up [Duration: 3.839]
[start 100.439] to the top [Duration: 4.021]
[start 102.119] and we can access it directly as well [Duration: 4.401]
[start 104.46] and say [Duration: 4.38]
[start 106.52] guard.proto Dot [Duration: 4.54]
[start 108.84] fuel for example [Duration: 4.38]
[start 111.06] is equal to petrol [Duration: 4.26]
[start 113.22] and that means that car dot petrol [Duration: 4.439]
[start 115.32] car.fuel should I say [Duration: 4.28]
[start 117.659] fuel is available [Duration: 5.061]
[start 119.6] but also [Duration: 5.619]
[start 122.72] vehicle.fuel is available as well we [Duration: 6.7]
[start 125.219] affected that prototype object directly [Duration: 7.561]
[start 129.42] one of the interesting things to note [Duration: 5.7]
[start 132.78] is that all [Duration: 5.52]
[start 135.12] objects in JavaScript by default share a [Duration: 5.9]
[start 138.3] prototype so if I was to set [Duration: 5.82]
[start 141.02] vehicle.proto dot or what's a good [Duration: 8.219]
[start 144.12] example size equal to large [Duration: 8.16]
[start 149.239] uh well let's go with [Duration: 5.681]
[start 104.46] and say [Duration: 4.38]
[start 106.52] guard.proto Dot [Duration: 4.54]
[start 108.84] fuel for example [Duration: 4.38]
[start 111.06] is equal to petrol [Duration: 4.26]
[start 113.22] and that means that car dot petrol [Duration: 4.439]
[start 115.32] car.fuel should I say [Duration: 4.28]
[start 117.659] fuel is available [Duration: 5.061]
[start 119.6] but also [Duration: 5.619]
[start 122.72] vehicle.fuel is available as well we [Duration: 6.7]
[start 125.219] affected that prototype object directly [Duration: 7.561]
[start 129.42] one of the interesting things to note [Duration: 5.7]
[start 132.78] is that all [Duration: 5.52]
[start 135.12] objects in JavaScript by default share a [Duration: 5.9]
[start 138.3] prototype so if I was to set [Duration: 5.82]
[start 141.02] vehicle.proto dot or what's a good [Duration: 8.219]
[start 144.12] example size equal to large [Duration: 8.16]
[start 149.239] uh well let's go with [Duration: 5.681]
[start 152.28] let's go with size it's large uh then [Duration: 4.62]
[start 154.92] we'll find that actually the window now [Duration: 4.74]
[start 156.9] has a size property as well called large [Duration: 5.04]
[start 159.66] because the window object shares a [Duration: 6.6]
[start 161.94] prototype with the vehicle object so if [Duration: 8.34]
[start 166.26] we can write to this uh Proto property [Duration: 7.5]
[start 170.28] somehow then we can affect [Duration: 7.08]
[start 173.76] effectively the global scope so window [Duration: 6.24]
[start 177.36] is is the global scope in JavaScript so [Duration: 4.8]
[start 180] now we have this size variable available [Duration: 3.9]
[start 182.16] so [Duration: 3.98]
[start 183.9] all well and good [Duration: 5.339]
[start 186.14] so let's take an example of where this [Duration: 5.08]
[start 189.239] can go wrong and where we get what we [Duration: 4.14]
[start 191.22] call prototype pollution [Duration: 5.04]
[start 193.379] so this is just a little demo web page [Duration: 4.741]
[start 196.26] that I put together [Duration: 4.5]
[start 198.12] it's a modern single page application [Duration: 5.22]
[start 200.76] with an about page [Duration: 4.74]
[start 203.34] and a contact page [Duration: 3.84]
[start 205.5] and we can see we've got one query [Duration: 5.58]
[start 207.18] string parameter here page equals home [Duration: 6.779]
[start 211.08] so let's have a look at the HTML source [Duration: 5.159]
[start 213.959] for this webpage and see what it looks [Duration: 3.78]
[start 216.239] like [Duration: 4.201]
[start 217.739] so here we go [Duration: 4.381]
[start 220.44] let's move this out of the way a little [Duration: 3.48]
[start 222.12] bit [Duration: 4.5]
[start 223.92] at least we'll try to not working so [Duration: 3.899]
[start 226.62] well [Duration: 3.839]
[start 227.819] let's move this one instead here we go [Duration: 5.401]
[start 230.459] so a fairly standard looking HTML page [Duration: 6.181]
[start 233.22] we got two different bits of JavaScript [Duration: 6.18]
[start 236.64] included here so we have jQuery and we [Duration: 4.679]
[start 239.4] also have this jQuery plug-in query [Duration: 3.24]
[start 241.319] object [Duration: 4.441]
[start 242.64] Library being included and I've included [Duration: 5.58]
[start 245.76] that for a fairly specific reason [Duration: 5.399]
[start 248.22] but we'll get to that in a second so we [Duration: 5.04]
[start 251.159] have our H1 tag which we can see in the [Duration: 4.741]
[start 253.26] page here we have a div with an idea of [Duration: 4.02]
[start 255.9] content and then we've got some [Duration: 3.48]
[start 257.28] JavaScript that will have a nice [Duration: 3.84]
[start 259.38] detailed look at [Duration: 4.68]
[start 261.12] so we have an object here called pages [Duration: 5.34]
[start 264.06] because you know a single application [Duration: 4.38]
[start 266.46] page applications of the future for sure [Duration: 3.6]
[start 268.44] so [Duration: 6.78]
[start 270.06] in here is a set of properties and each [Duration: 7.62]
[start 275.22] one has some HTML in it so one for the [Duration: 4.199]
[start 277.68] home page one for the about page one for [Duration: 3.72]
[start 279.419] the contact page that we've just seen [Duration: 5.041]
[start 281.4] and then what this JavaScript does is it [Duration: 6.239]
[start 284.46] uses this jQuery query [Duration: 5.34]
[start 287.639] okay query query is a bit of a mouthful [Duration: 5.101]
[start 289.8] isn't it uh plugin to get the page query [Duration: 5.88]
[start 292.74] string parameter that we can see here [Duration: 6.36]
[start 295.68] uh and then checks if it's empty if it [Duration: 6.299]
[start 299.1] is then it redirects us to page equals [Duration: 4.98]
[start 301.979] hum so we can see that happen [Duration: 4.261]
[start 304.08] like that [Duration: 4.559]
[start 306.24] and then if it's a known page we set the [Duration: 5.76]
[start 308.639] page content so we use that as a key for [Duration: 5.401]
[start 312] the pages object and if it's not [Duration: 5.28]
[start 314.04] undefined we use jQuery to fetch that [Duration: 6.18]
[start 317.28] content div and set its HTML to be [Duration: 5.34]
[start 320.22] whatever the HTML is [Duration: 5.4]
[start 322.62] in this object so [Duration: 5.22]
[start 325.62] when we click about [Duration: 4.079]
[start 327.84] we can see we get redirected to page [Duration: 4.82]
[start 329.699] equals about [Duration: 2.961]
[start 152.28] let's go with size it's large uh then [Duration: 4.62]
[start 154.92] we'll find that actually the window now [Duration: 4.74]
[start 156.9] has a size property as well called large [Duration: 5.04]
[start 159.66] because the window object shares a [Duration: 6.6]
[start 161.94] prototype with the vehicle object so if [Duration: 8.34]
[start 166.26] we can write to this uh Proto property [Duration: 7.5]
[start 170.28] somehow then we can affect [Duration: 7.08]
[start 173.76] effectively the global scope so window [Duration: 6.24]
[start 177.36] is is the global scope in JavaScript so [Duration: 4.8]
[start 180] now we have this size variable available [Duration: 3.9]
[start 182.16] so [Duration: 3.98]
[start 183.9] all well and good [Duration: 5.339]
[start 186.14] so let's take an example of where this [Duration: 5.08]
[start 189.239] can go wrong and where we get what we [Duration: 4.14]
[start 191.22] call prototype pollution [Duration: 5.04]
[start 193.379] so this is just a little demo web page [Duration: 4.741]
[start 196.26] that I put together [Duration: 4.5]
[start 198.12] it's a modern single page application [Duration: 5.22]
[start 200.76] with an about page [Duration: 4.74]
[start 203.34] and a contact page [Duration: 3.84]
[start 205.5] and we can see we've got one query [Duration: 5.58]
[start 207.18] string parameter here page equals home [Duration: 6.779]
[start 211.08] so let's have a look at the HTML source [Duration: 5.159]
[start 213.959] for this webpage and see what it looks [Duration: 3.78]
[start 216.239] like [Duration: 4.201]
[start 217.739] so here we go [Duration: 4.381]
[start 220.44] let's move this out of the way a little [Duration: 3.48]
[start 222.12] bit [Duration: 4.5]
[start 223.92] at least we'll try to not working so [Duration: 3.899]
[start 226.62] well [Duration: 3.839]
[start 227.819] let's move this one instead here we go [Duration: 5.401]
[start 230.459] so a fairly standard looking HTML page [Duration: 6.181]
[start 233.22] we got two different bits of JavaScript [Duration: 6.18]
[start 236.64] included here so we have jQuery and we [Duration: 4.679]
[start 239.4] also have this jQuery plug-in query [Duration: 3.24]
[start 241.319] object [Duration: 4.441]
[start 242.64] Library being included and I've included [Duration: 5.58]
[start 245.76] that for a fairly specific reason [Duration: 5.399]
[start 248.22] but we'll get to that in a second so we [Duration: 5.04]
[start 251.159] have our H1 tag which we can see in the [Duration: 4.741]
[start 253.26] page here we have a div with an idea of [Duration: 4.02]
[start 255.9] content and then we've got some [Duration: 3.48]
[start 257.28] JavaScript that will have a nice [Duration: 3.84]
[start 259.38] detailed look at [Duration: 4.68]
[start 261.12] so we have an object here called pages [Duration: 5.34]
[start 264.06] because you know a single application [Duration: 4.38]
[start 266.46] page applications of the future for sure [Duration: 3.6]
[start 268.44] so [Duration: 6.78]
[start 270.06] in here is a set of properties and each [Duration: 7.62]
[start 275.22] one has some HTML in it so one for the [Duration: 4.199]
[start 277.68] home page one for the about page one for [Duration: 3.72]
[start 279.419] the contact page that we've just seen [Duration: 5.041]
[start 281.4] and then what this JavaScript does is it [Duration: 6.239]
[start 284.46] uses this jQuery query [Duration: 5.34]
[start 287.639] okay query query is a bit of a mouthful [Duration: 5.101]
[start 289.8] isn't it uh plugin to get the page query [Duration: 5.88]
[start 292.74] string parameter that we can see here [Duration: 6.36]
[start 295.68] uh and then checks if it's empty if it [Duration: 6.299]
[start 299.1] is then it redirects us to page equals [Duration: 4.98]
[start 301.979] hum so we can see that happen [Duration: 4.261]
[start 304.08] like that [Duration: 4.559]
[start 306.24] and then if it's a known page we set the [Duration: 5.76]
[start 308.639] page content so we use that as a key for [Duration: 5.401]
[start 312] the pages object and if it's not [Duration: 5.28]
[start 314.04] undefined we use jQuery to fetch that [Duration: 6.18]
[start 317.28] content div and set its HTML to be [Duration: 5.34]
[start 320.22] whatever the HTML is [Duration: 5.4]
[start 322.62] in this object so [Duration: 5.22]
[start 325.62] when we click about [Duration: 4.079]
[start 327.84] we can see we get redirected to page [Duration: 4.82]
[start 329.699] equals about [Duration: 2.961]
[start 333.479] and this piece of HTML here under the [Duration: 6.481]
[start 336.06] about key is being put into this Dev so [Duration: 6.479]
[start 339.96] if we use the elements View and we can [Duration: 5.7]
[start 342.539] see that the HTML is there [Duration: 5.22]
[start 345.66] so that's all fine [Duration: 4.08]
[start 347.759] um and if you were you know evaluating [Duration: 4.321]
[start 349.74] this page to look for say Dom exercise [Duration: 4.62]
[start 352.08] for example [Duration: 5.88]
[start 354.36] um you might think that it's not [Duration: 5.64]
[start 357.96] vulnerable because you know we have no [Duration: 4.86]
[start 360] control over the content here we've got [Duration: 7.68]
[start 362.82] one parameter that um is used as just a [Duration: 6.36]
[start 367.68] page parameter and all it's used is is [Duration: 4.459]
[start 369.18] the key of this array [Duration: 6.54]
[start 372.139] uh so you know how come we got control [Duration: 5.321]
[start 375.72] over some content in the page and maybe [Duration: 4.62]
[start 377.46] get some domic success working [Duration: 5.04]
[start 380.34] and the answer here is as you might have [Duration: 5.579]
[start 382.5] guessed prototype pollution so what we [Duration: 7.5]
[start 385.919] want to do is affect the Prototype of [Duration: 6.961]
[start 390] this Pages object [Duration: 6.419]
[start 392.88] um and set our own value somehow [Duration: 6.12]
[start 396.419] and it turns out [Duration: 5.701]
[start 399] this particular jQuery plug-in query [Duration: 4.94]
[start 402.12] object [Duration: 3.419]
[start 403.94] plugin [Duration: 5.199]
[start 405.539] is vulnerable to prototype pollution and [Duration: 5.94]
[start 409.139] I know that thanks to this incredibly [Duration: 4.861]
[start 411.479] useful repo from black fan AKA Sergey [Duration: 5.28]
[start 414] bobrov Sergey Sergey I don't know which [Duration: 7.38]
[start 416.759] I apologize Sergio Sergey which lists a [Duration: 6.121]
[start 421.38] whole bunch of different JavaScript [Duration: 2.759]
[start 422.88] libraries which are vulnerable to [Duration: 4.08]
[start 424.139] prototype pollution and some ways that [Duration: 5.461]
[start 426.96] you can try and use that so [Duration: 6.6]
[start 429.6] we can see here suggested uh Pro Dublin [Duration: 5.879]
[start 433.56] score Proto double underscore test [Duration: 5.22]
[start 435.479] equals test so we can do something like [Duration: 4.921]
[start 438.78] this [Duration: 4.88]
[start 440.4] on the query string here [Duration: 3.26]
[start 444.72] and see if it worked and the way we can [Duration: 4.74]
[start 447.539] do that is just in the console we can [Duration: 4.38]
[start 449.46] look at the test variable and we can see [Duration: 3.959]
[start 451.919] it's equal to test [Duration: 4.801]
[start 453.419] and if we change it to something else [Duration: 6.06]
[start 456.72] mash the keyboard a little bit [Duration: 4.259]
[start 459.479] and we can say it's equal to that [Duration: 3.78]
[start 460.979] instead [Duration: 5.041]
[start 463.259] but also really importantly [Duration: 4.741]
[start 466.02] that page is variable if you remember [Duration: 5.579]
[start 468] the one with the all of our HTML in it [Duration: 7.62]
[start 471.599] now has a test property set to this [Duration: 7.201]
[start 475.62] value and that's because it shares a [Duration: 7.44]
[start 478.8] prototype with the window object [Duration: 6.119]
[start 333.479] and this piece of HTML here under the [Duration: 6.481]
[start 336.06] about key is being put into this Dev so [Duration: 6.479]
[start 339.96] if we use the elements View and we can [Duration: 5.7]
[start 483.06] so [Duration: 5.639]
[start 484.919] what we can do is set the page key to be [Duration: 5.9]
[start 488.699] some random value [Duration: 5.041]
[start 490.819] let's say Foo [Duration: 4.841]
[start 493.74] and then we can use prototype pollution [Duration: 7.5]
[start 495.66] to say that Foo is equal to some content [Duration: 7.56]
[start 342.539] see that the HTML is there [Duration: 5.22]
[start 345.66] so that's all fine [Duration: 4.08]
[start 347.759] um and if you were you know evaluating [Duration: 4.321]
[start 501.24] and now our content appears in the page [Duration: 3.42]
[start 503.22] so [Duration: 4.4]
[start 504.66] we're only really One Step Off [Duration: 6.36]
[start 507.62] having some kind of [Duration: 4.839]
[start 511.02] uh [Duration: 4.74]
[start 512.459] exploit here some Dom exercise so [Duration: 6.721]
[start 515.76] let's use image source empty source and [Duration: 7.38]
[start 519.18] use the on error event handler to fire [Duration: 7.5]
[start 523.14] off an alert of document.domain [Duration: 5.34]
[start 526.68] we're in a query string here so we need [Duration: 4.8]
[start 528.48] to actually uh escape this equal sign [Duration: 5.58]
[start 531.48] percent 3D [Duration: 4.919]
[start 534.06] with a better look we get an alert fired [Duration: 5.16]
[start 536.399] so double exercise through prototype [Duration: 4.261]
[start 539.22] pollution [Duration: 5.4]
[start 540.66] very useful very handy when it shows up [Duration: 6.54]
[start 544.62] and like say have a look through this uh [Duration: 4.62]
[start 547.2] great repository for all of the [Duration: 4.139]
[start 549.24] different libraries that can affect this [Duration: 3.96]
[start 551.339] whole host of information here [Duration: 4.5]
[start 553.2] incredibly useful [Duration: 4.259]
[start 555.839] so [Duration: 3.301]
[start 557.459] I love learning about new [Duration: 3.121]
[start 559.14] vulnerabilities and new ways to do [Duration: 3.48]
[start 560.58] things and and that was the same for me [Duration: 4.02]
[start 562.62] when I learned about prototype pollution [Duration: 5.76]
[start 564.6] but I also love automation or more [Duration: 5.76]
[start 568.38] specifically as some of you'll know I [Duration: 3.72]
[start 570.36] like writing tools [Duration: 5.28]
[start 572.1] and if I discover a new class of [Duration: 5.7]
[start 575.64] vulnerability I want to go off and try [Duration: 4.98]
[start 577.8] and find it everywhere that I can and a [Duration: 4.74]
[start 580.62] lot of people use things like nuclei for [Duration: 4.62]
[start 582.54] that which is uh you know it's a great [Duration: 4.739]
[start 585.24] project very useful [Duration: 3.719]
[start 587.279] um or maybe they use some of the tools [Duration: 4.56]
[start 349.74] this page to look for say Dom exercise [Duration: 4.62]
[start 352.08] for example [Duration: 5.88]
[start 354.36] um you might think that it's not [Duration: 5.64]
[start 357.96] vulnerable because you know we have no [Duration: 4.86]
[start 360] control over the content here we've got [Duration: 7.68]
[start 362.82] one parameter that um is used as just a [Duration: 6.36]
[start 367.68] page parameter and all it's used is is [Duration: 4.459]
[start 369.18] the key of this array [Duration: 6.54]
[start 372.139] uh so you know how come we got control [Duration: 5.321]
[start 375.72] over some content in the page and maybe [Duration: 4.62]
[start 377.46] get some domic success working [Duration: 5.04]
[start 380.34] and the answer here is as you might have [Duration: 5.579]
[start 382.5] guessed prototype pollution so what we [Duration: 7.5]
[start 385.919] want to do is affect the Prototype of [Duration: 6.961]
[start 390] this Pages object [Duration: 6.419]
[start 392.88] um and set our own value somehow [Duration: 6.12]
[start 396.419] and it turns out [Duration: 5.701]
[start 399] this particular jQuery plug-in query [Duration: 4.94]
[start 402.12] object [Duration: 3.419]
[start 403.94] plugin [Duration: 5.199]
[start 405.539] is vulnerable to prototype pollution and [Duration: 5.94]
[start 409.139] I know that thanks to this incredibly [Duration: 4.861]
[start 411.479] useful repo from black fan AKA Sergey [Duration: 5.28]
[start 414] bobrov Sergey Sergey I don't know which [Duration: 7.38]
[start 416.759] I apologize Sergio Sergey which lists a [Duration: 6.121]
[start 421.38] whole bunch of different JavaScript [Duration: 2.759]
[start 422.88] libraries which are vulnerable to [Duration: 4.08]
[start 424.139] prototype pollution and some ways that [Duration: 5.461]
[start 426.96] you can try and use that so [Duration: 6.6]
[start 429.6] we can see here suggested uh Pro Dublin [Duration: 5.879]
[start 433.56] score Proto double underscore test [Duration: 5.22]
[start 435.479] equals test so we can do something like [Duration: 4.921]
[start 438.78] this [Duration: 4.88]
[start 440.4] on the query string here [Duration: 3.26]
[start 444.72] and see if it worked and the way we can [Duration: 4.74]
[start 447.539] do that is just in the console we can [Duration: 4.38]
[start 449.46] look at the test variable and we can see [Duration: 3.959]
[start 451.919] it's equal to test [Duration: 4.801]
[start 453.419] and if we change it to something else [Duration: 6.06]
[start 456.72] mash the keyboard a little bit [Duration: 4.259]
[start 588.959] that I wrote like Meg for example go and [Duration: 4.741]
[start 459.479] and we can say it's equal to that [Duration: 3.78]
[start 460.979] instead [Duration: 5.041]
[start 463.259] but also really importantly [Duration: 4.741]
[start 466.02] that page is variable if you remember [Duration: 5.579]
[start 468] the one with the all of our HTML in it [Duration: 7.62]
[start 471.599] now has a test property set to this [Duration: 7.201]
[start 475.62] value and that's because it shares a [Duration: 7.44]
[start 478.8] prototype with the window object [Duration: 6.119]
[start 483.06] so [Duration: 5.639]
[start 484.919] what we can do is set the page key to be [Duration: 5.9]
[start 488.699] some random value [Duration: 5.041]
[start 490.819] let's say Foo [Duration: 4.841]
[start 493.74] and then we can use prototype pollution [Duration: 7.5]
[start 495.66] to say that Foo is equal to some content [Duration: 7.56]
[start 501.24] and now our content appears in the page [Duration: 3.42]
[start 503.22] so [Duration: 4.4]
[start 504.66] we're only really One Step Off [Duration: 6.36]
[start 507.62] having some kind of [Duration: 4.839]
[start 511.02] uh [Duration: 4.74]
[start 512.459] exploit here some Dom exercise so [Duration: 6.721]
[start 515.76] let's use image source empty source and [Duration: 7.38]
[start 519.18] use the on error event handler to fire [Duration: 7.5]
[start 591.839] search for reflected cross-site [Duration: 4.801]
[start 593.7] scripting or maybe SQL injection or [Duration: 4.74]
[start 596.64] anything like that [Duration: 3.78]
[start 598.44] but we have a bit of a problem doing [Duration: 4.14]
[start 600.42] that for something like prototype [Duration: 3.84]
[start 602.58] pollution because this is a purely [Duration: 4.56]
[start 604.26] client-side vulnerability [Duration: 6.42]
[start 607.14] you know if I took a test string like [Duration: 7.139]
[start 610.68] we had originally [Duration: 6.24]
[start 614.279] just test and test [Duration: 5.761]
[start 616.92] there's nothing about the page Source [Duration: 5.76]
[start 620.04] here that gives away that this page is [Duration: 4.739]
[start 622.68] vulnerable to prototype pollution short [Duration: 4.08]
[start 624.779] of maybe you know fingerprinting known [Duration: 4.62]
[start 626.76] vulnerable JavaScript libraries [Duration: 5.4]
[start 629.399] but even then you know that can be [Duration: 6]
[start 632.16] error-prone because we can't necessarily [Duration: 5.76]
[start 635.399] rely on the file name where of the [Duration: 4.261]
[start 637.92] JavaScript library when things have all [Duration: 5.039]
[start 523.14] off an alert of document.domain [Duration: 5.34]
[start 526.68] we're in a query string here so we need [Duration: 4.8]
[start 528.48] to actually uh escape this equal sign [Duration: 5.58]
[start 531.48] percent 3D [Duration: 4.919]
[start 534.06] with a better look we get an alert fired [Duration: 5.16]
[start 536.399] so double exercise through prototype [Duration: 4.261]
[start 539.22] pollution [Duration: 5.4]
[start 540.66] very useful very handy when it shows up [Duration: 6.54]
[start 544.62] and like say have a look through this uh [Duration: 4.62]
[start 547.2] great repository for all of the [Duration: 4.139]
[start 549.24] different libraries that can affect this [Duration: 3.96]
[start 551.339] whole host of information here [Duration: 4.5]
[start 553.2] incredibly useful [Duration: 4.259]
[start 555.839] so [Duration: 3.301]
[start 557.459] I love learning about new [Duration: 3.121]
[start 559.14] vulnerabilities and new ways to do [Duration: 3.48]
[start 560.58] things and and that was the same for me [Duration: 4.02]
[start 562.62] when I learned about prototype pollution [Duration: 5.76]
[start 564.6] but I also love automation or more [Duration: 5.76]
[start 568.38] specifically as some of you'll know I [Duration: 3.72]
[start 570.36] like writing tools [Duration: 5.28]
[start 572.1] and if I discover a new class of [Duration: 5.7]
[start 575.64] vulnerability I want to go off and try [Duration: 4.98]
[start 577.8] and find it everywhere that I can and a [Duration: 4.74]
[start 580.62] lot of people use things like nuclei for [Duration: 4.62]
[start 582.54] that which is uh you know it's a great [Duration: 4.739]
[start 585.24] project very useful [Duration: 3.719]
[start 587.279] um or maybe they use some of the tools [Duration: 4.56]
[start 588.959] that I wrote like Meg for example go and [Duration: 4.741]
[start 591.839] search for reflected cross-site [Duration: 4.801]
[start 593.7] scripting or maybe SQL injection or [Duration: 4.74]
[start 596.64] anything like that [Duration: 3.78]
[start 598.44] but we have a bit of a problem doing [Duration: 4.14]
[start 600.42] that for something like prototype [Duration: 3.84]
[start 602.58] pollution because this is a purely [Duration: 4.56]
[start 604.26] client-side vulnerability [Duration: 6.42]
[start 607.14] you know if I took a test string like [Duration: 7.139]
[start 610.68] we had originally [Duration: 6.24]
[start 614.279] just test and test [Duration: 5.761]
[start 616.92] there's nothing about the page Source [Duration: 5.76]
[start 620.04] here that gives away that this page is [Duration: 4.739]
[start 622.68] vulnerable to prototype pollution short [Duration: 4.08]
[start 624.779] of maybe you know fingerprinting known [Duration: 4.62]
[start 626.76] vulnerable JavaScript libraries [Duration: 5.4]
[start 629.399] but even then you know that can be [Duration: 6]
[start 632.16] error-prone because we can't necessarily [Duration: 5.76]
[start 635.399] rely on the file name where of the [Duration: 4.261]
[start 637.92] JavaScript library when things have all [Duration: 5.039]
[start 639.66] been concatenated and bundled into one [Duration: 5.64]
[start 642.959] um single Javascript file with just a [Duration: 4.38]
[start 645.3] hash as its name [Duration: 4.979]
[start 647.339] um and you know we also aren't going to [Duration: 4.861]
[start 650.279] spot any libraries that we don't already [Duration: 3.24]
[start 652.2] know about we're not going to find [Duration: 3.74]
[start 653.519] anything novel that way [Duration: 5.76]
[start 655.94] so what I would like to suggest [Duration: 6.76]
[start 659.279] is that we use a headless browser to go [Duration: 6.12]
[start 662.7] off and try and find this particular [Duration: 6.66]
[start 665.399] kind of issue and because I like go [Duration: 8.541]
[start 669.36] I'm going to use the Chrome DP Library [Duration: 4.58]
[start 674.04] so Chrome DP [Duration: 4.32]
[start 676.32] as the readme will tell us [Duration: 4.079]
[start 678.36] is a faster simpler way to drive [Duration: 4.32]
[start 680.399] browsers supporting the Chrome devtools [Duration: 5.101]
[start 682.68] protocol in go without any kind of [Duration: 4.86]
[start 685.5] external dependencies like selenium or [Duration: 5.04]
[start 687.54] Phantom JS and that sounds like exactly [Duration: 4.979]
[start 690.54] the kind of thing that I want [Duration: 4.799]
[start 692.519] so I'm going to take you through how I [Duration: 7.5]
[start 695.339] would prototype and then build a tool to [Duration: 6.841]
[start 700.019] detect this vulnerability using Chrome [Duration: 5.461]
[start 702.18] DP so let's give it a go so [Duration: 5.339]
[start 705.48] this is the library that we're going to [Duration: 3.78]
[start 707.519] use I'm going to switch to a terminal [Duration: 3.901]
[start 709.26] and I have a directory here already set [Duration: 3.92]
[start 711.42] up called run.js [Duration: 4.02]
[start 713.18] but there's only one thing in here which [Duration: 4.839]
[start 715.44] is a list of URLs that are pre-prepared [Duration: 4.62]
[start 718.019] and we'll come back to those later [Duration: 3.781]
[start 720.06] so I'm going to make a new go file [Duration: 4.519]
[start 721.8] called main.go [Duration: 2.779]
[start 725.3] apparently I already have a swap file [Duration: 4.18]
[start 727.8] for main.go so I'm just going to remove [Duration: 4.039]
[start 729.48] that [Duration: 2.359]
[start 732.48] and I'm using the vimgo plugin which [Duration: 6.419]
[start 735.899] gives me this template automatically [Duration: 5.761]
[start 738.899] when I start a new go program but we'll [Duration: 4.44]
[start 741.66] run through it quickly what it all means [Duration: 4.2]
[start 743.339] anyway if you're not super familiar with [Duration: 4.981]
[start 745.86] ghost syntax I'll try and explain as [Duration: 5.159]
[start 748.32] best as I can but unfortunately we don't [Duration: 4.68]
[start 751.019] really have the time to go through a [Duration: 4.021]
[start 753] full go tutorial [Duration: 4.8]
[start 755.04] uh so we're in package main that means [Duration: 5.34]
[start 757.8] we are writing an executable so in go [Duration: 4.86]
[start 760.38] code you can have libraries so this [Duration: 4.259]
[start 762.66] might be package my super awesome [Duration: 4.2]
[start 764.639] library for example that can be included [Duration: 5.041]
[start 766.86] in other go programs uh but if we're [Duration: 5.099]
[start 769.68] writing an executable uh we want package [Duration: 4.86]
[start 771.959] main we've imported the front package by [Duration: 4.401]
[start 639.66] been concatenated and bundled into one [Duration: 5.64]
[start 642.959] um single Javascript file with just a [Duration: 4.38]
[start 774.54] default because we have from.printlin [Duration: 5.22]
[start 776.36] and we have a main function here which [Duration: 5.62]
[start 779.76] is what runs when you execute a go [Duration: 5.579]
[start 781.98] executable a bit like in C and we have [Duration: 6.62]
[start 785.339] the main function now [Duration: 7.44]
[start 788.6] I like many other people in this world [Duration: 7.06]
[start 792.779] um relatively lazy and if I can get away [Duration: 5.521]
[start 795.66] with not doing very much work I will do [Duration: 3.54]
[start 798.3] that [Duration: 3.3]
[start 799.2] and as look would have it [Duration: 5.46]
[start 801.6] the maintainers of chrome DP uh have my [Duration: 5.52]
[start 804.66] back here so they provide an examples [Duration: 5.22]
[start 807.12] repository containing some more complex [Duration: 5.159]
[start 809.88] examples and I'm going to use that [Duration: 6.24]
[start 812.279] so our plan of attack is we want to load [Duration: 6.12]
[start 816.12] a URL like this [Duration: 6.08]
[start 818.399] have some kind of prototype pollution [Duration: 7.981]
[start 822.2] payload in the [Duration: 7.06]
[start 826.38] uh query string and then we're going to [Duration: 5.639]
[start 829.26] look to see if we've managed to set a [Duration: 5.22]
[start 832.019] variable in the global scope and if [Duration: 4.201]
[start 834.48] that's true then we should have [Duration: 4.26]
[start 836.22] prototype pollution doesn't necessarily [Duration: 6.84]
[start 838.74] tell us if we have you know if the page [Duration: 5.76]
[start 843.06] is going to be vulnerable to cross-site [Duration: 3.839]
[start 844.5] scripting but it does give us a pretty [Duration: 4.68]
[start 846.899] big hint that it's quite likely or it's [Duration: 3.901]
[start 849.18] at least possible [Duration: 4.26]
[start 850.8] so let's go with that [Duration: 5.7]
[start 853.44] so there's an example here in the [Duration: 5.339]
[start 856.5] examples repository called eval [Duration: 5.16]
[start 858.779] which is I'm going to use and if we take [Duration: 4.5]
[start 861.66] a look at it [Duration: 3.66]
[start 863.279] we can see it does something with a [Duration: 3.961]
[start 865.32] context I don't know about that yet [Duration: 4.5]
[start 867.24] we'll have a look and it's just chromedp [Duration: 5.88]
[start 869.82] dot run it navigates to a page Waits [Duration: 6.06]
[start 873.12] until some element is visible and then [Duration: 5.76]
[start 875.88] it evaluates some JavaScript [Duration: 5.94]
[start 878.88] and puts it into some kind of response [Duration: 6]
[start 881.82] variable so this feels like the kind of [Duration: 4.34]
[start 884.88] thing [Duration: 5.06]
[start 886.16] that we want or at least pretty close so [Duration: 7.96]
[start 889.94] let's just uh copy and paste it [Duration: 7.079]
[start 894.12] put it into our window [Duration: 2.899]
[start 897.18] um we need to import [Duration: 7.7]
[start 900.3] that package as well so let's do that [Duration: 4.58]
[start 905.579] import [Duration: 4.5]
[start 645.3] hash as its name [Duration: 4.979]
[start 647.339] um and you know we also aren't going to [Duration: 4.861]
[start 650.279] spot any libraries that we don't already [Duration: 3.24]
[start 652.2] know about we're not going to find [Duration: 3.74]
[start 653.519] anything novel that way [Duration: 5.76]
[start 655.94] so what I would like to suggest [Duration: 6.76]
[start 659.279] is that we use a headless browser to go [Duration: 6.12]
[start 662.7] off and try and find this particular [Duration: 6.66]
[start 665.399] kind of issue and because I like go [Duration: 8.541]
[start 669.36] I'm going to use the Chrome DP Library [Duration: 4.58]
[start 674.04] so Chrome DP [Duration: 4.32]
[start 676.32] as the readme will tell us [Duration: 4.079]
[start 678.36] is a faster simpler way to drive [Duration: 4.32]
[start 680.399] browsers supporting the Chrome devtools [Duration: 5.101]
[start 682.68] protocol in go without any kind of [Duration: 4.86]
[start 685.5] external dependencies like selenium or [Duration: 5.04]
[start 687.54] Phantom JS and that sounds like exactly [Duration: 4.979]
[start 690.54] the kind of thing that I want [Duration: 4.799]
[start 692.519] so I'm going to take you through how I [Duration: 7.5]
[start 695.339] would prototype and then build a tool to [Duration: 6.841]
[start 700.019] detect this vulnerability using Chrome [Duration: 5.461]
[start 702.18] DP so let's give it a go so [Duration: 5.339]
[start 705.48] this is the library that we're going to [Duration: 3.78]
[start 707.519] use I'm going to switch to a terminal [Duration: 3.901]
[start 709.26] and I have a directory here already set [Duration: 3.92]
[start 711.42] up called run.js [Duration: 4.02]
[start 713.18] but there's only one thing in here which [Duration: 4.839]
[start 715.44] is a list of URLs that are pre-prepared [Duration: 4.62]
[start 718.019] and we'll come back to those later [Duration: 3.781]
[start 720.06] so I'm going to make a new go file [Duration: 4.519]
[start 721.8] called main.go [Duration: 2.779]
[start 908.1] looks like I copied the quotes as well [Duration: 4.38]
[start 910.079] there we go [Duration: 5.221]
[start 912.48] apply some formatting and in theory if [Duration: 4.38]
[start 915.3] we run this [Duration: 5.219]
[start 916.86] we should load google.com [Duration: 7.44]
[start 920.519] wait for a main some element with an ID [Duration: 5.94]
[start 924.3] of main to be visible and then we should [Duration: 4.979]
[start 926.459] evaluate that bit of JavaScript and then [Duration: 4.261]
[start 929.279] we should print it out window object [Duration: 4.201]
[start 930.72] keys so let's see if that works [Duration: 5.28]
[start 933.48] and it may well not [Duration: 5.58]
[start 936] and if it doesn't I think the main most [Duration: 5.579]
[start 939.06] likely reason is going to be that that [Duration: 4.44]
[start 941.579] uh [Duration: 3.661]
[start 943.5] element with an idea of main doesn't [Duration: 3.6]
[start 945.24] exist so let's just drop that line out [Duration: 4.2]
[start 947.1] we probably don't want that anyway [Duration: 4.26]
[start 949.44] give that a run that looks like it did [Duration: 3.54]
[start 951.36] something so [Duration: 5.3]
[start 952.98] this is a list of all of the variables [Duration: 6.299]
[start 956.66] on the window object [Duration: 5.02]
[start 959.279] on google.com [Duration: 4.641]
[start 961.68] so [Duration: 4.98]
[start 963.92] it's working you know it's launching a [Duration: 5.74]
[start 966.66] headless browser and I think for me when [Duration: 6.119]
[start 969.66] making tools the important thing is to [Duration: 5.4]
[start 972.779] move from one working thing to another [Duration: 4.68]
[start 725.3] apparently I already have a swap file [Duration: 4.18]
[start 727.8] for main.go so I'm just going to remove [Duration: 4.039]
[start 729.48] that [Duration: 2.359]
[start 732.48] and I'm using the vimgo plugin which [Duration: 6.419]
[start 735.899] gives me this template automatically [Duration: 5.761]
[start 738.899] when I start a new go program but we'll [Duration: 4.44]
[start 741.66] run through it quickly what it all means [Duration: 4.2]
[start 743.339] anyway if you're not super familiar with [Duration: 4.981]
[start 745.86] ghost syntax I'll try and explain as [Duration: 5.159]
[start 748.32] best as I can but unfortunately we don't [Duration: 4.68]
[start 751.019] really have the time to go through a [Duration: 4.021]
[start 753] full go tutorial [Duration: 4.8]
[start 755.04] uh so we're in package main that means [Duration: 5.34]
[start 757.8] we are writing an executable so in go [Duration: 4.86]
[start 760.38] code you can have libraries so this [Duration: 4.259]
[start 762.66] might be package my super awesome [Duration: 4.2]
[start 764.639] library for example that can be included [Duration: 5.041]
[start 766.86] in other go programs uh but if we're [Duration: 5.099]
[start 769.68] writing an executable uh we want package [Duration: 4.86]
[start 771.959] main we've imported the front package by [Duration: 4.401]
[start 774.54] default because we have from.printlin [Duration: 5.22]
[start 776.36] and we have a main function here which [Duration: 5.62]
[start 779.76] is what runs when you execute a go [Duration: 5.579]
[start 781.98] executable a bit like in C and we have [Duration: 6.62]
[start 785.339] the main function now [Duration: 7.44]
[start 788.6] I like many other people in this world [Duration: 7.06]
[start 792.779] um relatively lazy and if I can get away [Duration: 5.521]
[start 795.66] with not doing very much work I will do [Duration: 3.54]
[start 798.3] that [Duration: 3.3]
[start 799.2] and as look would have it [Duration: 5.46]
[start 801.6] the maintainers of chrome DP uh have my [Duration: 5.52]
[start 804.66] back here so they provide an examples [Duration: 5.22]
[start 807.12] repository containing some more complex [Duration: 5.159]
[start 809.88] examples and I'm going to use that [Duration: 6.24]
[start 812.279] so our plan of attack is we want to load [Duration: 6.12]
[start 816.12] a URL like this [Duration: 6.08]
[start 818.399] have some kind of prototype pollution [Duration: 7.981]
[start 822.2] payload in the [Duration: 7.06]
[start 826.38] uh query string and then we're going to [Duration: 5.639]
[start 829.26] look to see if we've managed to set a [Duration: 5.22]
[start 832.019] variable in the global scope and if [Duration: 4.201]
[start 834.48] that's true then we should have [Duration: 4.26]
[start 836.22] prototype pollution doesn't necessarily [Duration: 6.84]
[start 838.74] tell us if we have you know if the page [Duration: 5.76]
[start 843.06] is going to be vulnerable to cross-site [Duration: 3.839]
[start 844.5] scripting but it does give us a pretty [Duration: 4.68]
[start 846.899] big hint that it's quite likely or it's [Duration: 3.901]
[start 849.18] at least possible [Duration: 4.26]
[start 850.8] so let's go with that [Duration: 5.7]
[start 853.44] so there's an example here in the [Duration: 5.339]
[start 856.5] examples repository called eval [Duration: 5.16]
[start 858.779] which is I'm going to use and if we take [Duration: 4.5]
[start 861.66] a look at it [Duration: 3.66]
[start 863.279] we can see it does something with a [Duration: 3.961]
[start 865.32] context I don't know about that yet [Duration: 4.5]
[start 867.24] we'll have a look and it's just chromedp [Duration: 5.88]
[start 869.82] dot run it navigates to a page Waits [Duration: 6.06]
[start 873.12] until some element is visible and then [Duration: 5.76]
[start 875.88] it evaluates some JavaScript [Duration: 5.94]
[start 878.88] and puts it into some kind of response [Duration: 6]
[start 881.82] variable so this feels like the kind of [Duration: 4.34]
[start 884.88] thing [Duration: 5.06]
[start 886.16] that we want or at least pretty close so [Duration: 7.96]
[start 889.94] let's just uh copy and paste it [Duration: 7.079]
[start 894.12] put it into our window [Duration: 2.899]
[start 897.18] um we need to import [Duration: 7.7]
[start 900.3] that package as well so let's do that [Duration: 4.58]
[start 905.579] import [Duration: 4.5]
[start 908.1] looks like I copied the quotes as well [Duration: 4.38]
[start 910.079] there we go [Duration: 5.221]
[start 912.48] apply some formatting and in theory if [Duration: 4.38]
[start 915.3] we run this [Duration: 5.219]
[start 916.86] we should load google.com [Duration: 7.44]
[start 920.519] wait for a main some element with an ID [Duration: 5.94]
[start 924.3] of main to be visible and then we should [Duration: 4.979]
[start 926.459] evaluate that bit of JavaScript and then [Duration: 4.261]
[start 929.279] we should print it out window object [Duration: 4.201]
[start 930.72] keys so let's see if that works [Duration: 5.28]
[start 933.48] and it may well not [Duration: 5.58]
[start 936] and if it doesn't I think the main most [Duration: 5.579]
[start 939.06] likely reason is going to be that that [Duration: 4.44]
[start 941.579] uh [Duration: 3.661]
[start 943.5] element with an idea of main doesn't [Duration: 3.6]
[start 945.24] exist so let's just drop that line out [Duration: 4.2]
[start 947.1] we probably don't want that anyway [Duration: 4.26]
[start 949.44] give that a run that looks like it did [Duration: 3.54]
[start 975.06] working thing in a small steps as [Duration: 6.24]
[start 977.459] possible if you set out to write a large [Duration: 5.701]
[start 981.3] complex application [Duration: 4.02]
[start 983.16] all at once [Duration: 5.52]
[start 985.32] um it might work but you dramatically [Duration: 5.04]
[start 988.68] increase your chances of having a [Duration: 4.56]
[start 990.36] working program if you start with [Duration: 4.08]
[start 993.24] something working [Duration: 4.74]
[start 994.44] and make small modifications until [Duration: 6.3]
[start 997.98] uh you're finished or until it stops [Duration: 4.08]
[start 1000.74] working I guess [Duration: 3.48]
[start 1002.06] so let's make some changes to this to [Duration: 4.92]
[start 1004.22] try and detect prototype pollution in [Duration: 5.34]
[start 1006.98] our example page [Duration: 5]
[start 1009.56] so let's take [Duration: 6.139]
[start 1011.98] this URL here [Duration: 3.719]
[start 1017.06] and we will [Duration: 5.04]
[start 1019.519] load that one instead [Duration: 4.981]
[start 1022.1] so I'm important to hear [Duration: 4.4]
[start 1024.5] change that URL to one that we control [Duration: 4.559]
[start 1026.5] and we want to know something about this [Duration: 6.76]
[start 951.36] something so [Duration: 5.3]
[start 952.98] this is a list of all of the variables [Duration: 6.299]
[start 956.66] on the window object [Duration: 5.02]
[start 959.279] on google.com [Duration: 4.641]
[start 961.68] so [Duration: 4.98]
[start 963.92] it's working you know it's launching a [Duration: 5.74]
[start 966.66] headless browser and I think for me when [Duration: 6.119]
[start 969.66] making tools the important thing is to [Duration: 5.4]
[start 972.779] move from one working thing to another [Duration: 4.68]
[start 975.06] working thing in a small steps as [Duration: 6.24]
[start 977.459] possible if you set out to write a large [Duration: 5.701]
[start 981.3] complex application [Duration: 4.02]
[start 983.16] all at once [Duration: 5.52]
[start 985.32] um it might work but you dramatically [Duration: 5.04]
[start 988.68] increase your chances of having a [Duration: 4.56]
[start 990.36] working program if you start with [Duration: 4.08]
[start 993.24] something working [Duration: 4.74]
[start 994.44] and make small modifications until [Duration: 6.3]
[start 997.98] uh you're finished or until it stops [Duration: 4.08]
[start 1000.74] working I guess [Duration: 3.48]
[start 1002.06] so let's make some changes to this to [Duration: 4.92]
[start 1029.059] test variable and in fact test is maybe [Duration: 6.421]
[start 1033.26] feels like a bit too likely to already [Duration: 4.679]
[start 1035.48] exist so I'm going to change it to a [Duration: 5.339]
[start 1037.939] nonsense word futile and I'm going to [Duration: 5.701]
[start 1040.819] set it to brutal I don't know why [Duration: 4.441]
[start 1043.64] they're just always the the two words [Duration: 4.159]
[start 1045.26] that I end up using [Duration: 6.24]
[start 1047.799] so the JavaScript that we want to run is [Duration: 5.081]
[start 1051.5] going to be something that tells us [Duration: 4.02]
[start 1052.88] whether that futile variable is set on [Duration: 5.4]
[start 1055.52] the window object so we could do [Duration: 4.94]
[start 1058.28] something like [Duration: 6.72]
[start 1060.46] uh just get the output of it so if we [Duration: 6.94]
[start 1065] just run futile or maybe window.foodle [Duration: 3.419]
[start 1067.4] or something [Duration: 3.36]
[start 1068.419] and we try and put the response into [Duration: 5.161]
[start 1070.76] just a regular string we don't want a [Duration: 5.52]
[start 1073.58] list of strings anymore [Duration: 4.62]
[start 1076.28] um and this is not the window object [Duration: 4.44]
[start 1078.2] keys this is going to be [Duration: 7.08]
[start 1080.72] the value of football and we run that [Duration: 6.78]
[start 1085.28] and let's see what it does [Duration: 5.7]
[start 1087.5] so we have the value of feudal is bootle [Duration: 6.48]
[start 1090.98] so that tells us that this page is [Duration: 4.22]
[start 1093.98] vulnerable [Duration: 5.04]
[start 1095.2] but you know this one exact page in this [Duration: 6.76]
[start 1099.02] one exact configuration this isn't an [Duration: 6.539]
[start 1101.96] especially useful bit of code so let's [Duration: 6.54]
[start 1105.559] try and make it a little bit more useful [Duration: 4.921]
[start 1108.5] uh you know one of the ways that we [Duration: 5.1]
[start 1110.48] could do that would be to have this code [Duration: 7.559]
[start 1113.6] accept a list of URLs as input [Duration: 8.52]
[start 1118.039] and check all of them somehow and if we [Duration: 5.041]
[start 1122.12] did that [Duration: 4.5]
[start 1123.08] we could you know apply this query [Duration: 4.62]
[start 1126.62] string [Duration: 3.62]
[start 1127.7] though that we've come up with here [Duration: 5.82]
[start 1130.24] to every single URL that comes in [Duration: 6.4]
[start 1133.52] and we would have a fairly useful but [Duration: 5.159]
[start 1136.64] single purpose tool there that would [Duration: 4.68]
[start 1138.679] check for just prototype pollution in [Duration: 4.321]
[start 1141.32] the URLs that you give it with this one [Duration: 3.78]
[start 1143] particular payload or maybe you could [Duration: 4.32]
[start 1145.1] build multiple payloads in [Duration: 4.439]
[start 1147.32] um all I'd really like to do is build [Duration: 3.66]
[start 1149.539] something else a little bit more [Duration: 3.961]
[start 1150.98] flexible so if I come up with anything [Duration: 5.34]
[start 1153.5] else that I want to do running [Duration: 4.62]
[start 1156.32] JavaScript on lots of different web [Duration: 3]
[start 1004.22] try and detect prototype pollution in [Duration: 5.34]
[start 1006.98] our example page [Duration: 5]
[start 1009.56] so let's take [Duration: 6.139]
[start 1011.98] this URL here [Duration: 3.719]
[start 1017.06] and we will [Duration: 5.04]
[start 1019.519] load that one instead [Duration: 4.981]
[start 1022.1] so I'm important to hear [Duration: 4.4]
[start 1024.5] change that URL to one that we control [Duration: 4.559]
[start 1158.12] pages [Duration: 3.84]
[start 1159.32] I can do that too [Duration: 5.34]
[start 1026.5] and we want to know something about this [Duration: 6.76]
[start 1029.059] test variable and in fact test is maybe [Duration: 6.421]
[start 1161.96] so uh let's start off with just [Duration: 5.52]
[start 1164.66] something that takes a list of URLs as [Duration: 5.82]
[start 1033.26] feels like a bit too likely to already [Duration: 4.679]
[start 1035.48] exist so I'm going to change it to a [Duration: 5.339]
[start 1037.939] nonsense word futile and I'm going to [Duration: 5.701]
[start 1040.819] set it to brutal I don't know why [Duration: 4.441]
[start 1043.64] they're just always the the two words [Duration: 4.159]
[start 1045.26] that I end up using [Duration: 6.24]
[start 1167.48] input and run some JavaScript on the [Duration: 5.699]
[start 1170.48] page and prints the result let's give it [Duration: 4.079]
[start 1047.799] so the JavaScript that we want to run is [Duration: 5.081]
[start 1051.5] going to be something that tells us [Duration: 4.02]
[start 1052.88] whether that futile variable is set on [Duration: 5.4]
[start 1055.52] the window object so we could do [Duration: 4.94]
[start 1058.28] something like [Duration: 6.72]
[start 1060.46] uh just get the output of it so if we [Duration: 6.94]
[start 1065] just run futile or maybe window.foodle [Duration: 3.419]
[start 1067.4] or something [Duration: 3.36]
[start 1068.419] and we try and put the response into [Duration: 5.161]
[start 1070.76] just a regular string we don't want a [Duration: 5.52]
[start 1073.58] list of strings anymore [Duration: 4.62]
[start 1076.28] um and this is not the window object [Duration: 4.44]
[start 1078.2] keys this is going to be [Duration: 7.08]
[start 1080.72] the value of football and we run that [Duration: 6.78]
[start 1085.28] and let's see what it does [Duration: 5.7]
[start 1087.5] so we have the value of feudal is bootle [Duration: 6.48]
[start 1090.98] so that tells us that this page is [Duration: 4.22]
[start 1093.98] vulnerable [Duration: 5.04]
[start 1095.2] but you know this one exact page in this [Duration: 6.76]
[start 1099.02] one exact configuration this isn't an [Duration: 6.539]
[start 1101.96] especially useful bit of code so let's [Duration: 6.54]
[start 1105.559] try and make it a little bit more useful [Duration: 4.921]
[start 1108.5] uh you know one of the ways that we [Duration: 5.1]
[start 1110.48] could do that would be to have this code [Duration: 7.559]
[start 1113.6] accept a list of URLs as input [Duration: 8.52]
[start 1118.039] and check all of them somehow and if we [Duration: 5.041]
[start 1122.12] did that [Duration: 4.5]
[start 1123.08] we could you know apply this query [Duration: 4.62]
[start 1126.62] string [Duration: 3.62]
[start 1127.7] though that we've come up with here [Duration: 5.82]
[start 1130.24] to every single URL that comes in [Duration: 6.4]
[start 1133.52] and we would have a fairly useful but [Duration: 5.159]
[start 1136.64] single purpose tool there that would [Duration: 4.68]
[start 1138.679] check for just prototype pollution in [Duration: 4.321]
[start 1141.32] the URLs that you give it with this one [Duration: 3.78]
[start 1143] particular payload or maybe you could [Duration: 4.32]
[start 1145.1] build multiple payloads in [Duration: 4.439]
[start 1147.32] um all I'd really like to do is build [Duration: 3.66]
[start 1149.539] something else a little bit more [Duration: 3.961]
[start 1150.98] flexible so if I come up with anything [Duration: 5.34]
[start 1153.5] else that I want to do running [Duration: 4.62]
[start 1156.32] JavaScript on lots of different web [Duration: 3]
[start 1158.12] pages [Duration: 3.84]
[start 1159.32] I can do that too [Duration: 5.34]
[start 1161.96] so uh let's start off with just [Duration: 5.52]
[start 1164.66] something that takes a list of URLs as [Duration: 5.82]
[start 1167.48] input and run some JavaScript on the [Duration: 5.699]
[start 1170.48] page and prints the result let's give it [Duration: 4.079]
[start 1173.179] a go [Duration: 2.781]
[start 1174.559] so [Duration: 4.141]
[start 1175.96] we are going to use [Duration: 5.079]
[start 1178.7] a thing from the buffet out package [Duration: 4.38]
[start 1181.039] called a scanner to read lines of input [Duration: 7.441]
[start 1183.08] so we'll say SC is a buffalo new scanner [Duration: 9.38]
[start 1188.48] over OS dot student [Duration: 3.98]
[start 1193.419] which is going to give us lines of [Duration: 4.12]
[start 1195.86] standard input on one left to the other [Duration: 3.84]
[start 1197.539] and we'll say [Duration: 6.301]
[start 1199.7] for the time that we can scan the input [Duration: 6.12]
[start 1203.84] we will do [Duration: 5.9]
[start 1173.179] a go [Duration: 2.781]
[start 1174.559] so [Duration: 4.141]
[start 1175.96] we are going to use [Duration: 5.079]
[start 1178.7] a thing from the buffet out package [Duration: 4.38]
[start 1181.039] called a scanner to read lines of input [Duration: 7.441]
[start 1183.08] so we'll say SC is a buffalo new scanner [Duration: 9.38]
[start 1188.48] over OS dot student [Duration: 3.98]
[start 1193.419] which is going to give us lines of [Duration: 4.12]
[start 1195.86] standard input on one left to the other [Duration: 3.84]
[start 1197.539] and we'll say [Duration: 6.301]
[start 1199.7] for the time that we can scan the input [Duration: 6.12]
[start 1203.84] we will do [Duration: 5.9]
[start 1205.82] all of this effectively [Duration: 3.92]
[start 1210.5] that we were doing before [Duration: 4.86]
[start 1212.6] and we're going to have some URL [Duration: 5.4]
[start 1215.36] what's that equal to U [Duration: 5.22]
[start 1218] H going to be a c dot text so that gets [Duration: 5.94]
[start 1220.58] us whatever the current line is that's [Duration: 7.08]
[start 1223.94] being read by the scanner [Duration: 6.359]
[start 1227.66] and [Duration: 5.34]
[start 1230.299] we will instead of loading that URL [Duration: 6.24]
[start 1233] we'll just load whatever URL we're given [Duration: 5.66]
[start 1236.539] and then we'll evaluate [Duration: 5.52]
[start 1238.66] window.foodle for now why not [Duration: 7.48]
[start 1242.059] and this log fatal uh in the middle of [Duration: 8.281]
[start 1246.14] the loop I'm not a specially keen on so [Duration: 7.8]
[start 1250.34] let's change this instead to a log dot [Duration: 5.4]
[start 1253.94] printf [Duration: 3.599]
[start 1255.74] where we print the string value of the [Duration: 3.299]
[start 1257.539] error and say [Duration: 4.02]
[start 1259.039] there has been an error of some kind we [Duration: 3.781]
[start 1261.559] don't need a new line because we're [Duration: 3.781]
[start 1262.82] using a log package and then we will [Duration: 6.66]
[start 1265.34] continue in this Loop instead [Duration: 5.719]
[start 1269.48] now [Duration: 5.16]
[start 1271.059] if I try and run this program it's going [Duration: 5.141]
[start 1274.64] to tell me that I've got some some [Duration: 3.12]
[start 1276.2] packages that haven't included so I'll [Duration: 3.839]
[start 1277.76] just do that real quick uh and if I run [Duration: 4.62]
[start 1280.039] that it's just going to sit there and [Duration: 3.661]
[start 1282.38] the reason it's sitting there is it's [Duration: 4.08]
[start 1205.82] all of this effectively [Duration: 3.92]
[start 1210.5] that we were doing before [Duration: 4.86]
[start 1212.6] and we're going to have some URL [Duration: 5.4]
[start 1215.36] what's that equal to U [Duration: 5.22]
[start 1218] H going to be a c dot text so that gets [Duration: 5.94]
[start 1220.58] us whatever the current line is that's [Duration: 7.08]
[start 1223.94] being read by the scanner [Duration: 6.359]
[start 1227.66] and [Duration: 5.34]
[start 1230.299] we will instead of loading that URL [Duration: 6.24]
[start 1233] we'll just load whatever URL we're given [Duration: 5.66]
[start 1236.539] and then we'll evaluate [Duration: 5.52]
[start 1238.66] window.foodle for now why not [Duration: 7.48]
[start 1242.059] and this log fatal uh in the middle of [Duration: 8.281]
[start 1246.14] the loop I'm not a specially keen on so [Duration: 7.8]
[start 1250.34] let's change this instead to a log dot [Duration: 5.4]
[start 1253.94] printf [Duration: 3.599]
[start 1255.74] where we print the string value of the [Duration: 3.299]
[start 1257.539] error and say [Duration: 4.02]
[start 1259.039] there has been an error of some kind we [Duration: 3.781]
[start 1261.559] don't need a new line because we're [Duration: 3.781]
[start 1262.82] using a log package and then we will [Duration: 6.66]
[start 1265.34] continue in this Loop instead [Duration: 5.719]
[start 1269.48] now [Duration: 5.16]
[start 1271.059] if I try and run this program it's going [Duration: 5.141]
[start 1274.64] to tell me that I've got some some [Duration: 3.12]
[start 1276.2] packages that haven't included so I'll [Duration: 3.839]
[start 1277.76] just do that real quick uh and if I run [Duration: 4.62]
[start 1280.039] that it's just going to sit there and [Duration: 3.661]
[start 1282.38] the reason it's sitting there is it's [Duration: 4.08]
[start 1283.7] waiting for us [Duration: 5.76]
[start 1283.7] waiting for us [Duration: 5.76]
[start 1286.46] to put in some kind of URL [Duration: 4.62]
[start 1289.46] and we can see we got an error on [Duration: 3.839]
[start 1291.08] example.com encountered an undefined [Duration: 4.14]
[start 1286.46] to put in some kind of URL [Duration: 4.62]
[start 1289.46] and we can see we got an error on [Duration: 3.839]
[start 1291.08] example.com encountered an undefined [Duration: 4.14]
[start 1293.299] value [Duration: 3.181]
[start 1293.299] value [Duration: 3.181]
[start 1295.22] and that's because it's looking for [Duration: 3.36]
[start 1296.48] window.footal right and that doesn't [Duration: 5.6]
[start 1298.58] exist because why would it [Duration: 7.14]
[start 1302.08] so what I'm going to do is say actually [Duration: 5.74]
[start 1305.72] I'll use bang to execute the shell [Duration: 4.98]
[start 1307.82] command I'll run go build [Duration: 6.12]
[start 1310.7] in the current directory and [Duration: 7.979]
[start 1313.94] I want to cut my URLs file into [Duration: 7.619]
[start 1318.679] this run.js program that we've been [Duration: 4.681]
[start 1321.559] writing so we were in a directory called [Duration: 5.521]
[start 1323.36] run.js called run JS and [Duration: 6.179]
[start 1327.08] therefore go decided that's what the [Duration: 4.8]
[start 1329.539] binary should be called so let's run [Duration: 4.02]
[start 1331.88] that and see what happens [Duration: 4.5]
[start 1333.559] so we got character undefined values on [Duration: 4.62]
[start 1336.38] one of them we got the value of food is [Duration: 3.539]
[start 1338.179] Moodle [Duration: 4.62]
[start 1339.919] um we don't know what for so let's fix [Duration: 3.721]
[start 1342.799] that [Duration: 3.301]
[start 1343.64] and instead of saying the value of [Duration: 4.2]
[start 1346.1] futile [Duration: 4.5]
[start 1347.84] let's just put in the URL that we were [Duration: 4.68]
[start 1350.6] calling instead and see what that looks [Duration: 3.18]
[start 1352.52] like [Duration: 3.42]
[start 1353.78] so we're running we expect the output to [Duration: 2.879]
[start 1355.94] be [Duration: 3.9]
[start 1356.659] uh I read the wrong thing I want to run [Duration: 5.701]
[start 1359.84] my go build command again [Duration: 4.92]
[start 1362.36] so we'll run that we calculate undefined [Duration: 6.48]
[start 1364.76] values for some of them uh and on others [Duration: 8.279]
[start 1368.84] on this one we've got this value bootle [Duration: 5.28]
[start 1373.039] so [Duration: 2.461]
[start 1374.12] that works okay [Duration: 3.84]
[start 1375.5] it's a little bit strange though to [Duration: 4.98]
[start 1377.96] always just run this window.footal I [Duration: 5.04]
[start 1380.48] wouldn't expect the user of this tool to [Duration: 4.92]
[start 1383] be able to you know guess or remember [Duration: 5.7]
[start 1385.4] that that's for some reason uh what you [Duration: 4.92]
[start 1388.7] had to do [Duration: 5.04]
[start 1390.32] so let's change this instead to be [Duration: 6.719]
[start 1393.74] some value called user.js and we're [Duration: 5.819]
[start 1397.039] going to accept that as a flag [Duration: 4.801]
[start 1399.559] so [Duration: 6.441]
[start 1401.84] we'll use the go flag package [Duration: 4.16]
[start 1406.52] and we will make a string variable and [Duration: 8.159]
[start 1411.26] let's see if I can remember the order of [Duration: 5.52]
[start 1414.679] the parameters here [Duration: 5.281]
[start 1416.78] so we're going to have our user.js [Duration: 4.92]
[start 1419.96] which is a string [Duration: 5.579]
[start 1421.7] and then a string variable of user.js [Duration: 7.44]
[start 1425.539] with a default of empty [Duration: 5.76]
[start 1429.14] I'm trying to get this right oh no first [Duration: 5.34]
[start 1431.299] comes the name so we'll make that j a [Duration: 5.821]
[start 1434.48] default of empty and then the help [Duration: 6.66]
[start 1437.12] output for is going to be the JS to run [Duration: 7.16]
[start 1441.14] on each page [Duration: 3.14]
[start 1444.86] so now if we run this [Duration: 4.799]
[start 1448.1] will tell us we haven't got the flag [Duration: 4.819]
[start 1449.659] package now we do [Duration: 3.26]
[start 1453.2] and it's going to go off and run some [Duration: 5.94]
[start 1456.44] empty JavaScript on every page but if we [Duration: 6.32]
[start 1459.14] change our Command to say let's include [Duration: 6.6]
[start 1462.76] window.futel again [Duration: 5.08]
[start 1465.74] hopefully with a little bit of look [Duration: 4.319]
[start 1467.84] we'll see one of them in there works [Duration: 4.56]
[start 1470.059] just fine which is great that's exactly [Duration: 4.441]
[start 1472.4] what we wanted [Duration: 4.7]
[start 1474.5] cool [Duration: 2.6]
[start 1477.799] so [Duration: 2.901]
[start 1479.179] uh [Duration: 5.761]
[start 1480.7] we have a kind of reasonably working [Duration: 6.16]
[start 1484.94] tool I think I think maybe the output [Duration: 5.06]
[start 1486.86] could use a little bit of fixing up [Duration: 6.96]
[start 1490] so I think the log of the error for [Duration: 5.02]
[start 1493.82] example [Duration: 3]
[start 1495.02] could probably [Duration: 4.74]
[start 1496.82] Santi tell us what uh [Duration: 5.46]
[start 1295.22] and that's because it's looking for [Duration: 3.36]
[start 1296.48] window.footal right and that doesn't [Duration: 5.6]
[start 1499.76] URL we were using so let's fix that fix [Duration: 4.76]
[start 1502.28] that [Duration: 2.24]
[start 1504.799] um [Duration: 2.061]
[start 1508.64] and you know let's have a quick play [Duration: 4.2]
[start 1511.28] with the tool and make sure it does [Duration: 3.899]
[start 1512.84] exactly what we want [Duration: 4.86]
[start 1515.179] so ah URLs file [Duration: 5.101]
[start 1517.7] kind of already has these payloads in [Duration: 3.359]
[start 1520.28] here [Duration: 3.56]
[start 1521.059] and we could [Duration: 5.461]
[start 1523.84] have them in there manually or we could [Duration: 7.3]
[start 1526.52] add them in with some kind of bash Magic [Duration: 5.88]
[start 1531.14] so [Duration: 3.96]
[start 1532.4] if we pretend [Duration: 4.82]
[start 1535.1] for example [Duration: 6.02]
[start 1537.22] that we only had the [Duration: 6.4]
[start 1541.12] first part of the URL without the path [Duration: 4]
[start 1543.62] or anything like that we could add it in [Duration: 5.539]
[start 1545.12] that way so we could take [Duration: 6.419]
[start 1549.159] now I have to try and remember how to [Duration: 4.301]
[start 1551.539] use my own tool [Duration: 3.901]
[start 1553.46] let's [Duration: 3.719]
[start 1555.44] have a look at the help out button for [Duration: 2.76]
[start 1557.179] unfill [Duration: 2.88]
[start 1558.2] so unfair is a tool I wrote for pulling [Duration: 4.079]
[start 1560.059] up our urls [Duration: 8.041]
[start 1562.279] so we might have the scheme which is [Duration: 7.821]
[start 1568.1] percent s [Duration: 5.939]
[start 1570.1] and then we want the domain which is [Duration: 7.24]
[start 1574.039] percent d uh and then we probably want [Duration: 6.541]
[start 1577.34] the path as well which is p so there we [Duration: 5.76]
[start 1580.58] go we've got those all stripped off [Duration: 5.4]
[start 1583.1] and then we could do something like [Duration: 4.8]
[start 1585.98] uh orc [Duration: 4.559]
[start 1587.9] print dollar one which is just the URL [Duration: 4.74]
[start 1590.539] by itself and then we could append the [Duration: 3.721]
[start 1592.64] query string that way so we could say [Duration: 3.56]
[start 1594.26] Proto [Duration: 3.6]
[start 1596.2] uh [Duration: 3.579]
[start 1597.86] let's use something other than Frugal [Duration: 4.86]
[start 1599.779] let's just use Foo is equal to bar [Duration: 5.161]
[start 1602.72] and that gives us a whole bunch of URLs [Duration: 5.52]
[start 1604.94] that have this query string appended to [Duration: 5.599]
[start 1608.24] them and then we can run that through [Duration: 5.52]
[start 1610.539] our run.js program give it some [Duration: 6.161]
[start 1613.76] JavaScript and say well we want to know [Duration: 7.08]
[start 1616.7] the value of window dot C [Duration: 7.88]
[start 1620.84] and see what happens there [Duration: 3.74]
[start 1624.679] so we have uh something I set up [Duration: 5.221]
[start 1627.08] previously here which is prototype [Duration: 6.18]
[start 1629.9] pollution example running elsewhere [Duration: 6.24]
[start 1633.26] and that's come up and said bar [Duration: 6.06]
[start 1636.14] which is you know kind of useful output [Duration: 6.06]
[start 1639.32] I suppose but we could probably do [Duration: 5.4]
[start 1642.2] something a little bit better and say [Duration: 6]
[start 1644.72] let's use a ternary operator to say if [Duration: 5.36]
[start 1648.2] window.foo exists [Duration: 5.479]
[start 1650.08] say vulnerable [Duration: 6.16]
[start 1653.679] otherwise say [Duration: 5.081]
[start 1298.58] exist because why would it [Duration: 7.14]
[start 1302.08] so what I'm going to do is say actually [Duration: 5.74]
[start 1305.72] I'll use bang to execute the shell [Duration: 4.98]
[start 1307.82] command I'll run go build [Duration: 6.12]
[start 1310.7] in the current directory and [Duration: 7.979]
[start 1313.94] I want to cut my URLs file into [Duration: 7.619]
[start 1318.679] this run.js program that we've been [Duration: 4.681]
[start 1321.559] writing so we were in a directory called [Duration: 5.521]
[start 1323.36] run.js called run JS and [Duration: 6.179]
[start 1327.08] therefore go decided that's what the [Duration: 4.8]
[start 1329.539] binary should be called so let's run [Duration: 4.02]
[start 1331.88] that and see what happens [Duration: 4.5]
[start 1333.559] so we got character undefined values on [Duration: 4.62]
[start 1336.38] one of them we got the value of food is [Duration: 3.539]
[start 1338.179] Moodle [Duration: 4.62]
[start 1339.919] um we don't know what for so let's fix [Duration: 3.721]
[start 1342.799] that [Duration: 3.301]
[start 1343.64] and instead of saying the value of [Duration: 4.2]
[start 1346.1] futile [Duration: 4.5]
[start 1347.84] let's just put in the URL that we were [Duration: 4.68]
[start 1350.6] calling instead and see what that looks [Duration: 3.18]
[start 1352.52] like [Duration: 3.42]
[start 1353.78] so we're running we expect the output to [Duration: 2.879]
[start 1355.94] be [Duration: 3.9]
[start 1356.659] uh I read the wrong thing I want to run [Duration: 5.701]
[start 1359.84] my go build command again [Duration: 4.92]
[start 1362.36] so we'll run that we calculate undefined [Duration: 6.48]
[start 1364.76] values for some of them uh and on others [Duration: 8.279]
[start 1368.84] on this one we've got this value bootle [Duration: 5.28]
[start 1373.039] so [Duration: 2.461]
[start 1374.12] that works okay [Duration: 3.84]
[start 1375.5] it's a little bit strange though to [Duration: 4.98]
[start 1377.96] always just run this window.footal I [Duration: 5.04]
[start 1380.48] wouldn't expect the user of this tool to [Duration: 4.92]
[start 1383] be able to you know guess or remember [Duration: 5.7]
[start 1385.4] that that's for some reason uh what you [Duration: 4.92]
[start 1388.7] had to do [Duration: 5.04]
[start 1390.32] so let's change this instead to be [Duration: 6.719]
[start 1393.74] some value called user.js and we're [Duration: 5.819]
[start 1397.039] going to accept that as a flag [Duration: 4.801]
[start 1399.559] so [Duration: 6.441]
[start 1401.84] we'll use the go flag package [Duration: 4.16]
[start 1406.52] and we will make a string variable and [Duration: 8.159]
[start 1411.26] let's see if I can remember the order of [Duration: 5.52]
[start 1414.679] the parameters here [Duration: 5.281]
[start 1416.78] so we're going to have our user.js [Duration: 4.92]
[start 1419.96] which is a string [Duration: 5.579]
[start 1421.7] and then a string variable of user.js [Duration: 7.44]
[start 1425.539] with a default of empty [Duration: 5.76]
[start 1429.14] I'm trying to get this right oh no first [Duration: 5.34]
[start 1431.299] comes the name so we'll make that j a [Duration: 5.821]
[start 1434.48] default of empty and then the help [Duration: 6.66]
[start 1437.12] output for is going to be the JS to run [Duration: 7.16]
[start 1441.14] on each page [Duration: 3.14]
[start 1444.86] so now if we run this [Duration: 4.799]
[start 1448.1] will tell us we haven't got the flag [Duration: 4.819]
[start 1449.659] package now we do [Duration: 3.26]
[start 1453.2] and it's going to go off and run some [Duration: 5.94]
[start 1456.44] empty JavaScript on every page but if we [Duration: 6.32]
[start 1459.14] change our Command to say let's include [Duration: 6.6]
[start 1462.76] window.futel again [Duration: 5.08]
[start 1465.74] hopefully with a little bit of look [Duration: 4.319]
[start 1467.84] we'll see one of them in there works [Duration: 4.56]
[start 1470.059] just fine which is great that's exactly [Duration: 4.441]
[start 1472.4] what we wanted [Duration: 4.7]
[start 1474.5] cool [Duration: 2.6]
[start 1477.799] so [Duration: 2.901]
[start 1479.179] uh [Duration: 5.761]
[start 1480.7] we have a kind of reasonably working [Duration: 6.16]
[start 1484.94] tool I think I think maybe the output [Duration: 5.06]
[start 1486.86] could use a little bit of fixing up [Duration: 6.96]
[start 1490] so I think the log of the error for [Duration: 5.02]
[start 1493.82] example [Duration: 3]
[start 1495.02] could probably [Duration: 4.74]
[start 1496.82] Santi tell us what uh [Duration: 5.46]
[start 1499.76] URL we were using so let's fix that fix [Duration: 4.76]
[start 1502.28] that [Duration: 2.24]
[start 1504.799] um [Duration: 2.061]
[start 1508.64] and you know let's have a quick play [Duration: 4.2]
[start 1511.28] with the tool and make sure it does [Duration: 3.899]
[start 1512.84] exactly what we want [Duration: 4.86]
[start 1515.179] so ah URLs file [Duration: 5.101]
[start 1517.7] kind of already has these payloads in [Duration: 3.359]
[start 1520.28] here [Duration: 3.56]
[start 1521.059] and we could [Duration: 5.461]
[start 1523.84] have them in there manually or we could [Duration: 7.3]
[start 1526.52] add them in with some kind of bash Magic [Duration: 5.88]
[start 1656.24] not vulnerable [Duration: 4.26]
[start 1658.76] instead and we'll see what that looks [Duration: 3.6]
[start 1660.5] like so now instead of getting that [Duration: 3.72]
[start 1662.36] error on all the ones that don't have [Duration: 3.96]
[start 1664.22] the uh [Duration: 6.059]
[start 1666.32] prototype Poland pollution issue we just [Duration: 7.32]
[start 1670.279] say not vulnerable instead [Duration: 6.481]
[start 1673.64] so that works reasonably well [Duration: 4.44]
[start 1676.76] I think we've done a fairly good job [Duration: 3.6]
[start 1678.08] there but there's still probably some [Duration: 3.9]
[start 1680.36] improvements that we can make to this [Duration: 3]
[start 1681.98] thing [Duration: 3.12]
[start 1683.36] um one thing I think is pretty common [Duration: 3.96]
[start 1685.1] across a lot of book bounty hunters [Duration: 4.8]
[start 1687.32] especially is that they like to look at [Duration: 5.099]
[start 1689.9] a lot of different targets so you know I [Duration: 5.7]
[start 1531.14] so [Duration: 3.96]
[start 1532.4] if we pretend [Duration: 4.82]
[start 1692.419] have a list of several URLs how many was [Duration: 5.941]
[start 1695.6] it seven urls [Duration: 5.459]
[start 1698.36] how often do you have several URLs you [Duration: 3.66]
[start 1535.1] for example [Duration: 6.02]
[start 1537.22] that we only had the [Duration: 6.4]
[start 1541.12] first part of the URL without the path [Duration: 4]
[start 1543.62] or anything like that we could add it in [Duration: 5.539]
[start 1545.12] that way so we could take [Duration: 6.419]
[start 1549.159] now I have to try and remember how to [Duration: 4.301]
[start 1551.539] use my own tool [Duration: 3.901]
[start 1553.46] let's [Duration: 3.719]
[start 1555.44] have a look at the help out button for [Duration: 2.76]
[start 1557.179] unfill [Duration: 2.88]
[start 1558.2] so unfair is a tool I wrote for pulling [Duration: 4.079]
[start 1560.059] up our urls [Duration: 8.041]
[start 1562.279] so we might have the scheme which is [Duration: 7.821]
[start 1568.1] percent s [Duration: 5.939]
[start 1570.1] and then we want the domain which is [Duration: 7.24]
[start 1574.039] percent d uh and then we probably want [Duration: 6.541]
[start 1577.34] the path as well which is p so there we [Duration: 5.76]
[start 1580.58] go we've got those all stripped off [Duration: 5.4]
[start 1583.1] and then we could do something like [Duration: 4.8]
[start 1585.98] uh orc [Duration: 4.559]
[start 1587.9] print dollar one which is just the URL [Duration: 4.74]
[start 1590.539] by itself and then we could append the [Duration: 3.721]
[start 1592.64] query string that way so we could say [Duration: 3.56]
[start 1594.26] Proto [Duration: 3.6]
[start 1596.2] uh [Duration: 3.579]
[start 1597.86] let's use something other than Frugal [Duration: 4.86]
[start 1701.059] want to look at you could do that [Duration: 3.24]
[start 1702.02] manually there's not really much point [Duration: 4.139]
[start 1704.299] in uh [Duration: 4.38]
[start 1706.159] you know writing a tool to check seven [Duration: 5.88]
[start 1708.679] URLs so let's add some concurrency to [Duration: 6.061]
[start 1712.039] this instead as well and hopefully maybe [Duration: 4.681]
[start 1714.74] we can check things a little bit faster [Duration: 5.28]
[start 1716.72] by introducing some parallelism [Duration: 5.16]
[start 1720.02] so [Duration: 4.5]
[start 1721.88] um the way I tend to approach adding [Duration: 4.799]
[start 1724.52] parallelism in go programs is to have [Duration: 4.62]
[start 1726.679] some kind of pool of workers [Duration: 6]
[start 1729.14] and then use a thing that go has called [Duration: 8.539]
[start 1732.679] channels to communicate the list of [Duration: 8.521]
[start 1737.679] inputs to them so let's do that and see [Duration: 5.021]
[start 1741.2] what that looks like [Duration: 5.04]
[start 1742.7] so we want to set up maybe oh let's say [Duration: 6.719]
[start 1746.24] five workers for for a concurrency level [Duration: 6.36]
[start 1749.419] of five so we'll say if I is equal to [Duration: 6.601]
[start 1752.6] zero I is less than five I plus plus go [Duration: 6.48]
[start 1756.02] only really has four Loops which is [Duration: 5.1]
[start 1759.08] actually one of the nice things about it [Duration: 4.38]
[start 1761.12] as far as I'm concerned we're going to [Duration: 4.2]
[start 1763.46] run a go routine which looks like this [Duration: 4.74]
[start 1765.32] and a go routine is a function which [Duration: 6.839]
[start 1768.2] runs asynchronously effectively [Duration: 6.24]
[start 1772.159] and what it's going to run [Duration: 5.661]
[start 1774.44] is all of this stuff [Duration: 3.38]
[start 1783.32] but it needs to get that from some kind [Duration: 6.42]
[start 1786.679] of input so let's make a channel [Duration: 6.74]
[start 1789.74] and we'll make that channel called [Duration: 5.46]
[start 1793.419] urls [Duration: 6]
[start 1795.2] so I'll make a Channel of strings [Duration: 4.219]
[start 1799.76] and then each go routine is going to [Duration: 5.7]
[start 1802.22] read from that channel so we'll say uh [Duration: 5.64]
[start 1805.46] for you [Duration: 7.079]
[start 1807.86] is equal to the range of urls [Duration: 9.439]
[start 1812.539] that's how you read on a channel and go [Duration: 4.76]
[start 1818.179] we are going to take URLs off the URLs [Duration: 6.961]
[start 1822.38] of the URLs channel uh for as long as we [Duration: 4.14]
[start 1825.14] can [Duration: 4.019]
[start 1826.52] and we are going to [Duration: 5.519]
[start 1829.159] run our headless Chrome code against [Duration: 5.52]
[start 1832.039] them we've got a couple of things to [Duration: 4.981]
[start 1834.679] clean up here though so one of which is [Duration: 4.681]
[start 1837.02] this defer cancel you know this was kind [Duration: 3.379]
[start 1839.36] of [Duration: 4.439]
[start 1840.399] fine using small volumes of URLs but if [Duration: 5.14]
[start 1843.799] you're going to be using Lots these are [Duration: 3.36]
[start 1845.539] all going to stack up until we've [Duration: 4.581]
[start 1847.159] finished at the very end so [Duration: 6.26]
[start 1850.12] we are not going to call cancel there [Duration: 6.419]
[start 1853.419] instead we are going to run it [Duration: 5.98]
[start 1856.539] let's say here [Duration: 5.201]
[start 1859.399] after we've finished doing all of the [Duration: 6.621]
[start 1861.74] things we need to do that should be fine [Duration: 4.28]
[start 1868.94] but if we try and use this well [Duration: 5.7]
[start 1872.299] uh so far we're not actually adding any [Duration: 5.401]
[start 1874.64] information to it so it'll just pretty [Duration: 4.259]
[start 1877.7] much [Duration: 3.479]
[start 1878.899] tell us you is not declared but is [Duration: 4.581]
[start 1881.179] declared and not used [Duration: 4.021]
[start 1883.48] which is [Duration: 4.36]
[start 1885.2] which one [Duration: 4.5]
[start 1887.84] oh it's this one here [Duration: 4.38]
[start 1889.7] so what we actually need to do here is [Duration: 6.12]
[start 1892.22] send this new text on our URLs channel [Duration: 6.72]
[start 1895.82] so that it gets sent to all of those [Duration: 5.339]
[start 1898.94] workers that we've just span up [Duration: 4.32]
[start 1599.779] let's just use Foo is equal to bar [Duration: 5.161]
[start 1602.72] and that gives us a whole bunch of URLs [Duration: 5.52]
[start 1604.94] that have this query string appended to [Duration: 5.599]
[start 1608.24] them and then we can run that through [Duration: 5.52]
[start 1610.539] our run.js program give it some [Duration: 6.161]
[start 1613.76] JavaScript and say well we want to know [Duration: 7.08]
[start 1616.7] the value of window dot C [Duration: 7.88]
[start 1620.84] and see what happens there [Duration: 3.74]
[start 1624.679] so we have uh something I set up [Duration: 5.221]
[start 1627.08] previously here which is prototype [Duration: 6.18]
[start 1629.9] pollution example running elsewhere [Duration: 6.24]
[start 1633.26] and that's come up and said bar [Duration: 6.06]
[start 1636.14] which is you know kind of useful output [Duration: 6.06]
[start 1639.32] I suppose but we could probably do [Duration: 5.4]
[start 1642.2] something a little bit better and say [Duration: 6]
[start 1644.72] let's use a ternary operator to say if [Duration: 5.36]
[start 1648.2] window.foo exists [Duration: 5.479]
[start 1650.08] say vulnerable [Duration: 6.16]
[start 1653.679] otherwise say [Duration: 5.081]
[start 1656.24] not vulnerable [Duration: 4.26]
[start 1658.76] instead and we'll see what that looks [Duration: 3.6]
[start 1660.5] like so now instead of getting that [Duration: 3.72]
[start 1662.36] error on all the ones that don't have [Duration: 3.96]
[start 1664.22] the uh [Duration: 6.059]
[start 1666.32] prototype Poland pollution issue we just [Duration: 7.32]
[start 1670.279] say not vulnerable instead [Duration: 6.481]
[start 1673.64] so that works reasonably well [Duration: 4.44]
[start 1676.76] I think we've done a fairly good job [Duration: 3.6]
[start 1678.08] there but there's still probably some [Duration: 3.9]
[start 1680.36] improvements that we can make to this [Duration: 3]
[start 1681.98] thing [Duration: 3.12]
[start 1683.36] um one thing I think is pretty common [Duration: 3.96]
[start 1685.1] across a lot of book bounty hunters [Duration: 4.8]
[start 1687.32] especially is that they like to look at [Duration: 5.099]
[start 1689.9] a lot of different targets so you know I [Duration: 5.7]
[start 1692.419] have a list of several URLs how many was [Duration: 5.941]
[start 1695.6] it seven urls [Duration: 5.459]
[start 1698.36] how often do you have several URLs you [Duration: 3.66]
[start 1701.059] want to look at you could do that [Duration: 3.24]
[start 1702.02] manually there's not really much point [Duration: 4.139]
[start 1704.299] in uh [Duration: 4.38]
[start 1706.159] you know writing a tool to check seven [Duration: 5.88]
[start 1708.679] URLs so let's add some concurrency to [Duration: 6.061]
[start 1712.039] this instead as well and hopefully maybe [Duration: 4.681]
[start 1714.74] we can check things a little bit faster [Duration: 5.28]
[start 1716.72] by introducing some parallelism [Duration: 5.16]
[start 1720.02] so [Duration: 4.5]
[start 1721.88] um the way I tend to approach adding [Duration: 4.799]
[start 1724.52] parallelism in go programs is to have [Duration: 4.62]
[start 1726.679] some kind of pool of workers [Duration: 6]
[start 1729.14] and then use a thing that go has called [Duration: 8.539]
[start 1732.679] channels to communicate the list of [Duration: 8.521]
[start 1737.679] inputs to them so let's do that and see [Duration: 5.021]
[start 1741.2] what that looks like [Duration: 5.04]
[start 1742.7] so we want to set up maybe oh let's say [Duration: 6.719]
[start 1746.24] five workers for for a concurrency level [Duration: 6.36]
[start 1749.419] of five so we'll say if I is equal to [Duration: 6.601]
[start 1752.6] zero I is less than five I plus plus go [Duration: 6.48]
[start 1756.02] only really has four Loops which is [Duration: 5.1]
[start 1759.08] actually one of the nice things about it [Duration: 4.38]
[start 1761.12] as far as I'm concerned we're going to [Duration: 4.2]
[start 1763.46] run a go routine which looks like this [Duration: 4.74]
[start 1765.32] and a go routine is a function which [Duration: 6.839]
[start 1768.2] runs asynchronously effectively [Duration: 6.24]
[start 1772.159] and what it's going to run [Duration: 5.661]
[start 1774.44] is all of this stuff [Duration: 3.38]
[start 1783.32] but it needs to get that from some kind [Duration: 6.42]
[start 1901.159] so let's give that a go instead see how [Duration: 3.781]
[start 1903.26] that works [Duration: 4.139]
[start 1904.94] oh [Duration: 4.8]
[start 1907.399] kind of worked so we've got you know [Duration: 4.26]
[start 1786.679] of input so let's make a channel [Duration: 6.74]
[start 1789.74] and we'll make that channel called [Duration: 5.46]
[start 1793.419] urls [Duration: 6]
[start 1795.2] so I'll make a Channel of strings [Duration: 4.219]
[start 1799.76] and then each go routine is going to [Duration: 5.7]
[start 1802.22] read from that channel so we'll say uh [Duration: 5.64]
[start 1805.46] for you [Duration: 7.079]
[start 1807.86] is equal to the range of urls [Duration: 9.439]
[start 1812.539] that's how you read on a channel and go [Duration: 4.76]
[start 1818.179] we are going to take URLs off the URLs [Duration: 6.961]
[start 1822.38] of the URLs channel uh for as long as we [Duration: 4.14]
[start 1825.14] can [Duration: 4.019]
[start 1826.52] and we are going to [Duration: 5.519]
[start 1829.159] run our headless Chrome code against [Duration: 5.52]
[start 1832.039] them we've got a couple of things to [Duration: 4.981]
[start 1834.679] clean up here though so one of which is [Duration: 4.681]
[start 1837.02] this defer cancel you know this was kind [Duration: 3.379]
[start 1839.36] of [Duration: 4.439]
[start 1840.399] fine using small volumes of URLs but if [Duration: 5.14]
[start 1843.799] you're going to be using Lots these are [Duration: 3.36]
[start 1845.539] all going to stack up until we've [Duration: 4.581]
[start 1847.159] finished at the very end so [Duration: 6.26]
[start 1850.12] we are not going to call cancel there [Duration: 6.419]
[start 1853.419] instead we are going to run it [Duration: 5.98]
[start 1856.539] let's say here [Duration: 5.201]
[start 1859.399] after we've finished doing all of the [Duration: 6.621]
[start 1861.74] things we need to do that should be fine [Duration: 4.28]
[start 1868.94] but if we try and use this well [Duration: 5.7]
[start 1872.299] uh so far we're not actually adding any [Duration: 5.401]
[start 1874.64] information to it so it'll just pretty [Duration: 4.259]
[start 1877.7] much [Duration: 3.479]
[start 1878.899] tell us you is not declared but is [Duration: 4.581]
[start 1881.179] declared and not used [Duration: 4.021]
[start 1883.48] which is [Duration: 4.36]
[start 1885.2] which one [Duration: 4.5]
[start 1887.84] oh it's this one here [Duration: 4.38]
[start 1889.7] so what we actually need to do here is [Duration: 6.12]
[start 1892.22] send this new text on our URLs channel [Duration: 6.72]
[start 1895.82] so that it gets sent to all of those [Duration: 5.339]
[start 1909.74] encountered and undefined value that's [Duration: 4.5]
[start 1911.659] fine that's just because we're you know [Duration: 4.441]
[start 1914.24] that's exactly what we're doing and on [Duration: 3.9]
[start 1916.1] these Pages there isn't one but more [Duration: 3.299]
[start 1918.14] worryingly [Duration: 3.539]
[start 1919.399] we only saw two of these [Duration: 4.26]
[start 1921.679] uh before [Duration: 5.341]
[start 1923.659] and stopped working so let's try again [Duration: 5.581]
[start 1927.02] and we only got two of them again so you [Duration: 4.86]
[start 1929.24] know what gives [Duration: 3.419]
[start 1931.88] um [Duration: 3.539]
[start 1932.659] and the answer is you know we're [Duration: 5.221]
[start 1935.419] creating a pool of workers [Duration: 5.821]
[start 1937.88] reading from this channel of data [Duration: 7.5]
[start 1941.24] and then we are writing all of our input [Duration: 6]
[start 1945.38] onto that channel so that they receive [Duration: 3.36]
[start 1947.24] it that's fine [Duration: 3.48]
[start 1948.74] but as soon as we've done writing it we [Duration: 3.84]
[start 1950.72] hit the end of our main function [Duration: 4.86]
[start 1952.58] and we stop go doesn't automatically [Duration: 6.959]
[start 1955.58] wait for your work to be finished uh [Duration: 5.94]
[start 1959.539] because it's perfectly legitimate that [Duration: 4.701]
[start 1961.52] you wouldn't want that to be the case [Duration: 4.8]
[start 1964.24] but we can use a thing called a weight [Duration: 6.22]
[start 1966.32] group to coordinate our worker pool and [Duration: 5.94]
[start 1970.46] wait until they've all finished doing [Duration: 4.74]
[start 1972.26] their thing before we stop so let's give [Duration: 4.799]
[start 1975.2] that a go [Duration: 4.14]
[start 1977.059] so somewhere around [Duration: 4.98]
[start 1979.34] yeah probably maybe after we maybe just [Duration: 6.48]
[start 1982.039] before we make our uh Channel a view for [Duration: 6.12]
[start 1985.82] URLs we're going to make a variable [Duration: 4.92]
[start 1988.159] called WG and that's going to be [Duration: 4.981]
[start 1990.74] something from the sync.weight group [Duration: 4.559]
[start 1993.14] package [Duration: 4.139]
[start 1995.299] and every time we launch a go routine [Duration: 6.421]
[start 1997.279] we're called WG dot pad1 to say we're [Duration: 7.201]
[start 2001.72] adding one thing to this weight group [Duration: 5.819]
[start 1898.94] workers that we've just span up [Duration: 4.32]
[start 1901.159] so let's give that a go instead see how [Duration: 3.781]
[start 2004.48] so what a weight group does is you add [Duration: 5.76]
[start 2007.539] tasks to it or effectively just sort of [Duration: 6.24]
[start 2010.24] placeholders to say I am doing something [Duration: 6.6]
[start 2013.779] and then when you're done so when the [Duration: 4.921]
[start 2016.84] channel is closed [Duration: 6.12]
[start 2018.7] uh we can call weight group dot done [Duration: 7.56]
[start 2022.96] in each go routine [Duration: 6]
[start 2026.26] so what that does is when we create the [Duration: 4.2]
[start 2028.96] go routines we add one to the weight [Duration: 2.88]
[start 2030.46] group [Duration: 5.099]
[start 2031.84] we create the go routine which will read [Duration: 6.78]
[start 2035.559] input from the URLs Channel until the [Duration: 4.921]
[start 2038.62] channel is closed that's the behavior of [Duration: 2.82]
[start 2040.48] range [Duration: 3.12]
[start 2041.44] and then when that's closed we'll call [Duration: 4.2]
[start 2043.6] weight group dot done and that [Duration: 3.72]
[start 2045.64] effectively subtracts one from the [Duration: 2.94]
[start 2047.32] weight group [Duration: 3.059]
[start 2048.58] and then down here right at the end of [Duration: 3.36]
[start 2050.379] our program [Duration: 5.46]
[start 2051.94] we can call WG dot weight and that's [Duration: 5.959]
[start 2055.839] going to sit there and block until [Duration: 4.161]
[start 2057.899] hopefully at least [Duration: 4.901]
[start 2060] all of our go routines are finished so [Duration: 6.159]
[start 2062.8] let's give that a go and see how it does [Duration: 5.52]
[start 2066.159] so [Duration: 4.321]
[start 2068.32] looks like things worked so we have a [Duration: 5.64]
[start 2070.48] bootle value for this one the rest of [Duration: 4.859]
[start 2073.96] them you know we encountered an [Duration: 4.439]
[start 2075.339] undefined error we can quit out of this [Duration: 5.461]
[start 2078.399] and run our previous command and give it [Duration: 3.361]
[start 2080.8] a go [Duration: 3.599]
[start 2081.76] and hopefully you can see things happen [Duration: 4.919]
[start 2084.399] a little bit faster now [Duration: 3.78]
[start 2086.679] uh [Duration: 3.781]
[start 2088.179] which is pretty good I think that's [Duration: 5.761]
[start 2090.46] something that we would want from a more [Duration: 5.699]
[start 2093.94] concurrent program [Duration: 5.28]
[start 2096.159] so uh hopefully this gives you a bit of [Duration: 6.421]
[start 2099.22] an idea of uh firstly what prototype [Duration: 6]
[start 2102.58] pollution is but also how I might [Duration: 6.72]
[start 2105.22] approach writing a small tool in go or [Duration: 6.48]
[start 2109.3] you know the principles apply to nearly [Duration: 4.68]
[start 2111.7] any language I think the important parts [Duration: 6]
[start 2113.98] for me are have a problem to solve [Duration: 6.72]
[start 2117.7] um but as you are working [Duration: 7.44]
[start 2120.7] move from a small working program in [Duration: 8.04]
[start 2125.14] small steps to your eventual working and [Duration: 6.959]
[start 2128.74] potentially complex program instead and [Duration: 5.4]
[start 2132.099] also you know where there's very little [Duration: 5.281]
[start 2134.14] overhead to doing so [Duration: 7.08]
[start 2137.38] it would be a really good idea to make a [Duration: 6.6]
[start 2141.22] tool more generally useful [Duration: 5.58]
[start 2143.98] so to give you an idea of what I mean [Duration: 6]
[start 2146.8] if I take my list of URLs I can run [Duration: 5.42]
[start 2149.98] through this run.js program [Duration: 6.359]
[start 2152.22] and let's say I wanted to know about [Duration: 7.18]
[start 2156.339] uh the [Duration: 5.341]
[start 2159.4] oh what's a good example any cookies [Duration: 6.6]
[start 2161.68] that were set so document.cookie [Duration: 6.659]
[start 2166] so I can run this [Duration: 5.06]
[start 2168.339] and I can see that on [Duration: 6.301]
[start 1903.26] that works [Duration: 4.139]
[start 1904.94] oh [Duration: 4.8]
[start 1907.399] kind of worked so we've got you know [Duration: 4.26]
[start 1909.74] encountered and undefined value that's [Duration: 4.5]
[start 1911.659] fine that's just because we're you know [Duration: 4.441]
[start 1914.24] that's exactly what we're doing and on [Duration: 3.9]
[start 1916.1] these Pages there isn't one but more [Duration: 3.299]
[start 1918.14] worryingly [Duration: 3.539]
[start 1919.399] we only saw two of these [Duration: 4.26]
[start 1921.679] uh before [Duration: 5.341]
[start 1923.659] and stopped working so let's try again [Duration: 5.581]
[start 1927.02] and we only got two of them again so you [Duration: 4.86]
[start 1929.24] know what gives [Duration: 3.419]
[start 1931.88] um [Duration: 3.539]
[start 1932.659] and the answer is you know we're [Duration: 5.221]
[start 1935.419] creating a pool of workers [Duration: 5.821]
[start 1937.88] reading from this channel of data [Duration: 7.5]
[start 1941.24] and then we are writing all of our input [Duration: 6]
[start 1945.38] onto that channel so that they receive [Duration: 3.36]
[start 1947.24] it that's fine [Duration: 3.48]
[start 1948.74] but as soon as we've done writing it we [Duration: 3.84]
[start 1950.72] hit the end of our main function [Duration: 4.86]
[start 1952.58] and we stop go doesn't automatically [Duration: 6.959]
[start 1955.58] wait for your work to be finished uh [Duration: 5.94]
[start 1959.539] because it's perfectly legitimate that [Duration: 4.701]
[start 1961.52] you wouldn't want that to be the case [Duration: 4.8]
[start 1964.24] but we can use a thing called a weight [Duration: 6.22]
[start 1966.32] group to coordinate our worker pool and [Duration: 5.94]
[start 1970.46] wait until they've all finished doing [Duration: 4.74]
[start 1972.26] their thing before we stop so let's give [Duration: 4.799]
[start 1975.2] that a go [Duration: 4.14]
[start 1977.059] so somewhere around [Duration: 4.98]
[start 1979.34] yeah probably maybe after we maybe just [Duration: 6.48]
[start 1982.039] before we make our uh Channel a view for [Duration: 6.12]
[start 1985.82] URLs we're going to make a variable [Duration: 4.92]
[start 1988.159] called WG and that's going to be [Duration: 4.981]
[start 1990.74] something from the sync.weight group [Duration: 4.559]
[start 1993.14] package [Duration: 4.139]
[start 1995.299] and every time we launch a go routine [Duration: 6.421]
[start 1997.279] we're called WG dot pad1 to say we're [Duration: 7.201]
[start 2001.72] adding one thing to this weight group [Duration: 5.819]
[start 2004.48] so what a weight group does is you add [Duration: 5.76]
[start 2007.539] tasks to it or effectively just sort of [Duration: 6.24]
[start 2010.24] placeholders to say I am doing something [Duration: 6.6]
[start 2013.779] and then when you're done so when the [Duration: 4.921]
[start 2016.84] channel is closed [Duration: 6.12]
[start 2018.7] uh we can call weight group dot done [Duration: 7.56]
[start 2022.96] in each go routine [Duration: 6]
[start 2026.26] so what that does is when we create the [Duration: 4.2]
[start 2028.96] go routines we add one to the weight [Duration: 2.88]
[start 2030.46] group [Duration: 5.099]
[start 2031.84] we create the go routine which will read [Duration: 6.78]
[start 2035.559] input from the URLs Channel until the [Duration: 4.921]
[start 2038.62] channel is closed that's the behavior of [Duration: 2.82]
[start 2040.48] range [Duration: 3.12]
[start 2041.44] and then when that's closed we'll call [Duration: 4.2]
[start 2043.6] weight group dot done and that [Duration: 3.72]
[start 2045.64] effectively subtracts one from the [Duration: 2.94]
[start 2047.32] weight group [Duration: 3.059]
[start 2048.58] and then down here right at the end of [Duration: 3.36]
[start 2050.379] our program [Duration: 5.46]
[start 2051.94] we can call WG dot weight and that's [Duration: 5.959]
[start 2055.839] going to sit there and block until [Duration: 4.161]
[start 2057.899] hopefully at least [Duration: 4.901]
[start 2060] all of our go routines are finished so [Duration: 6.159]
[start 2062.8] let's give that a go and see how it does [Duration: 5.52]
[start 2066.159] so [Duration: 4.321]
[start 2068.32] looks like things worked so we have a [Duration: 5.64]
[start 2070.48] bootle value for this one the rest of [Duration: 4.859]
[start 2073.96] them you know we encountered an [Duration: 4.439]
[start 2075.339] undefined error we can quit out of this [Duration: 5.461]
[start 2078.399] and run our previous command and give it [Duration: 3.361]
[start 2080.8] a go [Duration: 3.599]
[start 2081.76] and hopefully you can see things happen [Duration: 4.919]
[start 2084.399] a little bit faster now [Duration: 3.78]
[start 2086.679] uh [Duration: 3.781]
[start 2088.179] which is pretty good I think that's [Duration: 5.761]
[start 2090.46] something that we would want from a more [Duration: 5.699]
[start 2093.94] concurrent program [Duration: 5.28]
[start 2096.159] so uh hopefully this gives you a bit of [Duration: 6.421]
[start 2099.22] an idea of uh firstly what prototype [Duration: 6]
[start 2102.58] pollution is but also how I might [Duration: 6.72]
[start 2105.22] approach writing a small tool in go or [Duration: 6.48]
[start 2109.3] you know the principles apply to nearly [Duration: 4.68]
[start 2111.7] any language I think the important parts [Duration: 6]
[start 2113.98] for me are have a problem to solve [Duration: 6.72]
[start 2117.7] um but as you are working [Duration: 7.44]
[start 2120.7] move from a small working program in [Duration: 8.04]
[start 2125.14] small steps to your eventual working and [Duration: 6.959]
[start 2171.06] time.com and not being able to say your [Duration: 6.039]
[start 2174.64] own nicknames pretty bad uh there's [Duration: 5.939]
[start 2177.099] these utma and utmc cookies being set [Duration: 5.701]
[start 2180.579] and on the other ones there isn't really [Duration: 4.02]
[start 2182.8] anything [Duration: 4.74]
[start 2184.599] uh or maybe [Duration: 6.541]
[start 2187.54] we might want to look for [Duration: 7.26]
[start 2191.14] uh links that are in the page so we [Duration: 5.36]
[start 2194.8] might say [Duration: 5.88]
[start 2196.5] document dot get elements [Duration: 7.18]
[start 2200.68] by tag name [Duration: 6.84]
[start 2203.68] and have the uh a tag [Duration: 6.419]
[start 2207.52] and we will use the spread operator to [Duration: 5.52]
[start 2210.099] turn these into an array so we can use a [Duration: 6.601]
[start 2213.04] map operator on them take each node and [Duration: 7.2]
[start 2216.7] get the href value of it and then join [Duration: 5.76]
[start 2220.24] them together with a space [Duration: 4.08]
[start 2222.46] for example [Duration: 3.48]
[start 2224.32] seen some single quotes in there that [Duration: 2.7]
[start 2225.94] are probably going to mess with us I'll [Duration: 2.84]
[start 2227.02] change them to double quotes [Duration: 4.559]
[start 2228.78] and there you go you know the output's [Duration: 4.36]
[start 2231.579] not super pretty [Duration: 3.121]
[start 2233.14] but you can see it's working we're [Duration: 2.58]
[start 2234.7] getting the [Duration: 4.1]
[start 2235.72] href values from each page so [Duration: 7.26]
[start 2238.8] httb bin.org seems to have the most of [Duration: 5.38]
[start 2128.74] potentially complex program instead and [Duration: 5.4]
[start 2132.099] also you know where there's very little [Duration: 5.281]
[start 2134.14] overhead to doing so [Duration: 7.08]
[start 2137.38] it would be a really good idea to make a [Duration: 6.6]
[start 2141.22] tool more generally useful [Duration: 5.58]
[start 2143.98] so to give you an idea of what I mean [Duration: 6]
[start 2146.8] if I take my list of URLs I can run [Duration: 5.42]
[start 2149.98] through this run.js program [Duration: 6.359]
[start 2152.22] and let's say I wanted to know about [Duration: 7.18]
[start 2156.339] uh the [Duration: 5.341]
[start 2159.4] oh what's a good example any cookies [Duration: 6.6]
[start 2161.68] that were set so document.cookie [Duration: 6.659]
[start 2166] so I can run this [Duration: 5.06]
[start 2168.339] and I can see that on [Duration: 6.301]
[start 2171.06] time.com and not being able to say your [Duration: 6.039]
[start 2174.64] own nicknames pretty bad uh there's [Duration: 5.939]
[start 2177.099] these utma and utmc cookies being set [Duration: 5.701]
[start 2180.579] and on the other ones there isn't really [Duration: 4.02]
[start 2182.8] anything [Duration: 4.74]
[start 2184.599] uh or maybe [Duration: 6.541]
[start 2187.54] we might want to look for [Duration: 7.26]
[start 2191.14] uh links that are in the page so we [Duration: 5.36]
[start 2194.8] might say [Duration: 5.88]
[start 2196.5] document dot get elements [Duration: 7.18]
[start 2200.68] by tag name [Duration: 6.84]
[start 2203.68] and have the uh a tag [Duration: 6.419]
[start 2207.52] and we will use the spread operator to [Duration: 5.52]
[start 2210.099] turn these into an array so we can use a [Duration: 6.601]
[start 2213.04] map operator on them take each node and [Duration: 7.2]
[start 2216.7] get the href value of it and then join [Duration: 5.76]
[start 2220.24] them together with a space [Duration: 4.08]
[start 2222.46] for example [Duration: 3.48]
[start 2224.32] seen some single quotes in there that [Duration: 2.7]
[start 2225.94] are probably going to mess with us I'll [Duration: 2.84]
[start 2227.02] change them to double quotes [Duration: 4.559]
[start 2228.78] and there you go you know the output's [Duration: 4.36]
[start 2231.579] not super pretty [Duration: 3.121]
[start 2242.98] them in there [Duration: 5.42]
[start 2244.18] including a mail to Mia Kenneth [Duration: 7.38]
[start 2248.4] so you know we set out to make a tool [Duration: 7.42]
[start 2251.56] for Prototype pollution but actually we [Duration: 6.12]
[start 2255.82] ended up writing something that was more [Duration: 4.92]
[start 2257.68] generally applicable so I hope that was [Duration: 5.28]
[start 2260.74] useful for you uh I hope you attempted [Duration: 4.98]
[start 2262.96] to go off and write your own tools I [Duration: 4.8]
[start 2265.72] think with a little bit of practice you [Duration: 4.2]
[start 2267.76] can get quite fast at it I know there's [Duration: 4.56]
[start 2269.92] a real temptation to think I'm going to [Duration: 5.159]
[start 2272.32] spend more time automating things than I [Duration: 5.16]
[start 2275.079] am just you know doing some hacking or [Duration: 4.141]
[start 2277.48] just doing the task in the first place [Duration: 4.139]
[start 2279.22] but you know within a matter of 20 [Duration: 4.8]
[start 2281.619] minutes or so it really is genuinely [Duration: 5.341]
[start 2284.02] possible to write actually useful tools [Duration: 5.599]
[start 2286.96] thanks [Duration: 2.659]
[start 2233.14] but you can see it's working we're [Duration: 2.58]
[start 2234.7] getting the [Duration: 4.1]
[start 2235.72] href values from each page so [Duration: 7.26]
[start 2238.8] httb bin.org seems to have the most of [Duration: 5.38]
[start 2242.98] them in there [Duration: 5.42]
[start 2244.18] including a mail to Mia Kenneth [Duration: 7.38]
[start 2248.4] so you know we set out to make a tool [Duration: 7.42]
[start 2251.56] for Prototype pollution but actually we [Duration: 6.12]
[start 2255.82] ended up writing something that was more [Duration: 4.92]
[start 2257.68] generally applicable so I hope that was [Duration: 5.28]
[start 2260.74] useful for you uh I hope you attempted [Duration: 4.98]
[start 2262.96] to go off and write your own tools I [Duration: 4.8]
[start 2265.72] think with a little bit of practice you [Duration: 4.2]
[start 2267.76] can get quite fast at it I know there's [Duration: 4.56]
[start 2269.92] a real temptation to think I'm going to [Duration: 5.159]
[start 2272.32] spend more time automating things than I [Duration: 5.16]
[start 2275.079] am just you know doing some hacking or [Duration: 4.141]
[start 2277.48] just doing the task in the first place [Duration: 4.139]
[start 2279.22] but you know within a matter of 20 [Duration: 4.8]
[start 2281.619] minutes or so it really is genuinely [Duration: 5.341]
[start 2284.02] possible to write actually useful tools [Duration: 5.599]
[start 2286.96] thanks [Duration: 2.659]
 in the get_the_subtitles func
time taken in userKey decoding is -> 86  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 71994.438041 sec
in the auto generated track
formatting the transctipt.subtitles.text to be utf-8
[start 0.399] hello guys and welcome back to newbie on [Duration: 3.52]
[start 2.56] this channel i'm sobbie from call [Duration: 4.48]
[start 3.919] revolution so these days i worked on [Duration: 5.76]
[start 7.04] updates for headless browser api and i [Duration: 5.04]
[start 9.679] added three very important features to [Duration: 5.761]
[start 12.08] them so one will be the [Duration: 6.48]
[start 15.44] feature that it is much needed so the [Duration: 6.88]
[start 18.56] stealth module so headless browser api [Duration: 6.24]
[start 22.32] will act as a normal browser starting [Duration: 5.68]
[start 24.8] from now and websites will not be able [Duration: 6.559]
[start 28] to detect that it is actually a headless [Duration: 5.36]
[start 31.359] browser and [Duration: 4.961]
[start 33.36] it might scrape them so because of this [Duration: 5.359]
[start 36.32] they will not show any captures they [Duration: 5.36]
[start 38.719] will not block scraping and they will [Duration: 4.241]
[start 41.68] not act [Duration: 2.879]
[start 42.96] against [Duration: 4]
[start 44.559] accessing their resources so headless [Duration: 5.84]
[start 46.96] browser api got this update the don't [Duration: 6.8]
[start 50.399] get blocked update anti-bot detection [Duration: 7.361]
[start 53.76] and bypassing build into the api and you [Duration: 5.119]
[start 57.76] will not [Duration: 3.599]
[start 58.879] need to worry anymore for requests being [Duration: 3.601]
[start 61.359] blocked [Duration: 5.921]
[start 62.48] so let me show you this feature in the [Duration: 7.679]
[start 67.28] plugin and the chromatic plugin which [Duration: 6.24]
[start 70.159] uses headless browser api [Duration: 6.881]
[start 73.52] and let me show you this website that i [Duration: 6.32]
[start 77.04] found and i tested this feature on this [Duration: 3.84]
[start 79.84] website [Duration: 5.36]
[start 80.88] so it's auto inevitable dot com slash [Duration: 7.76]
[start 85.2] bots and here on the bottom if you are [Duration: 5.04]
[start 88.64] using a [Duration: 5.119]
[start 90.24] browser you will see many green things [Duration: 7.04]
[start 93.759] and uh on chrome 100 for some reason [Duration: 7.36]
[start 97.28] this is red because of uh they [Duration: 6.24]
[start 101.119] forgot to add the web driver however [Duration: 4.481]
[start 103.52] this should be green if you check this [Duration: 4.4]
[start 105.6] page on firefox you will see that [Duration: 5.12]
[start 107.92] everything is green so this is a normal [Duration: 6.32]
[start 110.72] browser behavior every test here is [Duration: 5.12]
[start 114.24] green [Duration: 5.199]
[start 115.84] so let me check this in the chromatic [Duration: 5.76]
[start 119.439] plugin and let me use headless browser [Duration: 4.161]
[start 121.6] api to [Duration: 4.72]
[start 123.6] test it so first of all let's use the [Duration: 5.84]
[start 126.32] default wordpress scraping method and [Duration: 6.639]
[start 129.44] check this website i will use the [Duration: 5.84]
[start 132.959] visual selector to visualize the content [Duration: 4.801]
[start 135.28] so using wordpress scraping [Duration: 4.48]
[start 137.76] as you can see the [Duration: 6.24]
[start 139.76] javascript is not executed and the parts [Duration: 6.8]
[start 144] of the test we are not seeing those [Duration: 6.56]
[start 146.56] parts now let's go ahead and jump to [Duration: 5.36]
[start 150.56] using [Duration: 3.84]
[start 151.92] puppeteer which is installed on my [Duration: 4.8]
[start 154.4] server which is not headless browser api [Duration: 5.36]
[start 156.72] but local puppeteer installed on my [Duration: 7.28]
[start 159.76] server and if we use [Duration: 7.28]
[start 164] the local puppeteer [Duration: 5.519]
[start 167.04] to visualize the website [Duration: 4.4]
[start 169.519] so keep in mind this is not headless [Duration: 4.241]
[start 171.44] browser api it is a local puppeteer [Duration: 5.519]
[start 173.76] installed on my local server we will see [Duration: 4.08]
[start 176.959] three [Duration: 3.681]
[start 177.84] things red so puppeteer failed these [Duration: 5.44]
[start 180.64] three tests this was the headless [Duration: 5.599]
[start 183.28] browser api result also before the [Duration: 5.679]
[start 186.239] updates that i made just now [Duration: 3.521]
[start 188.959] so [Duration: 3.92]
[start 189.76] and now let me check also with headless [Duration: 5.44]
[start 192.879] browser api puppeteer [Duration: 5.681]
[start 195.2] which will be [Duration: 4.16]
[start 198.56] uh [Duration: 3.2]
[start 199.36] the results so i hope everything will be [Duration: 4.879]
[start 201.76] great so let's check headless browser [Duration: 6.32]
[start 204.239] api puppeteer and this is the result and [Duration: 7.28]
[start 208.08] if we scroll down everything is green [Duration: 6.48]
[start 211.519] exactly like in firefox [Duration: 6.881]
[start 214.56] or so this is better than chrome 100 so [Duration: 4.72]
[start 218.4] the [Duration: 3.6]
[start 219.28] web driver test is not failing [Duration: 5.44]
[start 222] unlike on chrome 100 [Duration: 3.84]
[start 224.72] or [Duration: 2.32]
[start 225.84] let me [Duration: 5.28]
[start 227.04] show you how the built-in tor module is [Duration: 7.919]
[start 231.12] returning even more red parts [Duration: 5.039]
[start 234.959] because [Duration: 5.36]
[start 236.159] the tor module which is built in is even [Duration: 7.601]
[start 240.319] uh considered even dirtier however the [Duration: 6.161]
[start 243.76] headless browser api tour you will see [Duration: 4.399]
[start 246.48] that is [Duration: 4.08]
[start 248.159] green so this is the built-in tour [Duration: 4.72]
[start 250.56] module which is installed on my server [Duration: 4.48]
[start 252.879] so if you install tor on your server you [Duration: 3.441]
[start 255.04] will see that [Duration: 3.52]
[start 256.32] there will be some [Duration: 5.439]
[start 258.56] uh possibilities that the websites will [Duration: 5.84]
[start 261.759] detect that you are actually using [Duration: 6.241]
[start 264.4] uh headless browser but if you use store [Duration: 6.56]
[start 268] on headless browser api [Duration: 5.919]
[start 270.96] we will see that we should get full [Duration: 5.679]
[start 273.919] green results [Duration: 6.081]
[start 276.639] so this is the first major update i made [Duration: 6.161]
[start 280] for headless browser api and as you can [Duration: 6.24]
[start 282.8] see tor also is full green [Duration: 6]
[start 286.24] in the headless browser tests on this [Duration: 3.679]
[start 288.8] website [Duration: 2.32]
[start 289.919] okay [Duration: 4.241]
[start 291.12] so now let me show you the second [Duration: 5.76]
[start 294.16] feature is [Duration: 5.12]
[start 296.88] that the api will be able to [Duration: 5.68]
[start 299.28] automatically solve also captures [Duration: 4.479]
[start 302.56] that are [Duration: 3.359]
[start 303.759] on the page or which might be on the [Duration: 5.041]
[start 305.919] page so if the page is protected by a [Duration: 5.681]
[start 308.8] captcha you can use the automatic [Duration: 4.8]
[start 311.6] capture solving feature [Duration: 4.8]
[start 313.6] in headless browser api that will solve [Duration: 5.599]
[start 316.4] the capture to enable this [Duration: 6.44]
[start 319.199] in the latest plugin versions of [Duration: 7.84]
[start 322.84] chromatic you will find the [Duration: 7.639]
[start 327.039] this headless browser api enable capture [Duration: 5.761]
[start 330.479] solving checkbox if you check this [Duration: 4.16]
[start 332.8] checkbox and you use [Duration: 4.72]
[start 334.639] the puppeteer or tor [Duration: 6]
[start 337.52] modules of headless browser api it will [Duration: 7.04]
[start 340.639] be uh with capture solving enabled so [Duration: 6.641]
[start 344.56] this feature is only for puppeteer and [Duration: 3.6]
[start 347.28] tor [Duration: 3.44]
[start 348.16] for capture sorting in headless browser [Duration: 5.12]
[start 350.72] api [Duration: 5.44]
[start 353.28] now let me go ahead and tell you also [Duration: 5.52]
[start 356.16] about the third feature which will be [Duration: 6.319]
[start 358.8] adblock so headless browser api got a [Duration: 6.88]
[start 362.479] new update or so to block automatically [Duration: 6]
[start 365.68] ads which might appear in the content so [Duration: 5.44]
[start 368.479] simply check this checkbox and use the [Duration: 5.44]
[start 371.12] puppeteer or tor endpoints of headless [Duration: 5.44]
[start 373.919] browser api and you will be able to [Duration: 5.201]
[start 376.56] block ads that appear in the script [Duration: 5.84]
[start 379.12] content automatically exactly like you [Duration: 7.12]
[start 382.4] would use an ad block on chrome or on [Duration: 5.12]
[start 386.24] firefox [Duration: 2.64]
[start 387.52] okay so [Duration: 3.76]
[start 388.88] let me show you also the documentation [Duration: 4.319]
[start 391.28] of these new features which will be [Duration: 5.039]
[start 393.199] found on headless browser api.com [Duration: 5.041]
[start 396.319] documentation which is also linked in [Duration: 3.6]
[start 398.24] this video's description [Duration: 4.399]
[start 399.919] so this new features will be enabled [Duration: 6.641]
[start 402.639] with these arguments for the api course [Duration: 5.201]
[start 406.56] this is [Duration: 3.759]
[start 407.84] required only if you create your own [Duration: 4.96]
[start 410.319] tools which use headless browser api if [Duration: 4.88]
[start 412.8] you use the plugins that i created which [Duration: 4.56]
[start 415.199] automatically implement headless browser [Duration: 4.961]
[start 417.36] api you will not need to mess with these [Duration: 5.52]
[start 420.16] parameters so solve capture [Duration: 6.08]
[start 422.88] and enable ad block this can be set to [Duration: 6.48]
[start 426.24] one or on [Duration: 3.12]
[start 429.599] so on [Duration: 4.641]
[start 431.599] this is the value which will enable [Duration: 5.841]
[start 434.24] these features also note that if you use [Duration: 6.56]
[start 437.44] the solve capture feature in a uh add [Duration: 4.24]
[start 440.8] the [Duration: 4.239]
[start 441.68] to the waiting time that you [Duration: 7.2]
[start 445.039] wait after the results from the scraping [Duration: 5.401]
[start 448.88] at least [Duration: 5.599]
[start 450.44] 120 seconds because capture solving [Duration: 7.96]
[start 454.479] is a bit lengthy process and can take [Duration: 7.681]
[start 458.4] up to 120 seconds to complete so keep [Duration: 5.28]
[start 462.16] note of this [Duration: 4.479]
[start 463.68] okay so yeah this is all for today i [Duration: 4.88]
[start 466.639] hope you enjoyed these new features as [Duration: 4.4]
[start 468.56] hi of headless browser api it is linked [Duration: 4.079]
[start 471.039] in this video's description also you [Duration: 3.681]
[start 472.639] will find crawl-o-matic there [Duration: 3.28]
[start 474.72] and yeah [Duration: 2.8]
[start 475.919] until next time subscribe to this [Duration: 3.601]
[start 477.52] channel if you enjoyed this content have [Duration: 6.2]
[start 479.52] a nice day bye bye [Duration: 4.2]

 string value is this --> hello guys and welcome back to newbie on this channel i'm sobbie from call revolution so these days i worked on updates for headless browser api and i added three very important features to them so one will be the feature that it is much needed so the stealth module so headless browser api will act as a normal browser starting from now and websites will not be able to detect that it is actually a headless browser and it might scrape them so because of this they will not show any captures they will not block scraping and they will not act against accessing their resources so headless browser api got this update the don't get blocked update anti-bot detection and bypassing build into the api and you will not need to worry anymore for requests being blocked so let me show you this feature in the plugin and the chromatic plugin which uses headless browser api and let me show you this website that i found and i tested this feature on this website so it's auto inevitable dot com slash bots and here on the bottom if you are using a browser you will see many green things and uh on chrome 100 for some reason this is red because of uh they forgot to add the web driver however this should be green if you check this page on firefox you will see that everything is green so this is a normal browser behavior every test here is green so let me check this in the chromatic plugin and let me use headless browser api to test it so first of all let's use the default wordpress scraping method and check this website i will use the visual selector to visualize the content so using wordpress scraping as you can see the javascript is not executed and the parts of the test we are not seeing those parts now let's go ahead and jump to using puppeteer which is installed on my server which is not headless browser api but local puppeteer installed on my server and if we use the local puppeteer to visualize the website so keep in mind this is not headless browser api it is a local puppeteer installed on my local server we will see three things red so puppeteer failed these three tests this was the headless browser api result also before the updates that i made just now so and now let me check also with headless browser api puppeteer which will be uh the results so i hope everything will be great so let's check headless browser api puppeteer and this is the result and if we scroll down everything is green exactly like in firefox or so this is better than chrome 100 so the web driver test is not failing unlike on chrome 100 or let me show you how the built-in tor module is returning even more red parts because the tor module which is built in is even uh considered even dirtier however the headless browser api tour you will see that is green so this is the built-in tour module which is installed on my server so if you install tor on your server you will see that there will be some uh possibilities that the websites will detect that you are actually using uh headless browser but if you use store on headless browser api we will see that we should get full green results so this is the first major update i made for headless browser api and as you can see tor also is full green in the headless browser tests on this website okay so now let me show you the second feature is that the api will be able to automatically solve also captures that are on the page or which might be on the page so if the page is protected by a captcha you can use the automatic capture solving feature in headless browser api that will solve the capture to enable this in the latest plugin versions of chromatic you will find the this headless browser api enable capture solving checkbox if you check this checkbox and you use the puppeteer or tor modules of headless browser api it will be uh with capture solving enabled so this feature is only for puppeteer and tor for capture sorting in headless browser api now let me go ahead and tell you also about the third feature which will be adblock so headless browser api got a new update or so to block automatically ads which might appear in the content so simply check this checkbox and use the puppeteer or tor endpoints of headless browser api and you will be able to block ads that appear in the script content automatically exactly like you would use an ad block on chrome or on firefox okay so let me show you also the documentation of these new features which will be found on headless browser api.com documentation which is also linked in this video's description so this new features will be enabled with these arguments for the api course this is required only if you create your own tools which use headless browser api if you use the plugins that i created which automatically implement headless browser api you will not need to mess with these parameters so solve capture and enable ad block this can be set to one or on so on this is the value which will enable these features also note that if you use the solve capture feature in a uh add the to the waiting time that you wait after the results from the scraping at least 120 seconds because capture solving is a bit lengthy process and can take up to 120 seconds to complete so keep note of this okay so yeah this is all for today i hope you enjoyed these new features as hi of headless browser api it is linked in this video's description also you will find crawl-o-matic there and yeah until next time subscribe to this channel if you enjoyed this content have a nice day bye bye <--string value was this the nummber of key in the env is -->  2
random number generated is -> 0
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
formatted groq json is -->
 {"does_video_have_sponsorship":false, "sponsorship_subtitle":""} 

||6
555
 in the get_the_subtitles func
time taken in userKey decoding is -> 75  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 71990.137164 sec
in the auto generated track
formatting the transctipt.subtitles.text to be utf-8
[start 0.299] hey everyone and welcome to this video [Duration: 4.141]
[start 2.94] in which I'm going to explain to you [Duration: 4.26]
[start 4.44] what a web Unblocker is and when you [Duration: 5.579]
[start 7.2] should use one in these simplest terms a [Duration: 5.399]
[start 10.019] web Unblocker lets you bypass antibot [Duration: 5.341]
[start 12.599] systems ones that stop you from scraping [Duration: 5.461]
[start 15.36] sites to be precise it makes sure that [Duration: 4.919]
[start 18.06] not only your real IP address is hidden [Duration: 3.96]
[start 20.279] but also that your web requests don't [Duration: 3.481]
[start 22.02] differ in any way from real internet [Duration: 4.44]
[start 23.76] user requests it has smart features [Duration: 4.62]
[start 26.46] which I will get to later that allow you [Duration: 4.02]
[start 28.38] to successfully bypass even the most [Duration: 5.04]
[start 30.48] sophisticated antibot systems so [Duration: 5.46]
[start 33.42] essentially a web Unblocker does much [Duration: 4.799]
[start 35.94] more than a proxy server alone will ever [Duration: 4.68]
[start 38.219] be capable of if you run this basic [Duration: 4.261]
[start 40.62] Walmart scraping script a few times [Duration: 4.619]
[start 42.48] Walmart will block you like this [Duration: 5.46]
[start 45.239] now when you root this request through a [Duration: 5.101]
[start 47.94] web Unblocker it will decide what type [Duration: 4.98]
[start 50.34] of proxy to use and we'll use additional [Duration: 4.62]
[start 52.92] anti-detection techniques so that [Duration: 4.38]
[start 54.96] Walmart would think that it is just a [Duration: 4.8]
[start 57.3] regular Shopper browsing the website [Duration: 5.64]
[start 59.76] so how does a web Unblocker achieve this [Duration: 5.7]
[start 62.94] stay tuned as I will cover what exactly [Duration: 5.039]
[start 65.46] a weapon blocker is why use a web on [Duration: 5.339]
[start 67.979] blocker getting started scraping warmer [Duration: 4.441]
[start 70.799] and then finally ending with scraping [Duration: 3.36]
[start 72.42] Google we're going to do this with [Duration: 3.84]
[start 74.159] python and then with node.js so [Duration: 3.541]
[start 76.26] hopefully as many of you can follow [Duration: 4.08]
[start 77.7] along as possible so let's get to it [Duration: 4.08]
[start 80.34] let's start off with looking at what [Duration: 4.5]
[start 81.78] exactly a web Unblocker is a weapon [Duration: 5.22]
[start 84.84] blocker is an AI powered proxy solution [Duration: 4.26]
[start 87] capable of bypassing complex [Duration: 4.08]
[start 89.1] anti-scraping measures by appearing like [Duration: 5.22]
[start 91.08] an organic user on a website now there [Duration: 4.92]
[start 94.32] are many ways to appear like an organic [Duration: 3.9]
[start 96] user and unblock sites but for the [Duration: 4.2]
[start 98.22] purpose of this tutorial I'm going to be [Duration: 4.5]
[start 100.2] using oxylab's web Unblocker so keep [Duration: 4.2]
[start 102.72] that in mind when I'm referring to the [Duration: 4.079]
[start 104.4] web Unblocker in this explainer as the [Duration: 5.16]
[start 106.799] features are specific to it we are going [Duration: 4.5]
[start 109.56] to use oxylabs as I am currently an [Duration: 3.78]
[start 111.299] official ambassador of the brand so by [Duration: 3.6]
[start 113.34] clicking on the link below in the [Duration: 3.12]
[start 114.899] description you are really helping out [Duration: 3.301]
[start 116.46] this channel as they can track the [Duration: 4.26]
[start 118.2] traffic from this video we are going to [Duration: 4.94]
[start 120.72] bypass anti-bot systems with the help of [Duration: 5.28]
[start 123.14] Dynamic fingerprinting technology and [Duration: 5.38]
[start 126] other Advanced features in order to look [Duration: 5.459]
[start 128.52] like a real user the AI technology does [Duration: 5.76]
[start 131.459] a few things first it uses machine [Duration: 5.221]
[start 134.28] learning driven proxy management this [Duration: 4.5]
[start 136.68] feature evaluates which proxy types work [Duration: 4.68]
[start 138.78] the best on a specific Target and then [Duration: 4.56]
[start 141.36] it selects and rotates proxies that are [Duration: 3.72]
[start 143.34] likely to yield the highest success rate [Duration: 4.38]
[start 145.08] with the lowest response time possible [Duration: 4.86]
[start 147.72] next it chooses the most suitable [Duration: 4.32]
[start 149.94] headers cookies and other browser [Duration: 4.08]
[start 152.04] parameters based on what you are trying [Duration: 4.62]
[start 154.02] to scrape this feature is called Dynamic [Duration: 5.52]
[start 156.66] browser fingerprinting then it's time [Duration: 4.68]
[start 159.54] for machine learning powered response [Duration: 4.38]
[start 161.34] recognition simply said it determines [Duration: 4.44]
[start 163.92] the quality of the scraping results and [Duration: 4.02]
[start 165.78] passes this information to the next [Duration: 5.16]
[start 167.94] process in the web unblocking pipeline [Duration: 5.34]
[start 170.94] scraping outcome is unacceptable then [Duration: 4.439]
[start 173.28] the webon blocker automatically retries [Duration: 4.14]
[start 175.379] requests while simultaneously changing [Duration: 4.561]
[start 177.42] previously mentioned parameters until it [Duration: 4.38]
[start 179.94] successfully gets through the antibot [Duration: 3.06]
[start 181.8] system [Duration: 3.42]
[start 183] finally if a website uses JavaScript [Duration: 4.379]
[start 185.22] rendering to load content dynamically [Duration: 4.56]
[start 187.379] the user can instruct the web Unblocker [Duration: 4.321]
[start 189.78] to run requests through a headless [Duration: 4.739]
[start 191.7] browser on top of all this it can access [Duration: 7.08]
[start 194.519] content worldwide in 195 countries to be [Duration: 7.14]
[start 198.78] precise this is possible as the oxyloves [Duration: 5.28]
[start 201.659] web Unblocker uses an ethically gathered [Duration: 5.701]
[start 204.06] proxy pool of more than 102 million IP [Duration: 5.64]
[start 207.36] addresses so you can collect localized [Duration: 4.86]
[start 209.7] public data with these so imagine your [Duration: 4.319]
[start 212.22] proxies are getting blocked and you need [Duration: 3.659]
[start 214.019] to scrape Google search results from the [Duration: 3.841]
[start 215.879] United Kingdom while sitting at your [Duration: 5.461]
[start 217.86] desk in America easy that's what the web [Duration: 5.28]
[start 221.34] Unblocker can do [Duration: 4.56]
[start 223.14] so we now know what a web Unblocker is [Duration: 5.94]
[start 225.9] let's compare it to other options the [Duration: 5.339]
[start 229.08] web Unblocker we will be using is not [Duration: 4.379]
[start 231.239] just a standard proxy server and it is [Duration: 4.201]
[start 233.459] not a complete web scripting framework [Duration: 4.321]
[start 235.44] so why would you want to use it to help [Duration: 4.2]
[start 237.78] you understand I've created this table [Duration: 4.2]
[start 239.64] to compare proxies a custom built [Duration: 4.679]
[start 241.98] scraper and the web Unblocker will be [Duration: 3.6]
[start 244.319] using today [Duration: 3.961]
[start 245.58] first of all proxy servers use proxy [Duration: 4.739]
[start 248.28] infrastructure and the web Unblocker [Duration: 3.959]
[start 250.319] uses an advanced proxy infrastructure [Duration: 4.381]
[start 252.239] meaning they don't have web scraping and [Duration: 5.34]
[start 254.7] passing capabilities that is why users [Duration: 5.099]
[start 257.579] of both Solutions have to have their own [Duration: 3.72]
[start 259.799] infrastructure ready [Duration: 4.62]
[start 261.299] this is in a way similar to a custom web [Duration: 5.281]
[start 264.419] scraper where you have to create your [Duration: 4.141]
[start 266.58] own scraping infrastructure [Duration: 4.74]
[start 268.56] one major difference is that the proxy [Duration: 4.98]
[start 271.32] servers cannot render JavaScript content [Duration: 4.2]
[start 273.54] and cannot overcome fingerprinting [Duration: 4.74]
[start 275.52] methods like HTTP heading monitoring [Duration: 5.34]
[start 278.28] browser fingerprinting or TLS [Duration: 4.74]
[start 280.86] fingerprinting when it comes to building [Duration: 4.02]
[start 283.02] a custom web scraper you have to use [Duration: 3.66]
[start 284.88] libraries that enable the rendering of [Duration: 4.02]
[start 286.68] dynamic web pages and you must build [Duration: 4.44]
[start 288.9] anti-bot evasion solutions by yourself [Duration: 4.38]
[start 291.12] which requires immense technical [Duration: 4.98]
[start 293.28] knowledge and effort now the weapon [Duration: 4.8]
[start 296.1] blocker takes care of antibody vision [Duration: 4.74]
[start 298.08] for you out of the box and it can also [Duration: 4.679]
[start 300.84] run requests through a headless browser [Duration: 3.72]
[start 302.759] in a single line of code [Duration: 3.961]
[start 304.56] another important aspect is that the [Duration: 4.56]
[start 306.72] proxies have the ability to overcome IP [Duration: 5.28]
[start 309.12] bands and captures yet you have to [Duration: 4.68]
[start 312] implement further antibod evasion [Duration: 3.9]
[start 313.8] techniques in your infrastructure to be [Duration: 5.04]
[start 315.9] fully undetectable when building a web [Duration: 5.1]
[start 318.84] scraper or the same requirements apply [Duration: 4.079]
[start 321] and you also have to purchase the type [Duration: 4.86]
[start 322.919] of proxies that suit your needs the web [Duration: 4.801]
[start 325.86] Unblocker on the other hand has all [Duration: 3.54]
[start 327.72] these features integrated and [Duration: 3]
[start 329.4] additionally retries requests [Duration: 3.239]
[start 330.72] automatically with different proxies and [Duration: 3.72]
[start 332.639] fingerprint combinations [Duration: 4.021]
[start 334.44] what's good about modern proxies is that [Duration: 4.44]
[start 336.66] they typically come with automatic IP [Duration: 4.56]
[start 338.88] rotation depending on the provider and [Duration: 5.28]
[start 341.22] proxy type however you must understand [Duration: 5.28]
[start 344.16] the different variations of proxies and [Duration: 4.62]
[start 346.5] how they impact scraping tasks [Duration: 4.979]
[start 348.78] so when using proxies is your [Duration: 5]
[start 351.479] responsibility to use them efficiently [Duration: 4.621]
[start 353.78] this is similar to when you are creating [Duration: 4.06]
[start 356.1] a web scraper as you should understand [Duration: 4.2]
[start 357.84] proxy intricacies but if your chosen [Duration: 4.5]
[start 360.3] proxy types don't have automatic IP [Duration: 4.26]
[start 362.34] rotation and health monitoring you must [Duration: 4.5]
[start 364.56] rotate IPS and monitor their health [Duration: 3.479]
[start 366.84] yourself [Duration: 3.84]
[start 368.039] in comparison the web Unblocker does all [Duration: 4.981]
[start 370.68] this automatically under the hood [Duration: 4.62]
[start 373.02] you can draw some similarities between [Duration: 4.8]
[start 375.3] proxy servers and the web Unblocker when [Duration: 4.82]
[start 377.82] it comes to geo-targeting capabilities [Duration: 4.98]
[start 380.12] with proxies it all relies on the [Duration: 4.96]
[start 382.8] provider you choose and the proxy type [Duration: 5.04]
[start 385.08] you purchase with the web Unblocker [Duration: 5.04]
[start 387.84] however you get access to more than 102 [Duration: 5.52]
[start 390.12] million IP addresses located in all 195 [Duration: 5.16]
[start 393.36] countries with the ability to get [Duration: 4.08]
[start 395.28] localized content on a country's City or [Duration: 3.72]
[start 397.44] even coordinate level [Duration: 3.9]
[start 399] in comparison a custom built web script [Duration: 3.96]
[start 401.34] it must use proxy servers to access [Duration: 3.72]
[start 402.96] different geolocations [Duration: 4.38]
[start 405.06] and finally all these different aspects [Duration: 4.38]
[start 407.34] directly affect the success rate of each [Duration: 4.979]
[start 409.44] solution a proxy server enables better [Duration: 4.62]
[start 412.319] success rates but lacks the power to [Duration: 4.801]
[start 414.06] bypass difficult anti-scraping systems a [Duration: 5.52]
[start 417.12] web scraper success solely depends on [Duration: 4.68]
[start 419.58] you and whether you integrate proxies [Duration: 5.1]
[start 421.8] and use anti-fingerprinting methods now [Duration: 4.8]
[start 424.68] the web Unblocker has all the power to [Duration: 3.9]
[start 426.6] overcome detection and provides much [Duration: 3.719]
[start 428.58] higher success rates when compared to [Duration: 3]
[start 430.319] proxies [Duration: 4.021]
[start 431.58] so why use the weapon blocker it's [Duration: 4.8]
[start 434.34] simple to significantly ease the [Duration: 3.96]
[start 436.38] unblocking process and increase the [Duration: 4.5]
[start 438.3] success of your scraping operations the [Duration: 5.22]
[start 440.88] weapon blocker is especially a lifesaver [Duration: 4.439]
[start 443.52] in cases where you don't have the [Duration: 3.6]
[start 445.319] resources or knowledge to build a [Duration: 3.841]
[start 447.12] scraper to access websites that use [Duration: 4.079]
[start 449.16] sophisticated anti-scraping techniques [Duration: 4.2]
[start 451.199] as a matter of fact it may actually save [Duration: 4.081]
[start 453.36] you Financial Resources in the long run [Duration: 3.839]
[start 455.28] as you don't have to maintain a complex [Duration: 3.9]
[start 457.199] infrastructure you can just build a [Duration: 3.481]
[start 459.18] basic scraper in Python with the [Duration: 3.78]
[start 460.68] requests and beautiful soup and have the [Duration: 4.44]
[start 462.96] web Unblocker to the heavy lifting for [Duration: 5.28]
[start 465.12] you okay so now that we know that let's [Duration: 5.699]
[start 468.24] look at how to retrieve data from a site [Duration: 5.459]
[start 470.819] that uses a sophisticated antibot system [Duration: 6]
[start 473.699] okay so let's get to it first off I'm [Duration: 4.921]
[start 476.819] going to show you how to build a normal [Duration: 4.44]
[start 478.62] web scraper that will scrape pretty much [Duration: 4.62]
[start 481.259] anything apart from really difficult [Duration: 4.261]
[start 483.24] sites like warmer Amazon and Google [Duration: 4.62]
[start 485.52] because you will get blocked by their [Duration: 4.739]
[start 487.86] antibot systems so I'm going to show you [Duration: 4.8]
[start 490.259] that and show you how we are getting [Duration: 4.5]
[start 492.66] blocked and then show you how to get [Duration: 4.979]
[start 494.759] around it using the web Unblocker so [Duration: 4.62]
[start 497.639] let's do it let's head over to the [Duration: 3.78]
[start 499.379] oxylab dashboard and register account [Duration: 4.141]
[start 501.419] you can find the dashboard Link in the [Duration: 4.081]
[start 503.52] description below so just go ahead and [Duration: 4.2]
[start 505.5] click on that so we're at the same place [Duration: 5.22]
[start 507.72] on the overview page under the proxies [Duration: 5.34]
[start 510.72] tab select web on blocker and then click [Duration: 4.679]
[start 513.06] get started this will open the pricing [Duration: 4.02]
[start 515.399] page where you can click on the start [Duration: 3.901]
[start 517.08] free trial button read the terms and [Duration: 4.379]
[start 519.3] conditions accept them and continue [Duration: 3.72]
[start 521.459] this will bring you back to the overview [Duration: 3.601]
[start 523.02] page where you can select my products [Duration: 4.439]
[start 525.06] now create the username and password [Duration: 4.32]
[start 527.459] credentials that you will use to make [Duration: 4.741]
[start 529.38] the requests via web Unblocker and [Duration: 4.62]
[start 532.2] that's it now let's go back to the [Duration: 3.12]
[start 534] dashboard [Duration: 4.08]
[start 535.32] here is the dashboard that you are going [Duration: 4.8]
[start 538.08] to see so I'm just going to walk you [Duration: 3.72]
[start 540.12] through it you'll see all the products [Duration: 3.719]
[start 541.8] available and then you've also got your [Duration: 3.479]
[start 543.839] account where you can see the settings [Duration: 3.961]
[start 545.279] as well as more information on the [Duration: 5.881]
[start 547.8] products so great let's get to it no [Duration: 6.06]
[start 551.16] time to waste let's get up off code [Duration: 6.48]
[start 553.86] editors and our terminal so I'm going to [Duration: 5.22]
[start 557.64] create a project that's going to hold [Duration: 4.08]
[start 559.08] the python file so let's do it [Duration: 4.62]
[start 561.72] so first off I'm just going to create a [Duration: 4.5]
[start 563.7] new project I'm going to do it in my [Duration: 5.28]
[start 566.22] development directory so I'm just going [Duration: 5.88]
[start 568.98] to go into that and use the commander on [Duration: 6.12]
[start 572.1] Max to create a project which I'm going [Duration: 5.58]
[start 575.1] to call web on blocker now let's go into [Duration: 4.38]
[start 577.68] web Unblocker I'm just going to open up [Duration: 5.4]
[start 579.48] mvs code using the code dot command that [Duration: 5.82]
[start 583.08] I have pre-installed however you get [Duration: 4.379]
[start 585.3] your projects going please meet me at [Duration: 5.34]
[start 587.459] this point based on whatever code editor [Duration: 5.401]
[start 590.64] you are using or whatever operating [Duration: 3.36]
[start 592.86] system [Duration: 2.58]
[start 594] great [Duration: 4.14]
[start 595.44] so here we are now I'm just in the [Duration: 5.399]
[start 598.14] project and I'm just going to create a [Duration: 5.34]
[start 600.839] file just a simple script file so I'm [Duration: 4.56]
[start 603.48] going to call it script.py as we're [Duration: 4.38]
[start 605.399] going to be working with python so just [Duration: 4.261]
[start 607.86] make that a little bit bigger for you [Duration: 4.56]
[start 609.66] okay and now I'm going to import a [Duration: 4.679]
[start 612.42] package it's going to be called requests [Duration: 5.34]
[start 614.339] so just do the same and then the URL but [Duration: 5.221]
[start 617.76] we're going to specify the URL here so [Duration: 3.96]
[start 619.56] I'm going to come back to that as a [Duration: 5.219]
[start 621.72] string and next we are just going to [Duration: 4.86]
[start 624.779] Define some headers that we need to pass [Duration: 4.081]
[start 626.58] through into our web scraper [Duration: 3.84]
[start 628.86] so the first Hazard we're going to pass [Duration: 2.82]
[start 630.42] through well we're going to pass through [Duration: 3.84]
[start 631.68] the user agent and we're going to leave [Duration: 4.92]
[start 634.26] that blank for now because we're going [Duration: 4.5]
[start 636.6] to come back to this and the next one [Duration: 4.38]
[start 638.76] we're going to pass through the next [Duration: 4.62]
[start 640.98] attribute is accept language and again [Duration: 4.5]
[start 643.38] I'm going to come back to this [Duration: 3.899]
[start 645.48] so there we go that's all the headers [Duration: 4.02]
[start 647.279] that we need and now let's actually make [Duration: 4.921]
[start 649.5] the request so I'm going to save the [Duration: 5.399]
[start 652.2] response to the variable response and [Duration: 4.56]
[start 654.899] then I'm going to use requests so the [Duration: 3.901]
[start 656.76] import requests and it's going to be a [Duration: 3.42]
[start 658.8] get method and I'm just going to pass [Duration: 4.02]
[start 660.18] through the URL and the custom headers [Duration: 5.099]
[start 662.82] as the headers great just make sure to [Duration: 4.32]
[start 665.279] spell that correctly [Duration: 4.141]
[start 667.14] now I'm going to just print the response [Duration: 4.74]
[start 669.42] and get the text from it so oops let's [Duration: 4.2]
[start 671.88] just make sure that is spelled spelled [Duration: 2.76]
[start 673.62] correctly [Duration: 3.3]
[start 674.64] and wonderful [Duration: 5.1]
[start 676.92] so we are nearly there let's just pass [Duration: 4.74]
[start 679.74] through the accepted languages I'm going [Duration: 5.099]
[start 681.66] to put English the US version as well as [Duration: 7.14]
[start 684.839] English the UK version and then for the [Duration: 5.821]
[start 688.8] user agent I'm just going to paste this [Duration: 4.86]
[start 690.66] okay so here is what you need to pass [Duration: 4.919]
[start 693.66] through don't worry I'll be adding the [Duration: 3.9]
[start 695.579] code to this in the video description [Duration: 4.021]
[start 697.56] below in case you can't copy this out [Duration: 4.56]
[start 699.6] but for all of you copying from the [Duration: 5.1]
[start 702.12] video here it is you can type out please [Duration: 5.52]
[start 704.7] pause if you need and go back and forth [Duration: 5.699]
[start 707.64] in the video Until yours looks the same [Duration: 5.759]
[start 710.399] great so now let's go ahead and get the [Duration: 5.101]
[start 713.399] URL we want to scrape like I said we're [Duration: 4.5]
[start 715.5] going to be escaping Walmart so just [Duration: 5.339]
[start 717.899] head over to Walmart and I am going to [Duration: 5.821]
[start 720.839] choose to scrape games so in the search [Duration: 4.56]
[start 723.72] I'm going to write games and this [Duration: 3.96]
[start 725.399] constructs the URL that we need that [Duration: 4.861]
[start 727.68] we're going to essentially script okay [Duration: 4.44]
[start 730.26] of course you can scrape whatever you [Duration: 5.34]
[start 732.12] want I'm just choosing to skip games so [Duration: 6.48]
[start 735.6] now that we have that I'm just going to [Duration: 7.08]
[start 738.6] install that package using pip3 install [Duration: 6]
[start 742.68] hopefully you guys have set up your [Duration: 5.279]
[start 744.6] terminals to use Python so if you have [Duration: 5.4]
[start 747.959] this should work and if not please go [Duration: 4.5]
[start 750] ahead and set up your terminals to be [Duration: 6.42]
[start 752.459] able to use the PIP 3 command so there [Duration: 7.56]
[start 756.42] we go that has now imported the requests [Duration: 6.12]
[start 760.019] package and now if we run this script by [Duration: 4.26]
[start 762.54] pressing this little play button right [Duration: 6.66]
[start 764.279] here we should get all of the HTML from [Duration: 6.261]
[start 769.2] that site [Duration: 5.28]
[start 770.54] amazing okay so there we go so we have [Duration: 7.479]
[start 774.48] now built just a simple scraper that [Duration: 6.06]
[start 778.019] scrapes sites but will get blocked by [Duration: 5.341]
[start 780.54] certain bigger websites like Walmart if [Duration: 5.34]
[start 783.36] we make too many requests so if we go [Duration: 5.099]
[start 785.88] ahead and press the play button right [Duration: 6.06]
[start 788.459] here okay and do this a few times we [Duration: 6.481]
[start 791.94] should get blocked so how do we go about [Duration: 6.72]
[start 794.94] this well to go about this and the [Duration: 7.139]
[start 798.66] bypass anti-bot systems such as the ones [Duration: 6.78]
[start 802.079] Walmart Amazon and Google have we're [Duration: 5.401]
[start 805.44] going to use the web Unblocker and it's [Duration: 4.68]
[start 807.48] super simple we're just going to add a [Duration: 4.859]
[start 810.12] few more lines of code to what we have [Duration: 3.839]
[start 812.339] written so far [Duration: 4.8]
[start 813.959] okay so let's do it I'm just going to [Duration: 5.701]
[start 817.139] write an object I'm going to save it [Duration: 5.461]
[start 819.66] under the variable proxies and the first [Duration: 5.64]
[start 822.6] attribute is going to be for the HTTP [Duration: 6.239]
[start 825.3] address and it's just going to be HTTP s [Duration: 5.219]
[start 828.839] and we're going to get our username and [Duration: 4.68]
[start 830.519] password so back on the dashboard under [Duration: 6]
[start 833.519] my products just go on to web Unblocker [Duration: 5.101]
[start 836.519] and under users you should have a [Duration: 4.32]
[start 838.62] username and a password now you can [Duration: 4.74]
[start 840.839] change your password here if you have [Duration: 5.821]
[start 843.36] forgotten it but I have not so that is [Duration: 4.8]
[start 846.66] where you'd find your username and [Duration: 4.08]
[start 848.16] password let's just go back to here and [Duration: 5.22]
[start 850.74] paste the username followed by the colon [Duration: 5.76]
[start 853.38] and then the password that you have and [Duration: 4.759]
[start 856.5] then at [Duration: 4.26]
[start 858.139] unblock.oxylabs.io 60 [Duration: 4.181]
[start 860.76] 000. [Duration: 4.62]
[start 862.32] comma and then just copy the whole thing [Duration: 7.079]
[start 865.38] and do the same but for https [Duration: 7.44]
[start 869.399] okay so just add in the Esther [Duration: 6.18]
[start 872.82] and we are good to go [Duration: 5.699]
[start 875.579] great so that's what it looks like let's [Duration: 5.88]
[start 878.519] continue so now let's also pass through [Duration: 6.06]
[start 881.459] the proxies into the request so just [Duration: 4.62]
[start 884.579] pass it through [Duration: 3.721]
[start 886.079] above here so I'm just going to space [Duration: 5.82]
[start 888.3] this out so proxies and then verify [Duration: 8.039]
[start 891.899] equals false and we are golden so now [Duration: 6.361]
[start 896.339] let's run this so I'm just going to run [Duration: 3.601]
[start 898.26] that script again [Duration: 4.439]
[start 899.94] okay so just press that play button here [Duration: 7.92]
[start 902.699] and amazing we get all of the HTML and [Duration: 7.5]
[start 907.86] we are not getting blocked [Duration: 3.539]
[start 910.199] great [Duration: 3.121]
[start 911.399] now I'm just going to take this tutorial [Duration: 4.021]
[start 913.32] step further and show you how to [Duration: 5.34]
[start 915.42] actually get certain values out of this [Duration: 5.58]
[start 918.66] HTML I'm going to show you how to do it [Duration: 4.26]
[start 921] just with one title and then hopefully [Duration: 3.899]
[start 922.92] you can use the same approach in order [Duration: 4.74]
[start 924.899] to get all the information that you need [Duration: 5.701]
[start 927.66] so in order to do this we are going to [Duration: 6.66]
[start 930.6] use another package called bs4 so I'm [Duration: 6.239]
[start 934.32] just going to first offrite the code for [Duration: 4.019]
[start 936.839] this so we're going to write a variable [Duration: 3.781]
[start 938.339] called soup and then use the bs4 package [Duration: 4.74]
[start 940.62] and a method from it called Beautiful [Duration: 3.839]
[start 943.079] soup [Duration: 3.541]
[start 944.459] okay and then just pause through the [Duration: 4.38]
[start 946.62] response and the text so everything we [Duration: 4.62]
[start 948.839] just saw in the terminal [Duration: 4.081]
[start 951.24] next I'm just going to pass through the [Duration: 2.599]
[start 952.92] string [Duration: 4.979]
[start 953.839] lxml okay now let's go ahead and get [Duration: 5.921]
[start 957.899] what we want out of the text so I'm just [Duration: 3.541]
[start 959.76] going to grab a product title just one [Duration: 3.54]
[start 961.44] product title so let's go ahead and [Duration: 3.959]
[start 963.3] Define product title and I'm going to [Duration: 4.8]
[start 965.399] use sup find in order to find it from [Duration: 5.461]
[start 968.1] all the HTML so the title we're going to [Duration: 5.34]
[start 970.86] look for is the first one here so let's [Duration: 4.8]
[start 973.44] just inspect the element that holds this [Duration: 4.8]
[start 975.66] title and the element that holds this [Duration: 6.78]
[start 978.24] title is in fact a let's have a look [Duration: 7.44]
[start 982.44] it is a span element so we're going to [Duration: 6.54]
[start 985.68] look for a span that also has a specific [Duration: 7.2]
[start 988.98] attribute so in this case it's the ID of [Duration: 5.58]
[start 992.88] product title that I'm going to be [Duration: 4.8]
[start 994.56] looking for and all of the HTML so let's [Duration: 5.639]
[start 997.68] look for a span and let's look for a [Duration: 4.74]
[start 1000.199] Spam that has I think it was the ID [Duration: 4.5]
[start 1002.42] let's go back to this the idea product [Duration: 3.779]
[start 1004.699] title [Duration: 3.301]
[start 1006.199] so that's what we are looking for and [Duration: 4.801]
[start 1008] we're just going to essentially get that [Duration: 4.86]
[start 1011] element that we saved as product title [Duration: 4.079]
[start 1012.86] and get the text from inside it using [Duration: 5.58]
[start 1015.079] the get text method so that's what we [Duration: 5.041]
[start 1018.44] are going to do [Duration: 4.22]
[start 1020.12] okay let's just go ahead and install [Duration: 7.439]
[start 1022.66] PS4 the package that we are using so [Duration: 7.179]
[start 1027.559] just like that which means we now need [Duration: 4.5]
[start 1029.839] to import it into the file so I'm simply [Duration: 6.541]
[start 1032.059] going to import bs4 like so okay so [Duration: 6.181]
[start 1036.38] that's all I am doing [Duration: 3.98]
[start 1038.24] and we also need to install [Duration: 4.679]
[start 1040.36] lxml so let's go ahead and do that [Duration: 5.14]
[start 1042.919] making sure it's pip3 so just install [Duration: 5.101]
[start 1045.5] that too so that is the string that we [Duration: 3.6]
[start 1048.02] wrote [Duration: 2.52]
[start 1049.1] okay [Duration: 6.12]
[start 1050.54] and great so now let's essentially let's [Duration: 7.32]
[start 1055.22] look back at the code [Duration: 6.06]
[start 1057.86] okay uh this should actually be this is [Duration: 6.059]
[start 1061.28] a custom attribute not an ID as you can [Duration: 5.519]
[start 1063.919] see here it's custom so in order to get [Duration: 4.921]
[start 1066.799] a custom attribute we simply have to [Duration: 5.161]
[start 1068.84] write ATT or S and then pass that [Duration: 5.339]
[start 1071.96] through like so and now we can Define [Duration: 4.92]
[start 1074.179] the custom attribute for that element [Duration: 5.701]
[start 1076.88] and it was Data automation ID and just [Duration: 4.86]
[start 1079.88] use get rid of that equal sign right [Duration: 5.22]
[start 1081.74] there and replace it okay wonderful now [Duration: 7.439]
[start 1085.1] let's run this code and ta-da we get the [Duration: 6.24]
[start 1089.179] specific title so that's how you would [Duration: 5.761]
[start 1091.34] get certain text out of the HTML please [Duration: 6.12]
[start 1094.94] use this use the package bs4 do your own [Duration: 4.56]
[start 1097.46] research on it you can find specific [Duration: 4.8]
[start 1099.5] elements you can find all elements and [Duration: 4.14]
[start 1102.26] so on just head over to the [Duration: 3.24]
[start 1103.64] documentation right here [Duration: 4.62]
[start 1105.5] so great we have now successfully [Duration: 6.48]
[start 1108.26] scraped Walmart using python I'm going [Duration: 6.06]
[start 1111.98] to show you how to scrape using node.js [Duration: 6.12]
[start 1114.32] so JavaScript next so let's do it [Duration: 6.42]
[start 1118.1] okay so this time I'm going to use a [Duration: 4.56]
[start 1120.74] different code editor this is webstorm [Duration: 5.1]
[start 1122.66] just to differentiate so first off I've [Duration: 4.98]
[start 1125.84] just gone ahead and created a new [Duration: 4.92]
[start 1127.64] directory again called Web Unblocker and [Duration: 4.68]
[start 1130.76] now let's get up our terminal making [Duration: 4.2]
[start 1132.32] sure that we are in web Unblocker and [Duration: 6]
[start 1134.96] I'm just gonna type npm init to [Duration: 6]
[start 1138.32] initialize a back end essentially to [Duration: 6.18]
[start 1140.96] initialize a node.js project so by [Duration: 5.7]
[start 1144.5] typing npm in it and just going enter [Duration: 5.34]
[start 1146.66] through all the default questions it's [Duration: 5.7]
[start 1149.84] going to spin up a package Json file for [Duration: 5.16]
[start 1152.36] me so there it is okay this is just the [Duration: 4.679]
[start 1155] default stuff we don't need to change [Duration: 4.559]
[start 1157.039] much we just need to add a type so that [Duration: 5.88]
[start 1159.559] we can use inputs in the file so type [Duration: 6]
[start 1162.919] and then we're going to put modules and [Duration: 5.341]
[start 1165.559] this will allow us to have Imports in [Duration: 5.161]
[start 1168.26] the index.js file we are about to make [Duration: 5.039]
[start 1170.72] okay so make sure that's there and now [Duration: 4.98]
[start 1173.299] let's go ahead and create that file it's [Duration: 4.321]
[start 1175.7] going to be a Javascript file which is [Duration: 3.66]
[start 1177.62] going to be called index so there we go [Duration: 4.74]
[start 1179.36] it's an index.js file now we can use the [Duration: 5.52]
[start 1182.36] import keyword thanks to the types [Duration: 5.04]
[start 1184.88] module and I'm going to import fetch [Duration: 5.7]
[start 1187.4] from the package node fetch [Duration: 6.48]
[start 1190.58] okay so that is something you would also [Duration: 5.64]
[start 1193.88] need to do again I can use import thanks [Duration: 4.98]
[start 1196.22] to the type module and now we're also [Duration: 5.94]
[start 1198.86] going to import https proxy agent from [Duration: 5.819]
[start 1202.16] HTTP proxy agent so those are two [Duration: 4.74]
[start 1204.679] packages that you're going to need to [Duration: 4.561]
[start 1206.9] install and if you go to package.json [Duration: 3.96]
[start 1209.24] after they've installed you will see [Duration: 3.9]
[start 1210.86] them there along with their versions so [Duration: 3.9]
[start 1213.14] if anything is not working and you're [Duration: 3.36]
[start 1214.76] watching this in the future it could be [Duration: 3.72]
[start 1216.5] down to the package you are using just [Duration: 4.38]
[start 1218.48] make sure to have yours the same as me [Duration: 4.26]
[start 1220.88] great [Duration: 4.679]
[start 1222.74] so now let's continue [Duration: 5.1]
[start 1225.559] I'm going to define the username and [Duration: 4.021]
[start 1227.84] password that we're going to need to [Duration: 3.959]
[start 1229.58] pass through into the proxies just as we [Duration: 4.86]
[start 1231.799] did before okay so I'm going to leave [Duration: 5.041]
[start 1234.44] those empty and next let's define the [Duration: 5.58]
[start 1236.84] agent so I'm going to use the import so [Duration: 4.98]
[start 1240.02] make sure that is spelled correctly it's [Duration: 4.92]
[start 1241.82] https proxy agent which we're importing [Duration: 6.96]
[start 1244.94] from the package https proxy agent and [Duration: 6]
[start 1248.78] now we're just going to pause through a [Duration: 4.32]
[start 1250.94] few things into this Constructor [Duration: 3.54]
[start 1253.1] so the things that we're going to pass [Duration: 4.439]
[start 1254.48] through into this Constructor is a URL [Duration: 6]
[start 1257.539] that I need to construct HTTP and we're [Duration: 6.361]
[start 1260.48] going to use the username constant so [Duration: 5.4]
[start 1263.9] making sure that obviously this is [Duration: 4.68]
[start 1265.88] embacted so we can pick up the code and [Duration: 4.74]
[start 1268.58] we Define this as code by using the [Duration: 4.44]
[start 1270.62] dollar sign and Kylie braces then we get [Duration: 5.22]
[start 1273.02] out of that code we use the colon and [Duration: 6.14]
[start 1275.84] then password and then put at unblock [Duration: 5.78]
[start 1279.16] dot [Duration: 5.56]
[start 1281.62] oxylabs.io 60 [Duration: 5.02]
[start 1284.72] 000. okay so just like we did before we [Duration: 4.8]
[start 1286.64] just constructed the same URL [Duration: 4.14]
[start 1289.52] great [Duration: 3.779]
[start 1290.78] now we just need to put in some code so [Duration: 6.66]
[start 1293.299] process EnV no TLS reject and authorize [Duration: 6.841]
[start 1297.44] and just put through a series this [Duration: 4.5]
[start 1300.14] essentially makes TLS connections and [Duration: 4.32]
[start 1301.94] https requests insecure by disabling [Duration: 5.58]
[start 1304.46] certificate verification [Duration: 5.64]
[start 1307.52] and now let's get our response so we're [Duration: 4.5]
[start 1310.1] going to define the response as the [Duration: 3.6]
[start 1312.02] const response and we're going to await [Duration: 4.74]
[start 1313.7] fetch as it's an asynchronous method and [Duration: 4.8]
[start 1316.76] we're going to just pass through the URL [Duration: 3.12]
[start 1318.5] that we want to essentially scrape [Duration: 3.48]
[start 1319.88] followed by an object which we're going [Duration: 4.5]
[start 1321.98] to define the method as get even though [Duration: 3.96]
[start 1324.38] we probably don't need to do this the [Duration: 3.9]
[start 1325.94] fetch method already has a default [Duration: 5.219]
[start 1328.28] action of get and then we're also going [Duration: 4.56]
[start 1331.159] to pass through the agent that we just [Duration: 3.661]
[start 1332.84] made so that we go [Duration: 5.459]
[start 1334.82] wonderful so now let's console log out [Duration: 6.42]
[start 1338.299] the response I'm just going to await it [Duration: 5.88]
[start 1341.24] okay so a weight response [Duration: 6.36]
[start 1344.179] and get its text from it so that's what [Duration: 5.461]
[start 1347.6] we're going to do now let's get the URL [Duration: 4.02]
[start 1349.64] that we want to scrape so we're going to [Duration: 4.32]
[start 1351.62] scrape Google okay and again we are [Duration: 4.799]
[start 1353.96] going to scrape Google for games so that [Duration: 5.4]
[start 1356.419] is the URL that we're going to do so [Duration: 5.041]
[start 1359.36] this is just the same as me going to [Duration: 4.98]
[start 1361.46] Google and searching for games as you [Duration: 4.56]
[start 1364.34] would in your browser like this okay [Duration: 3.8]
[start 1366.02] that's what we're gonna scrape [Duration: 7.139]
[start 1368.14] so let's do it okay before we move on [Duration: 5.98]
[start 1373.159] though I'm just going to pass through [Duration: 2.88]
[start 1374.12] the username and password it's the same [Duration: 4.679]
[start 1376.039] that we had before so here is mine and [Duration: 5.041]
[start 1378.799] here is my password please fill in yours [Duration: 4.981]
[start 1381.08] here as mine will not work for you now [Duration: 4.2]
[start 1383.78] let's run this script so I'm going to [Duration: 3.24]
[start 1385.28] run this script by getting up the [Duration: 5.66]
[start 1387.02] terminal and typing node index.js and [Duration: 8.82]
[start 1390.94] ta-da we get the HTML for that page here [Duration: 7.18]
[start 1395.84] we have it it's just the same as we did [Duration: 5.16]
[start 1398.12] with python and if you want to pick [Duration: 5.1]
[start 1401] stuff out of here you would do it with [Duration: 4.98]
[start 1403.22] the same approach as we did for python [Duration: 4.98]
[start 1405.98] okay so you look for certain elements in [Duration: 5.22]
[start 1408.2] here and get the text from it [Duration: 5.459]
[start 1411.2] and just to prove that we have scraped [Duration: 5.4]
[start 1413.659] this HTML we're going to look for this [Duration: 5.281]
[start 1416.6] piece of text so let's copy it and let's [Duration: 4.079]
[start 1418.94] find it in here so I'm just going to [Duration: 5.52]
[start 1420.679] search for that and there we go [Duration: 5.461]
[start 1424.46] great [Duration: 4.199]
[start 1426.14] so great hopefully now you know how to [Duration: 6.06]
[start 1428.659] scrape Pages using web Unblocker and [Duration: 6.841]
[start 1432.2] bypassing antibot systems in a super [Duration: 5.52]
[start 1435.5] simple and easy way [Duration: 4.32]
[start 1437.72] okay so I hope you've learned something [Duration: 4.8]
[start 1439.82] useful today as a recap here is what we [Duration: 5.099]
[start 1442.52] covered in this video we looked at what [Duration: 5.159]
[start 1444.919] exactly a web Unblocker is we compared [Duration: 5.341]
[start 1447.679] proxies to custom web scrapers to the [Duration: 4.62]
[start 1450.26] web Unblocker and then we actually [Duration: 4.32]
[start 1452.299] signed up and used the actual web [Duration: 4.561]
[start 1454.58] Unblocker to scrape Walmart and Google [Duration: 4.8]
[start 1456.86] using the oxylabs web Unblocker [Duration: 4.74]
[start 1459.38] specifically if you would like to read [Duration: 4.44]
[start 1461.6] up more about the web Unblocker we were [Duration: 4.38]
[start 1463.82] using today in this video please do [Duration: 4.739]
[start 1465.98] visit the developer documentation via [Duration: 5.3]
[start 1468.559] the link below [Duration: 2.721]

 string value is this --> hey everyone and welcome to this video in which I'm going to explain to you what a web Unblocker is and when you should use one in these simplest terms a web Unblocker lets you bypass antibot systems ones that stop you from scraping sites to be precise it makes sure that not only your real IP address is hidden but also that your web requests don't differ in any way from real internet user requests it has smart features which I will get to later that allow you to successfully bypass even the most sophisticated antibot systems so essentially a web Unblocker does much more than a proxy server alone will ever be capable of if you run this basic Walmart scraping script a few times Walmart will block you like this now when you root this request through a web Unblocker it will decide what type of proxy to use and we'll use additional anti-detection techniques so that Walmart would think that it is just a regular Shopper browsing the website so how does a web Unblocker achieve this stay tuned as I will cover what exactly a weapon blocker is why use a web on blocker getting started scraping warmer and then finally ending with scraping Google we're going to do this with python and then with node.js so hopefully as many of you can follow along as possible so let's get to it let's start off with looking at what exactly a web Unblocker is a weapon blocker is an AI powered proxy solution capable of bypassing complex anti-scraping measures by appearing like an organic user on a website now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video we are going to bypass anti-bot systems with the help of Dynamic fingerprinting technology and other Advanced features in order to look like a real user the AI technology does a few things first it uses machine learning driven proxy management this feature evaluates which proxy types work the best on a specific Target and then it selects and rotates proxies that are likely to yield the highest success rate with the lowest response time possible next it chooses the most suitable headers cookies and other browser parameters based on what you are trying to scrape this feature is called Dynamic browser fingerprinting then it's time for machine learning powered response recognition simply said it determines the quality of the scraping results and passes this information to the next process in the web unblocking pipeline scraping outcome is unacceptable then the webon blocker automatically retries requests while simultaneously changing previously mentioned parameters until it successfully gets through the antibot system finally if a website uses JavaScript rendering to load content dynamically the user can instruct the web Unblocker to run requests through a headless browser on top of all this it can access content worldwide in 195 countries to be precise this is possible as the oxyloves web Unblocker uses an ethically gathered proxy pool of more than 102 million IP addresses so you can collect localized public data with these so imagine your proxies are getting blocked and you need to scrape Google search results from the United Kingdom while sitting at your desk in America easy that's what the web Unblocker can do so we now know what a web Unblocker is let's compare it to other options the web Unblocker we will be using is not just a standard proxy server and it is not a complete web scripting framework so why would you want to use it to help you understand I've created this table to compare proxies a custom built scraper and the web Unblocker will be using today first of all proxy servers use proxy infrastructure and the web Unblocker uses an advanced proxy infrastructure meaning they don't have web scraping and passing capabilities that is why users of both Solutions have to have their own infrastructure ready this is in a way similar to a custom web scraper where you have to create your own scraping infrastructure one major difference is that the proxy servers cannot render JavaScript content and cannot overcome fingerprinting methods like HTTP heading monitoring browser fingerprinting or TLS fingerprinting when it comes to building a custom web scraper you have to use libraries that enable the rendering of dynamic web pages and you must build anti-bot evasion solutions by yourself which requires immense technical knowledge and effort now the weapon blocker takes care of antibody vision for you out of the box and it can also run requests through a headless browser in a single line of code another important aspect is that the proxies have the ability to overcome IP bands and captures yet you have to implement further antibod evasion techniques in your infrastructure to be fully undetectable when building a web scraper or the same requirements apply and you also have to purchase the type of proxies that suit your needs the web Unblocker on the other hand has all these features integrated and additionally retries requests automatically with different proxies and fingerprint combinations what's good about modern proxies is that they typically come with automatic IP rotation depending on the provider and proxy type however you must understand the different variations of proxies and how they impact scraping tasks so when using proxies is your responsibility to use them efficiently this is similar to when you are creating a web scraper as you should understand proxy intricacies but if your chosen proxy types don't have automatic IP rotation and health monitoring you must rotate IPS and monitor their health yourself in comparison the web Unblocker does all this automatically under the hood you can draw some similarities between proxy servers and the web Unblocker when it comes to geo-targeting capabilities with proxies it all relies on the provider you choose and the proxy type you purchase with the web Unblocker however you get access to more than 102 million IP addresses located in all 195 countries with the ability to get localized content on a country's City or even coordinate level in comparison a custom built web script it must use proxy servers to access different geolocations and finally all these different aspects directly affect the success rate of each solution a proxy server enables better success rates but lacks the power to bypass difficult anti-scraping systems a web scraper success solely depends on you and whether you integrate proxies and use anti-fingerprinting methods now the web Unblocker has all the power to overcome detection and provides much higher success rates when compared to proxies so why use the weapon blocker it's simple to significantly ease the unblocking process and increase the success of your scraping operations the weapon blocker is especially a lifesaver in cases where you don't have the resources or knowledge to build a scraper to access websites that use sophisticated anti-scraping techniques as a matter of fact it may actually save you Financial Resources in the long run as you don't have to maintain a complex infrastructure you can just build a basic scraper in Python with the requests and beautiful soup and have the web Unblocker to the heavy lifting for you okay so now that we know that let's look at how to retrieve data from a site that uses a sophisticated antibot system okay so let's get to it first off I'm going to show you how to build a normal web scraper that will scrape pretty much anything apart from really difficult sites like warmer Amazon and Google because you will get blocked by their antibot systems so I'm going to show you that and show you how we are getting blocked and then show you how to get around it using the web Unblocker so let's do it let's head over to the oxylab dashboard and register account you can find the dashboard Link in the description below so just go ahead and click on that so we're at the same place on the overview page under the proxies tab select web on blocker and then click get started this will open the pricing page where you can click on the start free trial button read the terms and conditions accept them and continue this will bring you back to the overview page where you can select my products now create the username and password credentials that you will use to make the requests via web Unblocker and that's it now let's go back to the dashboard here is the dashboard that you are going to see so I'm just going to walk you through it you'll see all the products available and then you've also got your account where you can see the settings as well as more information on the products so great let's get to it no time to waste let's get up off code editors and our terminal so I'm going to create a project that's going to hold the python file so let's do it so first off I'm just going to create a new project I'm going to do it in my development directory so I'm just going to go into that and use the commander on Max to create a project which I'm going to call web on blocker now let's go into web Unblocker I'm just going to open up mvs code using the code dot command that I have pre-installed however you get your projects going please meet me at this point based on whatever code editor you are using or whatever operating system great so here we are now I'm just in the project and I'm just going to create a file just a simple script file so I'm going to call it script.py as we're going to be working with python so just make that a little bit bigger for you okay and now I'm going to import a package it's going to be called requests so just do the same and then the URL but we're going to specify the URL here so I'm going to come back to that as a string and next we are just going to Define some headers that we need to pass through into our web scraper so the first Hazard we're going to pass through well we're going to pass through the user agent and we're going to leave that blank for now because we're going to come back to this and the next one we're going to pass through the next attribute is accept language and again I'm going to come back to this so there we go that's all the headers that we need and now let's actually make the request so I'm going to save the response to the variable response and then I'm going to use requests so the import requests and it's going to be a get method and I'm just going to pass through the URL and the custom headers as the headers great just make sure to spell that correctly now I'm going to just print the response and get the text from it so oops let's just make sure that is spelled spelled correctly and wonderful so we are nearly there let's just pass through the accepted languages I'm going to put English the US version as well as English the UK version and then for the user agent I'm just going to paste this okay so here is what you need to pass through don't worry I'll be adding the code to this in the video description below in case you can't copy this out but for all of you copying from the video here it is you can type out please pause if you need and go back and forth in the video Until yours looks the same great so now let's go ahead and get the URL we want to scrape like I said we're going to be escaping Walmart so just head over to Walmart and I am going to choose to scrape games so in the search I'm going to write games and this constructs the URL that we need that we're going to essentially script okay of course you can scrape whatever you want I'm just choosing to skip games so now that we have that I'm just going to install that package using pip3 install hopefully you guys have set up your terminals to use Python so if you have this should work and if not please go ahead and set up your terminals to be able to use the PIP 3 command so there we go that has now imported the requests package and now if we run this script by pressing this little play button right here we should get all of the HTML from that site amazing okay so there we go so we have now built just a simple scraper that scrapes sites but will get blocked by certain bigger websites like Walmart if we make too many requests so if we go ahead and press the play button right here okay and do this a few times we should get blocked so how do we go about this well to go about this and the bypass anti-bot systems such as the ones Walmart Amazon and Google have we're going to use the web Unblocker and it's super simple we're just going to add a few more lines of code to what we have written so far okay so let's do it I'm just going to write an object I'm going to save it under the variable proxies and the first attribute is going to be for the HTTP address and it's just going to be HTTP s and we're going to get our username and password so back on the dashboard under my products just go on to web Unblocker and under users you should have a username and a password now you can change your password here if you have forgotten it but I have not so that is where you'd find your username and password let's just go back to here and paste the username followed by the colon and then the password that you have and then at unblock.oxylabs.io 60 000. comma and then just copy the whole thing and do the same but for https okay so just add in the Esther and we are good to go great so that's what it looks like let's continue so now let's also pass through the proxies into the request so just pass it through above here so I'm just going to space this out so proxies and then verify equals false and we are golden so now let's run this so I'm just going to run that script again okay so just press that play button here and amazing we get all of the HTML and we are not getting blocked great now I'm just going to take this tutorial step further and show you how to actually get certain values out of this HTML I'm going to show you how to do it just with one title and then hopefully you can use the same approach in order to get all the information that you need so in order to do this we are going to use another package called bs4 so I'm just going to first offrite the code for this so we're going to write a variable called soup and then use the bs4 package and a method from it called Beautiful soup okay and then just pause through the response and the text so everything we just saw in the terminal next I'm just going to pass through the string lxml okay now let's go ahead and get what we want out of the text so I'm just going to grab a product title just one product title so let's go ahead and Define product title and I'm going to use sup find in order to find it from all the HTML so the title we're going to look for is the first one here so let's just inspect the element that holds this title and the element that holds this title is in fact a let's have a look it is a span element so we're going to look for a span that also has a specific attribute so in this case it's the ID of product title that I'm going to be looking for and all of the HTML so let's look for a span and let's look for a Spam that has I think it was the ID let's go back to this the idea product title so that's what we are looking for and we're just going to essentially get that element that we saved as product title and get the text from inside it using the get text method so that's what we are going to do okay let's just go ahead and install PS4 the package that we are using so just like that which means we now need to import it into the file so I'm simply going to import bs4 like so okay so that's all I am doing and we also need to install lxml so let's go ahead and do that making sure it's pip3 so just install that too so that is the string that we wrote okay and great so now let's essentially let's look back at the code okay uh this should actually be this is a custom attribute not an ID as you can see here it's custom so in order to get a custom attribute we simply have to write ATT or S and then pass that through like so and now we can Define the custom attribute for that element and it was Data automation ID and just use get rid of that equal sign right there and replace it okay wonderful now let's run this code and ta-da we get the specific title so that's how you would get certain text out of the HTML please use this use the package bs4 do your own research on it you can find specific elements you can find all elements and so on just head over to the documentation right here so great we have now successfully scraped Walmart using python I'm going to show you how to scrape using node.js so JavaScript next so let's do it okay so this time I'm going to use a different code editor this is webstorm just to differentiate so first off I've just gone ahead and created a new directory again called Web Unblocker and now let's get up our terminal making sure that we are in web Unblocker and I'm just gonna type npm init to initialize a back end essentially to initialize a node.js project so by typing npm in it and just going enter through all the default questions it's going to spin up a package Json file for me so there it is okay this is just the default stuff we don't need to change much we just need to add a type so that we can use inputs in the file so type and then we're going to put modules and this will allow us to have Imports in the index.js file we are about to make okay so make sure that's there and now let's go ahead and create that file it's going to be a Javascript file which is going to be called index so there we go it's an index.js file now we can use the import keyword thanks to the types module and I'm going to import fetch from the package node fetch okay so that is something you would also need to do again I can use import thanks to the type module and now we're also going to import https proxy agent from HTTP proxy agent so those are two packages that you're going to need to install and if you go to package.json after they've installed you will see them there along with their versions so if anything is not working and you're watching this in the future it could be down to the package you are using just make sure to have yours the same as me great so now let's continue I'm going to define the username and password that we're going to need to pass through into the proxies just as we did before okay so I'm going to leave those empty and next let's define the agent so I'm going to use the import so make sure that is spelled correctly it's https proxy agent which we're importing from the package https proxy agent and now we're just going to pause through a few things into this Constructor so the things that we're going to pass through into this Constructor is a URL that I need to construct HTTP and we're going to use the username constant so making sure that obviously this is embacted so we can pick up the code and we Define this as code by using the dollar sign and Kylie braces then we get out of that code we use the colon and then password and then put at unblock dot oxylabs.io 60 000. okay so just like we did before we just constructed the same URL great now we just need to put in some code so process EnV no TLS reject and authorize and just put through a series this essentially makes TLS connections and https requests insecure by disabling certificate verification and now let's get our response so we're going to define the response as the const response and we're going to await fetch as it's an asynchronous method and we're going to just pass through the URL that we want to essentially scrape followed by an object which we're going to define the method as get even though we probably don't need to do this the fetch method already has a default action of get and then we're also going to pass through the agent that we just made so that we go wonderful so now let's console log out the response I'm just going to await it okay so a weight response and get its text from it so that's what we're going to do now let's get the URL that we want to scrape so we're going to scrape Google okay and again we are going to scrape Google for games so that is the URL that we're going to do so this is just the same as me going to Google and searching for games as you would in your browser like this okay that's what we're gonna scrape so let's do it okay before we move on though I'm just going to pass through the username and password it's the same that we had before so here is mine and here is my password please fill in yours here as mine will not work for you now let's run this script so I'm going to run this script by getting up the terminal and typing node index.js and ta-da we get the HTML for that page here we have it it's just the same as we did with python and if you want to pick stuff out of here you would do it with the same approach as we did for python okay so you look for certain elements in here and get the text from it and just to prove that we have scraped this HTML we're going to look for this piece of text so let's copy it and let's find it in here so I'm just going to search for that and there we go great so great hopefully now you know how to scrape Pages using web Unblocker and bypassing antibot systems in a super simple and easy way okay so I hope you've learned something useful today as a recap here is what we covered in this video we looked at what exactly a web Unblocker is we compared proxies to custom web scrapers to the web Unblocker and then we actually signed up and used the actual web Unblocker to scrape Walmart and Google using the oxylabs web Unblocker specifically if you would like to read up more about the web Unblocker we were using today in this video please do visit the developer documentation via the link below <--string value was this the nummber of key in the env is -->  2
random number generated is -> 0
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {
  "does_video_have_sponsorship": true,
  "sponsorship_subtitle": "now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video"
}
formatted groq json is -->
 {
  "does_video_have_sponsorship": true,
  "sponsorship_subtitle": "now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video"
} 

||6
555
got overboard, the text in prev one is(I think correct)--> anti-scraping measures by appearing like
this text is --> an organic user on a website now there
== now
the correct text is --> an organic user on a website now there
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
correct ending text-- the link below
sponsershipSubtitlesStartIndex, sponsershipSubtitlesEndIndex, sponsershipSubtitlesEndIndex-- 1496 1984 605
 in the get_the_subtitles func
time taken in userKey decoding is -> 73  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 71869.122700 sec
in the auto generated track
formatting the transctipt.subtitles.text to be utf-8
[start 0.299] hey everyone and welcome to this video [Duration: 4.141]
[start 2.94] in which I'm going to explain to you [Duration: 4.26]
[start 4.44] what a web Unblocker is and when you [Duration: 5.579]
[start 7.2] should use one in these simplest terms a [Duration: 5.399]
[start 10.019] web Unblocker lets you bypass antibot [Duration: 5.341]
[start 12.599] systems ones that stop you from scraping [Duration: 5.461]
[start 15.36] sites to be precise it makes sure that [Duration: 4.919]
[start 18.06] not only your real IP address is hidden [Duration: 3.96]
[start 20.279] but also that your web requests don't [Duration: 3.481]
[start 22.02] differ in any way from real internet [Duration: 4.44]
[start 23.76] user requests it has smart features [Duration: 4.62]
[start 26.46] which I will get to later that allow you [Duration: 4.02]
[start 28.38] to successfully bypass even the most [Duration: 5.04]
[start 30.48] sophisticated antibot systems so [Duration: 5.46]
[start 33.42] essentially a web Unblocker does much [Duration: 4.799]
[start 35.94] more than a proxy server alone will ever [Duration: 4.68]
[start 38.219] be capable of if you run this basic [Duration: 4.261]
[start 40.62] Walmart scraping script a few times [Duration: 4.619]
[start 42.48] Walmart will block you like this [Duration: 5.46]
[start 45.239] now when you root this request through a [Duration: 5.101]
[start 47.94] web Unblocker it will decide what type [Duration: 4.98]
[start 50.34] of proxy to use and we'll use additional [Duration: 4.62]
[start 52.92] anti-detection techniques so that [Duration: 4.38]
[start 54.96] Walmart would think that it is just a [Duration: 4.8]
[start 57.3] regular Shopper browsing the website [Duration: 5.64]
[start 59.76] so how does a web Unblocker achieve this [Duration: 5.7]
[start 62.94] stay tuned as I will cover what exactly [Duration: 5.039]
[start 65.46] a weapon blocker is why use a web on [Duration: 5.339]
[start 67.979] blocker getting started scraping warmer [Duration: 4.441]
[start 70.799] and then finally ending with scraping [Duration: 3.36]
[start 72.42] Google we're going to do this with [Duration: 3.84]
[start 74.159] python and then with node.js so [Duration: 3.541]
[start 76.26] hopefully as many of you can follow [Duration: 4.08]
[start 77.7] along as possible so let's get to it [Duration: 4.08]
[start 80.34] let's start off with looking at what [Duration: 4.5]
[start 81.78] exactly a web Unblocker is a weapon [Duration: 5.22]
[start 84.84] blocker is an AI powered proxy solution [Duration: 4.26]
[start 87] capable of bypassing complex [Duration: 4.08]
[start 89.1] anti-scraping measures by appearing like [Duration: 5.22]
[start 91.08] an organic user on a website now there [Duration: 4.92]
[start 94.32] are many ways to appear like an organic [Duration: 3.9]
[start 96] user and unblock sites but for the [Duration: 4.2]
[start 98.22] purpose of this tutorial I'm going to be [Duration: 4.5]
[start 100.2] using oxylab's web Unblocker so keep [Duration: 4.2]
[start 102.72] that in mind when I'm referring to the [Duration: 4.079]
[start 104.4] web Unblocker in this explainer as the [Duration: 5.16]
[start 106.799] features are specific to it we are going [Duration: 4.5]
[start 109.56] to use oxylabs as I am currently an [Duration: 3.78]
[start 111.299] official ambassador of the brand so by [Duration: 3.6]
[start 113.34] clicking on the link below in the [Duration: 3.12]
[start 114.899] description you are really helping out [Duration: 3.301]
[start 116.46] this channel as they can track the [Duration: 4.26]
[start 118.2] traffic from this video we are going to [Duration: 4.94]
[start 120.72] bypass anti-bot systems with the help of [Duration: 5.28]
[start 123.14] Dynamic fingerprinting technology and [Duration: 5.38]
[start 126] other Advanced features in order to look [Duration: 5.459]
[start 128.52] like a real user the AI technology does [Duration: 5.76]
[start 131.459] a few things first it uses machine [Duration: 5.221]
[start 134.28] learning driven proxy management this [Duration: 4.5]
[start 136.68] feature evaluates which proxy types work [Duration: 4.68]
[start 138.78] the best on a specific Target and then [Duration: 4.56]
[start 141.36] it selects and rotates proxies that are [Duration: 3.72]
[start 143.34] likely to yield the highest success rate [Duration: 4.38]
[start 145.08] with the lowest response time possible [Duration: 4.86]
[start 147.72] next it chooses the most suitable [Duration: 4.32]
[start 149.94] headers cookies and other browser [Duration: 4.08]
[start 152.04] parameters based on what you are trying [Duration: 4.62]
[start 154.02] to scrape this feature is called Dynamic [Duration: 5.52]
[start 156.66] browser fingerprinting then it's time [Duration: 4.68]
[start 159.54] for machine learning powered response [Duration: 4.38]
[start 161.34] recognition simply said it determines [Duration: 4.44]
[start 163.92] the quality of the scraping results and [Duration: 4.02]
[start 165.78] passes this information to the next [Duration: 5.16]
[start 167.94] process in the web unblocking pipeline [Duration: 5.34]
[start 170.94] scraping outcome is unacceptable then [Duration: 4.439]
[start 173.28] the webon blocker automatically retries [Duration: 4.14]
[start 175.379] requests while simultaneously changing [Duration: 4.561]
[start 177.42] previously mentioned parameters until it [Duration: 4.38]
[start 179.94] successfully gets through the antibot [Duration: 3.06]
[start 181.8] system [Duration: 3.42]
[start 183] finally if a website uses JavaScript [Duration: 4.379]
[start 185.22] rendering to load content dynamically [Duration: 4.56]
[start 187.379] the user can instruct the web Unblocker [Duration: 4.321]
[start 189.78] to run requests through a headless [Duration: 4.739]
[start 191.7] browser on top of all this it can access [Duration: 7.08]
[start 194.519] content worldwide in 195 countries to be [Duration: 7.14]
[start 198.78] precise this is possible as the oxyloves [Duration: 5.28]
[start 201.659] web Unblocker uses an ethically gathered [Duration: 5.701]
[start 204.06] proxy pool of more than 102 million IP [Duration: 5.64]
[start 207.36] addresses so you can collect localized [Duration: 4.86]
[start 209.7] public data with these so imagine your [Duration: 4.319]
[start 212.22] proxies are getting blocked and you need [Duration: 3.659]
[start 214.019] to scrape Google search results from the [Duration: 3.841]
[start 215.879] United Kingdom while sitting at your [Duration: 5.461]
[start 217.86] desk in America easy that's what the web [Duration: 5.28]
[start 221.34] Unblocker can do [Duration: 4.56]
[start 223.14] so we now know what a web Unblocker is [Duration: 5.94]
[start 225.9] let's compare it to other options the [Duration: 5.339]
[start 229.08] web Unblocker we will be using is not [Duration: 4.379]
[start 231.239] just a standard proxy server and it is [Duration: 4.201]
[start 233.459] not a complete web scripting framework [Duration: 4.321]
[start 235.44] so why would you want to use it to help [Duration: 4.2]
[start 237.78] you understand I've created this table [Duration: 4.2]
[start 239.64] to compare proxies a custom built [Duration: 4.679]
[start 241.98] scraper and the web Unblocker will be [Duration: 3.6]
[start 244.319] using today [Duration: 3.961]
[start 245.58] first of all proxy servers use proxy [Duration: 4.739]
[start 248.28] infrastructure and the web Unblocker [Duration: 3.959]
[start 250.319] uses an advanced proxy infrastructure [Duration: 4.381]
[start 252.239] meaning they don't have web scraping and [Duration: 5.34]
[start 254.7] passing capabilities that is why users [Duration: 5.099]
[start 257.579] of both Solutions have to have their own [Duration: 3.72]
[start 259.799] infrastructure ready [Duration: 4.62]
[start 261.299] this is in a way similar to a custom web [Duration: 5.281]
[start 264.419] scraper where you have to create your [Duration: 4.141]
[start 266.58] own scraping infrastructure [Duration: 4.74]
[start 268.56] one major difference is that the proxy [Duration: 4.98]
[start 271.32] servers cannot render JavaScript content [Duration: 4.2]
[start 273.54] and cannot overcome fingerprinting [Duration: 4.74]
[start 275.52] methods like HTTP heading monitoring [Duration: 5.34]
[start 278.28] browser fingerprinting or TLS [Duration: 4.74]
[start 280.86] fingerprinting when it comes to building [Duration: 4.02]
[start 283.02] a custom web scraper you have to use [Duration: 3.66]
[start 284.88] libraries that enable the rendering of [Duration: 4.02]
[start 286.68] dynamic web pages and you must build [Duration: 4.44]
[start 288.9] anti-bot evasion solutions by yourself [Duration: 4.38]
[start 291.12] which requires immense technical [Duration: 4.98]
[start 293.28] knowledge and effort now the weapon [Duration: 4.8]
[start 296.1] blocker takes care of antibody vision [Duration: 4.74]
[start 298.08] for you out of the box and it can also [Duration: 4.679]
[start 300.84] run requests through a headless browser [Duration: 3.72]
[start 302.759] in a single line of code [Duration: 3.961]
[start 304.56] another important aspect is that the [Duration: 4.56]
[start 306.72] proxies have the ability to overcome IP [Duration: 5.28]
[start 309.12] bands and captures yet you have to [Duration: 4.68]
[start 312] implement further antibod evasion [Duration: 3.9]
[start 313.8] techniques in your infrastructure to be [Duration: 5.04]
[start 315.9] fully undetectable when building a web [Duration: 5.1]
[start 318.84] scraper or the same requirements apply [Duration: 4.079]
[start 321] and you also have to purchase the type [Duration: 4.86]
[start 322.919] of proxies that suit your needs the web [Duration: 4.801]
[start 325.86] Unblocker on the other hand has all [Duration: 3.54]
[start 327.72] these features integrated and [Duration: 3]
[start 329.4] additionally retries requests [Duration: 3.239]
[start 330.72] automatically with different proxies and [Duration: 3.72]
[start 332.639] fingerprint combinations [Duration: 4.021]
[start 334.44] what's good about modern proxies is that [Duration: 4.44]
[start 336.66] they typically come with automatic IP [Duration: 4.56]
[start 338.88] rotation depending on the provider and [Duration: 5.28]
[start 341.22] proxy type however you must understand [Duration: 5.28]
[start 344.16] the different variations of proxies and [Duration: 4.62]
[start 346.5] how they impact scraping tasks [Duration: 4.979]
[start 348.78] so when using proxies is your [Duration: 5]
[start 351.479] responsibility to use them efficiently [Duration: 4.621]
[start 353.78] this is similar to when you are creating [Duration: 4.06]
[start 356.1] a web scraper as you should understand [Duration: 4.2]
[start 357.84] proxy intricacies but if your chosen [Duration: 4.5]
[start 360.3] proxy types don't have automatic IP [Duration: 4.26]
[start 362.34] rotation and health monitoring you must [Duration: 4.5]
[start 364.56] rotate IPS and monitor their health [Duration: 3.479]
[start 366.84] yourself [Duration: 3.84]
[start 368.039] in comparison the web Unblocker does all [Duration: 4.981]
[start 370.68] this automatically under the hood [Duration: 4.62]
[start 373.02] you can draw some similarities between [Duration: 4.8]
[start 375.3] proxy servers and the web Unblocker when [Duration: 4.82]
[start 377.82] it comes to geo-targeting capabilities [Duration: 4.98]
[start 380.12] with proxies it all relies on the [Duration: 4.96]
[start 382.8] provider you choose and the proxy type [Duration: 5.04]
[start 385.08] you purchase with the web Unblocker [Duration: 5.04]
[start 387.84] however you get access to more than 102 [Duration: 5.52]
[start 390.12] million IP addresses located in all 195 [Duration: 5.16]
[start 393.36] countries with the ability to get [Duration: 4.08]
[start 395.28] localized content on a country's City or [Duration: 3.72]
[start 397.44] even coordinate level [Duration: 3.9]
[start 399] in comparison a custom built web script [Duration: 3.96]
[start 401.34] it must use proxy servers to access [Duration: 3.72]
[start 402.96] different geolocations [Duration: 4.38]
[start 405.06] and finally all these different aspects [Duration: 4.38]
[start 407.34] directly affect the success rate of each [Duration: 4.979]
[start 409.44] solution a proxy server enables better [Duration: 4.62]
[start 412.319] success rates but lacks the power to [Duration: 4.801]
[start 414.06] bypass difficult anti-scraping systems a [Duration: 5.52]
[start 417.12] web scraper success solely depends on [Duration: 4.68]
[start 419.58] you and whether you integrate proxies [Duration: 5.1]
[start 421.8] and use anti-fingerprinting methods now [Duration: 4.8]
[start 424.68] the web Unblocker has all the power to [Duration: 3.9]
[start 426.6] overcome detection and provides much [Duration: 3.719]
[start 428.58] higher success rates when compared to [Duration: 3]
[start 430.319] proxies [Duration: 4.021]
[start 431.58] so why use the weapon blocker it's [Duration: 4.8]
[start 434.34] simple to significantly ease the [Duration: 3.96]
[start 436.38] unblocking process and increase the [Duration: 4.5]
[start 438.3] success of your scraping operations the [Duration: 5.22]
[start 440.88] weapon blocker is especially a lifesaver [Duration: 4.439]
[start 443.52] in cases where you don't have the [Duration: 3.6]
[start 445.319] resources or knowledge to build a [Duration: 3.841]
[start 447.12] scraper to access websites that use [Duration: 4.079]
[start 449.16] sophisticated anti-scraping techniques [Duration: 4.2]
[start 451.199] as a matter of fact it may actually save [Duration: 4.081]
[start 453.36] you Financial Resources in the long run [Duration: 3.839]
[start 455.28] as you don't have to maintain a complex [Duration: 3.9]
[start 457.199] infrastructure you can just build a [Duration: 3.481]
[start 459.18] basic scraper in Python with the [Duration: 3.78]
[start 460.68] requests and beautiful soup and have the [Duration: 4.44]
[start 462.96] web Unblocker to the heavy lifting for [Duration: 5.28]
[start 465.12] you okay so now that we know that let's [Duration: 5.699]
[start 468.24] look at how to retrieve data from a site [Duration: 5.459]
[start 470.819] that uses a sophisticated antibot system [Duration: 6]
[start 473.699] okay so let's get to it first off I'm [Duration: 4.921]
[start 476.819] going to show you how to build a normal [Duration: 4.44]
[start 478.62] web scraper that will scrape pretty much [Duration: 4.62]
[start 481.259] anything apart from really difficult [Duration: 4.261]
[start 483.24] sites like warmer Amazon and Google [Duration: 4.62]
[start 485.52] because you will get blocked by their [Duration: 4.739]
[start 487.86] antibot systems so I'm going to show you [Duration: 4.8]
[start 490.259] that and show you how we are getting [Duration: 4.5]
[start 492.66] blocked and then show you how to get [Duration: 4.979]
[start 494.759] around it using the web Unblocker so [Duration: 4.62]
[start 497.639] let's do it let's head over to the [Duration: 3.78]
[start 499.379] oxylab dashboard and register account [Duration: 4.141]
[start 501.419] you can find the dashboard Link in the [Duration: 4.081]
[start 503.52] description below so just go ahead and [Duration: 4.2]
[start 505.5] click on that so we're at the same place [Duration: 5.22]
[start 507.72] on the overview page under the proxies [Duration: 5.34]
[start 510.72] tab select web on blocker and then click [Duration: 4.679]
[start 513.06] get started this will open the pricing [Duration: 4.02]
[start 515.399] page where you can click on the start [Duration: 3.901]
[start 517.08] free trial button read the terms and [Duration: 4.379]
[start 519.3] conditions accept them and continue [Duration: 3.72]
[start 521.459] this will bring you back to the overview [Duration: 3.601]
[start 523.02] page where you can select my products [Duration: 4.439]
[start 525.06] now create the username and password [Duration: 4.32]
[start 527.459] credentials that you will use to make [Duration: 4.741]
[start 529.38] the requests via web Unblocker and [Duration: 4.62]
[start 532.2] that's it now let's go back to the [Duration: 3.12]
[start 534] dashboard [Duration: 4.08]
[start 535.32] here is the dashboard that you are going [Duration: 4.8]
[start 538.08] to see so I'm just going to walk you [Duration: 3.72]
[start 540.12] through it you'll see all the products [Duration: 3.719]
[start 541.8] available and then you've also got your [Duration: 3.479]
[start 543.839] account where you can see the settings [Duration: 3.961]
[start 545.279] as well as more information on the [Duration: 5.881]
[start 547.8] products so great let's get to it no [Duration: 6.06]
[start 551.16] time to waste let's get up off code [Duration: 6.48]
[start 553.86] editors and our terminal so I'm going to [Duration: 5.22]
[start 557.64] create a project that's going to hold [Duration: 4.08]
[start 559.08] the python file so let's do it [Duration: 4.62]
[start 561.72] so first off I'm just going to create a [Duration: 4.5]
[start 563.7] new project I'm going to do it in my [Duration: 5.28]
[start 566.22] development directory so I'm just going [Duration: 5.88]
[start 568.98] to go into that and use the commander on [Duration: 6.12]
[start 572.1] Max to create a project which I'm going [Duration: 5.58]
[start 575.1] to call web on blocker now let's go into [Duration: 4.38]
[start 577.68] web Unblocker I'm just going to open up [Duration: 5.4]
[start 579.48] mvs code using the code dot command that [Duration: 5.82]
[start 583.08] I have pre-installed however you get [Duration: 4.379]
[start 585.3] your projects going please meet me at [Duration: 5.34]
[start 587.459] this point based on whatever code editor [Duration: 5.401]
[start 590.64] you are using or whatever operating [Duration: 3.36]
[start 592.86] system [Duration: 2.58]
[start 594] great [Duration: 4.14]
[start 595.44] so here we are now I'm just in the [Duration: 5.399]
[start 598.14] project and I'm just going to create a [Duration: 5.34]
[start 600.839] file just a simple script file so I'm [Duration: 4.56]
[start 603.48] going to call it script.py as we're [Duration: 4.38]
[start 605.399] going to be working with python so just [Duration: 4.261]
[start 607.86] make that a little bit bigger for you [Duration: 4.56]
[start 609.66] okay and now I'm going to import a [Duration: 4.679]
[start 612.42] package it's going to be called requests [Duration: 5.34]
[start 614.339] so just do the same and then the URL but [Duration: 5.221]
[start 617.76] we're going to specify the URL here so [Duration: 3.96]
[start 619.56] I'm going to come back to that as a [Duration: 5.219]
[start 621.72] string and next we are just going to [Duration: 4.86]
[start 624.779] Define some headers that we need to pass [Duration: 4.081]
[start 626.58] through into our web scraper [Duration: 3.84]
[start 628.86] so the first Hazard we're going to pass [Duration: 2.82]
[start 630.42] through well we're going to pass through [Duration: 3.84]
[start 631.68] the user agent and we're going to leave [Duration: 4.92]
[start 634.26] that blank for now because we're going [Duration: 4.5]
[start 636.6] to come back to this and the next one [Duration: 4.38]
[start 638.76] we're going to pass through the next [Duration: 4.62]
[start 640.98] attribute is accept language and again [Duration: 4.5]
[start 643.38] I'm going to come back to this [Duration: 3.899]
[start 645.48] so there we go that's all the headers [Duration: 4.02]
[start 647.279] that we need and now let's actually make [Duration: 4.921]
[start 649.5] the request so I'm going to save the [Duration: 5.399]
[start 652.2] response to the variable response and [Duration: 4.56]
[start 654.899] then I'm going to use requests so the [Duration: 3.901]
[start 656.76] import requests and it's going to be a [Duration: 3.42]
[start 658.8] get method and I'm just going to pass [Duration: 4.02]
[start 660.18] through the URL and the custom headers [Duration: 5.099]
[start 662.82] as the headers great just make sure to [Duration: 4.32]
[start 665.279] spell that correctly [Duration: 4.141]
[start 667.14] now I'm going to just print the response [Duration: 4.74]
[start 669.42] and get the text from it so oops let's [Duration: 4.2]
[start 671.88] just make sure that is spelled spelled [Duration: 2.76]
[start 673.62] correctly [Duration: 3.3]
[start 674.64] and wonderful [Duration: 5.1]
[start 676.92] so we are nearly there let's just pass [Duration: 4.74]
[start 679.74] through the accepted languages I'm going [Duration: 5.099]
[start 681.66] to put English the US version as well as [Duration: 7.14]
[start 684.839] English the UK version and then for the [Duration: 5.821]
[start 688.8] user agent I'm just going to paste this [Duration: 4.86]
[start 690.66] okay so here is what you need to pass [Duration: 4.919]
[start 693.66] through don't worry I'll be adding the [Duration: 3.9]
[start 695.579] code to this in the video description [Duration: 4.021]
[start 697.56] below in case you can't copy this out [Duration: 4.56]
[start 699.6] but for all of you copying from the [Duration: 5.1]
[start 702.12] video here it is you can type out please [Duration: 5.52]
[start 704.7] pause if you need and go back and forth [Duration: 5.699]
[start 707.64] in the video Until yours looks the same [Duration: 5.759]
[start 710.399] great so now let's go ahead and get the [Duration: 5.101]
[start 713.399] URL we want to scrape like I said we're [Duration: 4.5]
[start 715.5] going to be escaping Walmart so just [Duration: 5.339]
[start 717.899] head over to Walmart and I am going to [Duration: 5.821]
[start 720.839] choose to scrape games so in the search [Duration: 4.56]
[start 723.72] I'm going to write games and this [Duration: 3.96]
[start 725.399] constructs the URL that we need that [Duration: 4.861]
[start 727.68] we're going to essentially script okay [Duration: 4.44]
[start 730.26] of course you can scrape whatever you [Duration: 5.34]
[start 732.12] want I'm just choosing to skip games so [Duration: 6.48]
[start 735.6] now that we have that I'm just going to [Duration: 7.08]
[start 738.6] install that package using pip3 install [Duration: 6]
[start 742.68] hopefully you guys have set up your [Duration: 5.279]
[start 744.6] terminals to use Python so if you have [Duration: 5.4]
[start 747.959] this should work and if not please go [Duration: 4.5]
[start 750] ahead and set up your terminals to be [Duration: 6.42]
[start 752.459] able to use the PIP 3 command so there [Duration: 7.56]
[start 756.42] we go that has now imported the requests [Duration: 6.12]
[start 760.019] package and now if we run this script by [Duration: 4.26]
[start 762.54] pressing this little play button right [Duration: 6.66]
[start 764.279] here we should get all of the HTML from [Duration: 6.261]
[start 769.2] that site [Duration: 5.28]
[start 770.54] amazing okay so there we go so we have [Duration: 7.479]
[start 774.48] now built just a simple scraper that [Duration: 6.06]
[start 778.019] scrapes sites but will get blocked by [Duration: 5.341]
[start 780.54] certain bigger websites like Walmart if [Duration: 5.34]
[start 783.36] we make too many requests so if we go [Duration: 5.099]
[start 785.88] ahead and press the play button right [Duration: 6.06]
[start 788.459] here okay and do this a few times we [Duration: 6.481]
[start 791.94] should get blocked so how do we go about [Duration: 6.72]
[start 794.94] this well to go about this and the [Duration: 7.139]
[start 798.66] bypass anti-bot systems such as the ones [Duration: 6.78]
[start 802.079] Walmart Amazon and Google have we're [Duration: 5.401]
[start 805.44] going to use the web Unblocker and it's [Duration: 4.68]
[start 807.48] super simple we're just going to add a [Duration: 4.859]
[start 810.12] few more lines of code to what we have [Duration: 3.839]
[start 812.339] written so far [Duration: 4.8]
[start 813.959] okay so let's do it I'm just going to [Duration: 5.701]
[start 817.139] write an object I'm going to save it [Duration: 5.461]
[start 819.66] under the variable proxies and the first [Duration: 5.64]
[start 822.6] attribute is going to be for the HTTP [Duration: 6.239]
[start 825.3] address and it's just going to be HTTP s [Duration: 5.219]
[start 828.839] and we're going to get our username and [Duration: 4.68]
[start 830.519] password so back on the dashboard under [Duration: 6]
[start 833.519] my products just go on to web Unblocker [Duration: 5.101]
[start 836.519] and under users you should have a [Duration: 4.32]
[start 838.62] username and a password now you can [Duration: 4.74]
[start 840.839] change your password here if you have [Duration: 5.821]
[start 843.36] forgotten it but I have not so that is [Duration: 4.8]
[start 846.66] where you'd find your username and [Duration: 4.08]
[start 848.16] password let's just go back to here and [Duration: 5.22]
[start 850.74] paste the username followed by the colon [Duration: 5.76]
[start 853.38] and then the password that you have and [Duration: 4.759]
[start 856.5] then at [Duration: 4.26]
[start 858.139] unblock.oxylabs.io 60 [Duration: 4.181]
[start 860.76] 000. [Duration: 4.62]
[start 862.32] comma and then just copy the whole thing [Duration: 7.079]
[start 865.38] and do the same but for https [Duration: 7.44]
[start 869.399] okay so just add in the Esther [Duration: 6.18]
[start 872.82] and we are good to go [Duration: 5.699]
[start 875.579] great so that's what it looks like let's [Duration: 5.88]
[start 878.519] continue so now let's also pass through [Duration: 6.06]
[start 881.459] the proxies into the request so just [Duration: 4.62]
[start 884.579] pass it through [Duration: 3.721]
[start 886.079] above here so I'm just going to space [Duration: 5.82]
[start 888.3] this out so proxies and then verify [Duration: 8.039]
[start 891.899] equals false and we are golden so now [Duration: 6.361]
[start 896.339] let's run this so I'm just going to run [Duration: 3.601]
[start 898.26] that script again [Duration: 4.439]
[start 899.94] okay so just press that play button here [Duration: 7.92]
[start 902.699] and amazing we get all of the HTML and [Duration: 7.5]
[start 907.86] we are not getting blocked [Duration: 3.539]
[start 910.199] great [Duration: 3.121]
[start 911.399] now I'm just going to take this tutorial [Duration: 4.021]
[start 913.32] step further and show you how to [Duration: 5.34]
[start 915.42] actually get certain values out of this [Duration: 5.58]
[start 918.66] HTML I'm going to show you how to do it [Duration: 4.26]
[start 921] just with one title and then hopefully [Duration: 3.899]
[start 922.92] you can use the same approach in order [Duration: 4.74]
[start 924.899] to get all the information that you need [Duration: 5.701]
[start 927.66] so in order to do this we are going to [Duration: 6.66]
[start 930.6] use another package called bs4 so I'm [Duration: 6.239]
[start 934.32] just going to first offrite the code for [Duration: 4.019]
[start 936.839] this so we're going to write a variable [Duration: 3.781]
[start 938.339] called soup and then use the bs4 package [Duration: 4.74]
[start 940.62] and a method from it called Beautiful [Duration: 3.839]
[start 943.079] soup [Duration: 3.541]
[start 944.459] okay and then just pause through the [Duration: 4.38]
[start 946.62] response and the text so everything we [Duration: 4.62]
[start 948.839] just saw in the terminal [Duration: 4.081]
[start 951.24] next I'm just going to pass through the [Duration: 2.599]
[start 952.92] string [Duration: 4.979]
[start 953.839] lxml okay now let's go ahead and get [Duration: 5.921]
[start 957.899] what we want out of the text so I'm just [Duration: 3.541]
[start 959.76] going to grab a product title just one [Duration: 3.54]
[start 961.44] product title so let's go ahead and [Duration: 3.959]
[start 963.3] Define product title and I'm going to [Duration: 4.8]
[start 965.399] use sup find in order to find it from [Duration: 5.461]
[start 968.1] all the HTML so the title we're going to [Duration: 5.34]
[start 970.86] look for is the first one here so let's [Duration: 4.8]
[start 973.44] just inspect the element that holds this [Duration: 4.8]
[start 975.66] title and the element that holds this [Duration: 6.78]
[start 978.24] title is in fact a let's have a look [Duration: 7.44]
[start 982.44] it is a span element so we're going to [Duration: 6.54]
[start 985.68] look for a span that also has a specific [Duration: 7.2]
[start 988.98] attribute so in this case it's the ID of [Duration: 5.58]
[start 992.88] product title that I'm going to be [Duration: 4.8]
[start 994.56] looking for and all of the HTML so let's [Duration: 5.639]
[start 997.68] look for a span and let's look for a [Duration: 4.74]
[start 1000.199] Spam that has I think it was the ID [Duration: 4.5]
[start 1002.42] let's go back to this the idea product [Duration: 3.779]
[start 1004.699] title [Duration: 3.301]
[start 1006.199] so that's what we are looking for and [Duration: 4.801]
[start 1008] we're just going to essentially get that [Duration: 4.86]
[start 1011] element that we saved as product title [Duration: 4.079]
[start 1012.86] and get the text from inside it using [Duration: 5.58]
[start 1015.079] the get text method so that's what we [Duration: 5.041]
[start 1018.44] are going to do [Duration: 4.22]
[start 1020.12] okay let's just go ahead and install [Duration: 7.439]
[start 1022.66] PS4 the package that we are using so [Duration: 7.179]
[start 1027.559] just like that which means we now need [Duration: 4.5]
[start 1029.839] to import it into the file so I'm simply [Duration: 6.541]
[start 1032.059] going to import bs4 like so okay so [Duration: 6.181]
[start 1036.38] that's all I am doing [Duration: 3.98]
[start 1038.24] and we also need to install [Duration: 4.679]
[start 1040.36] lxml so let's go ahead and do that [Duration: 5.14]
[start 1042.919] making sure it's pip3 so just install [Duration: 5.101]
[start 1045.5] that too so that is the string that we [Duration: 3.6]
[start 1048.02] wrote [Duration: 2.52]
[start 1049.1] okay [Duration: 6.12]
[start 1050.54] and great so now let's essentially let's [Duration: 7.32]
[start 1055.22] look back at the code [Duration: 6.06]
[start 1057.86] okay uh this should actually be this is [Duration: 6.059]
[start 1061.28] a custom attribute not an ID as you can [Duration: 5.519]
[start 1063.919] see here it's custom so in order to get [Duration: 4.921]
[start 1066.799] a custom attribute we simply have to [Duration: 5.161]
[start 1068.84] write ATT or S and then pass that [Duration: 5.339]
[start 1071.96] through like so and now we can Define [Duration: 4.92]
[start 1074.179] the custom attribute for that element [Duration: 5.701]
[start 1076.88] and it was Data automation ID and just [Duration: 4.86]
[start 1079.88] use get rid of that equal sign right [Duration: 5.22]
[start 1081.74] there and replace it okay wonderful now [Duration: 7.439]
[start 1085.1] let's run this code and ta-da we get the [Duration: 6.24]
[start 1089.179] specific title so that's how you would [Duration: 5.761]
[start 1091.34] get certain text out of the HTML please [Duration: 6.12]
[start 1094.94] use this use the package bs4 do your own [Duration: 4.56]
[start 1097.46] research on it you can find specific [Duration: 4.8]
[start 1099.5] elements you can find all elements and [Duration: 4.14]
[start 1102.26] so on just head over to the [Duration: 3.24]
[start 1103.64] documentation right here [Duration: 4.62]
[start 1105.5] so great we have now successfully [Duration: 6.48]
[start 1108.26] scraped Walmart using python I'm going [Duration: 6.06]
[start 1111.98] to show you how to scrape using node.js [Duration: 6.12]
[start 1114.32] so JavaScript next so let's do it [Duration: 6.42]
[start 1118.1] okay so this time I'm going to use a [Duration: 4.56]
[start 1120.74] different code editor this is webstorm [Duration: 5.1]
[start 1122.66] just to differentiate so first off I've [Duration: 4.98]
[start 1125.84] just gone ahead and created a new [Duration: 4.92]
[start 1127.64] directory again called Web Unblocker and [Duration: 4.68]
[start 1130.76] now let's get up our terminal making [Duration: 4.2]
[start 1132.32] sure that we are in web Unblocker and [Duration: 6]
[start 1134.96] I'm just gonna type npm init to [Duration: 6]
[start 1138.32] initialize a back end essentially to [Duration: 6.18]
[start 1140.96] initialize a node.js project so by [Duration: 5.7]
[start 1144.5] typing npm in it and just going enter [Duration: 5.34]
[start 1146.66] through all the default questions it's [Duration: 5.7]
[start 1149.84] going to spin up a package Json file for [Duration: 5.16]
[start 1152.36] me so there it is okay this is just the [Duration: 4.679]
[start 1155] default stuff we don't need to change [Duration: 4.559]
[start 1157.039] much we just need to add a type so that [Duration: 5.88]
[start 1159.559] we can use inputs in the file so type [Duration: 6]
[start 1162.919] and then we're going to put modules and [Duration: 5.341]
[start 1165.559] this will allow us to have Imports in [Duration: 5.161]
[start 1168.26] the index.js file we are about to make [Duration: 5.039]
[start 1170.72] okay so make sure that's there and now [Duration: 4.98]
[start 1173.299] let's go ahead and create that file it's [Duration: 4.321]
[start 1175.7] going to be a Javascript file which is [Duration: 3.66]
[start 1177.62] going to be called index so there we go [Duration: 4.74]
[start 1179.36] it's an index.js file now we can use the [Duration: 5.52]
[start 1182.36] import keyword thanks to the types [Duration: 5.04]
[start 1184.88] module and I'm going to import fetch [Duration: 5.7]
[start 1187.4] from the package node fetch [Duration: 6.48]
[start 1190.58] okay so that is something you would also [Duration: 5.64]
[start 1193.88] need to do again I can use import thanks [Duration: 4.98]
[start 1196.22] to the type module and now we're also [Duration: 5.94]
[start 1198.86] going to import https proxy agent from [Duration: 5.819]
[start 1202.16] HTTP proxy agent so those are two [Duration: 4.74]
[start 1204.679] packages that you're going to need to [Duration: 4.561]
[start 1206.9] install and if you go to package.json [Duration: 3.96]
[start 1209.24] after they've installed you will see [Duration: 3.9]
[start 1210.86] them there along with their versions so [Duration: 3.9]
[start 1213.14] if anything is not working and you're [Duration: 3.36]
[start 1214.76] watching this in the future it could be [Duration: 3.72]
[start 1216.5] down to the package you are using just [Duration: 4.38]
[start 1218.48] make sure to have yours the same as me [Duration: 4.26]
[start 1220.88] great [Duration: 4.679]
[start 1222.74] so now let's continue [Duration: 5.1]
[start 1225.559] I'm going to define the username and [Duration: 4.021]
[start 1227.84] password that we're going to need to [Duration: 3.959]
[start 1229.58] pass through into the proxies just as we [Duration: 4.86]
[start 1231.799] did before okay so I'm going to leave [Duration: 5.041]
[start 1234.44] those empty and next let's define the [Duration: 5.58]
[start 1236.84] agent so I'm going to use the import so [Duration: 4.98]
[start 1240.02] make sure that is spelled correctly it's [Duration: 4.92]
[start 1241.82] https proxy agent which we're importing [Duration: 6.96]
[start 1244.94] from the package https proxy agent and [Duration: 6]
[start 1248.78] now we're just going to pause through a [Duration: 4.32]
[start 1250.94] few things into this Constructor [Duration: 3.54]
[start 1253.1] so the things that we're going to pass [Duration: 4.439]
[start 1254.48] through into this Constructor is a URL [Duration: 6]
[start 1257.539] that I need to construct HTTP and we're [Duration: 6.361]
[start 1260.48] going to use the username constant so [Duration: 5.4]
[start 1263.9] making sure that obviously this is [Duration: 4.68]
[start 1265.88] embacted so we can pick up the code and [Duration: 4.74]
[start 1268.58] we Define this as code by using the [Duration: 4.44]
[start 1270.62] dollar sign and Kylie braces then we get [Duration: 5.22]
[start 1273.02] out of that code we use the colon and [Duration: 6.14]
[start 1275.84] then password and then put at unblock [Duration: 5.78]
[start 1279.16] dot [Duration: 5.56]
[start 1281.62] oxylabs.io 60 [Duration: 5.02]
[start 1284.72] 000. okay so just like we did before we [Duration: 4.8]
[start 1286.64] just constructed the same URL [Duration: 4.14]
[start 1289.52] great [Duration: 3.779]
[start 1290.78] now we just need to put in some code so [Duration: 6.66]
[start 1293.299] process EnV no TLS reject and authorize [Duration: 6.841]
[start 1297.44] and just put through a series this [Duration: 4.5]
[start 1300.14] essentially makes TLS connections and [Duration: 4.32]
[start 1301.94] https requests insecure by disabling [Duration: 5.58]
[start 1304.46] certificate verification [Duration: 5.64]
[start 1307.52] and now let's get our response so we're [Duration: 4.5]
[start 1310.1] going to define the response as the [Duration: 3.6]
[start 1312.02] const response and we're going to await [Duration: 4.74]
[start 1313.7] fetch as it's an asynchronous method and [Duration: 4.8]
[start 1316.76] we're going to just pass through the URL [Duration: 3.12]
[start 1318.5] that we want to essentially scrape [Duration: 3.48]
[start 1319.88] followed by an object which we're going [Duration: 4.5]
[start 1321.98] to define the method as get even though [Duration: 3.96]
[start 1324.38] we probably don't need to do this the [Duration: 3.9]
[start 1325.94] fetch method already has a default [Duration: 5.219]
[start 1328.28] action of get and then we're also going [Duration: 4.56]
[start 1331.159] to pass through the agent that we just [Duration: 3.661]
[start 1332.84] made so that we go [Duration: 5.459]
[start 1334.82] wonderful so now let's console log out [Duration: 6.42]
[start 1338.299] the response I'm just going to await it [Duration: 5.88]
[start 1341.24] okay so a weight response [Duration: 6.36]
[start 1344.179] and get its text from it so that's what [Duration: 5.461]
[start 1347.6] we're going to do now let's get the URL [Duration: 4.02]
[start 1349.64] that we want to scrape so we're going to [Duration: 4.32]
[start 1351.62] scrape Google okay and again we are [Duration: 4.799]
[start 1353.96] going to scrape Google for games so that [Duration: 5.4]
[start 1356.419] is the URL that we're going to do so [Duration: 5.041]
[start 1359.36] this is just the same as me going to [Duration: 4.98]
[start 1361.46] Google and searching for games as you [Duration: 4.56]
[start 1364.34] would in your browser like this okay [Duration: 3.8]
[start 1366.02] that's what we're gonna scrape [Duration: 7.139]
[start 1368.14] so let's do it okay before we move on [Duration: 5.98]
[start 1373.159] though I'm just going to pass through [Duration: 2.88]
[start 1374.12] the username and password it's the same [Duration: 4.679]
[start 1376.039] that we had before so here is mine and [Duration: 5.041]
[start 1378.799] here is my password please fill in yours [Duration: 4.981]
[start 1381.08] here as mine will not work for you now [Duration: 4.2]
[start 1383.78] let's run this script so I'm going to [Duration: 3.24]
[start 1385.28] run this script by getting up the [Duration: 5.66]
[start 1387.02] terminal and typing node index.js and [Duration: 8.82]
[start 1390.94] ta-da we get the HTML for that page here [Duration: 7.18]
[start 1395.84] we have it it's just the same as we did [Duration: 5.16]
[start 1398.12] with python and if you want to pick [Duration: 5.1]
[start 1401] stuff out of here you would do it with [Duration: 4.98]
[start 1403.22] the same approach as we did for python [Duration: 4.98]
[start 1405.98] okay so you look for certain elements in [Duration: 5.22]
[start 1408.2] here and get the text from it [Duration: 5.459]
[start 1411.2] and just to prove that we have scraped [Duration: 5.4]
[start 1413.659] this HTML we're going to look for this [Duration: 5.281]
[start 1416.6] piece of text so let's copy it and let's [Duration: 4.079]
[start 1418.94] find it in here so I'm just going to [Duration: 5.52]
[start 1420.679] search for that and there we go [Duration: 5.461]
[start 1424.46] great [Duration: 4.199]
[start 1426.14] so great hopefully now you know how to [Duration: 6.06]
[start 1428.659] scrape Pages using web Unblocker and [Duration: 6.841]
[start 1432.2] bypassing antibot systems in a super [Duration: 5.52]
[start 1435.5] simple and easy way [Duration: 4.32]
[start 1437.72] okay so I hope you've learned something [Duration: 4.8]
[start 1439.82] useful today as a recap here is what we [Duration: 5.099]
[start 1442.52] covered in this video we looked at what [Duration: 5.159]
[start 1444.919] exactly a web Unblocker is we compared [Duration: 5.341]
[start 1447.679] proxies to custom web scrapers to the [Duration: 4.62]
[start 1450.26] web Unblocker and then we actually [Duration: 4.32]
[start 1452.299] signed up and used the actual web [Duration: 4.561]
[start 1454.58] Unblocker to scrape Walmart and Google [Duration: 4.8]
[start 1456.86] using the oxylabs web Unblocker [Duration: 4.74]
[start 1459.38] specifically if you would like to read [Duration: 4.44]
[start 1461.6] up more about the web Unblocker we were [Duration: 4.38]
[start 1463.82] using today in this video please do [Duration: 4.739]
[start 1465.98] visit the developer documentation via [Duration: 5.3]
[start 1468.559] the link below [Duration: 2.721]

 string value is this --> hey everyone and welcome to this video in which I'm going to explain to you what a web Unblocker is and when you should use one in these simplest terms a web Unblocker lets you bypass antibot systems ones that stop you from scraping sites to be precise it makes sure that not only your real IP address is hidden but also that your web requests don't differ in any way from real internet user requests it has smart features which I will get to later that allow you to successfully bypass even the most sophisticated antibot systems so essentially a web Unblocker does much more than a proxy server alone will ever be capable of if you run this basic Walmart scraping script a few times Walmart will block you like this now when you root this request through a web Unblocker it will decide what type of proxy to use and we'll use additional anti-detection techniques so that Walmart would think that it is just a regular Shopper browsing the website so how does a web Unblocker achieve this stay tuned as I will cover what exactly a weapon blocker is why use a web on blocker getting started scraping warmer and then finally ending with scraping Google we're going to do this with python and then with node.js so hopefully as many of you can follow along as possible so let's get to it let's start off with looking at what exactly a web Unblocker is a weapon blocker is an AI powered proxy solution capable of bypassing complex anti-scraping measures by appearing like an organic user on a website now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video we are going to bypass anti-bot systems with the help of Dynamic fingerprinting technology and other Advanced features in order to look like a real user the AI technology does a few things first it uses machine learning driven proxy management this feature evaluates which proxy types work the best on a specific Target and then it selects and rotates proxies that are likely to yield the highest success rate with the lowest response time possible next it chooses the most suitable headers cookies and other browser parameters based on what you are trying to scrape this feature is called Dynamic browser fingerprinting then it's time for machine learning powered response recognition simply said it determines the quality of the scraping results and passes this information to the next process in the web unblocking pipeline scraping outcome is unacceptable then the webon blocker automatically retries requests while simultaneously changing previously mentioned parameters until it successfully gets through the antibot system finally if a website uses JavaScript rendering to load content dynamically the user can instruct the web Unblocker to run requests through a headless browser on top of all this it can access content worldwide in 195 countries to be precise this is possible as the oxyloves web Unblocker uses an ethically gathered proxy pool of more than 102 million IP addresses so you can collect localized public data with these so imagine your proxies are getting blocked and you need to scrape Google search results from the United Kingdom while sitting at your desk in America easy that's what the web Unblocker can do so we now know what a web Unblocker is let's compare it to other options the web Unblocker we will be using is not just a standard proxy server and it is not a complete web scripting framework so why would you want to use it to help you understand I've created this table to compare proxies a custom built scraper and the web Unblocker will be using today first of all proxy servers use proxy infrastructure and the web Unblocker uses an advanced proxy infrastructure meaning they don't have web scraping and passing capabilities that is why users of both Solutions have to have their own infrastructure ready this is in a way similar to a custom web scraper where you have to create your own scraping infrastructure one major difference is that the proxy servers cannot render JavaScript content and cannot overcome fingerprinting methods like HTTP heading monitoring browser fingerprinting or TLS fingerprinting when it comes to building a custom web scraper you have to use libraries that enable the rendering of dynamic web pages and you must build anti-bot evasion solutions by yourself which requires immense technical knowledge and effort now the weapon blocker takes care of antibody vision for you out of the box and it can also run requests through a headless browser in a single line of code another important aspect is that the proxies have the ability to overcome IP bands and captures yet you have to implement further antibod evasion techniques in your infrastructure to be fully undetectable when building a web scraper or the same requirements apply and you also have to purchase the type of proxies that suit your needs the web Unblocker on the other hand has all these features integrated and additionally retries requests automatically with different proxies and fingerprint combinations what's good about modern proxies is that they typically come with automatic IP rotation depending on the provider and proxy type however you must understand the different variations of proxies and how they impact scraping tasks so when using proxies is your responsibility to use them efficiently this is similar to when you are creating a web scraper as you should understand proxy intricacies but if your chosen proxy types don't have automatic IP rotation and health monitoring you must rotate IPS and monitor their health yourself in comparison the web Unblocker does all this automatically under the hood you can draw some similarities between proxy servers and the web Unblocker when it comes to geo-targeting capabilities with proxies it all relies on the provider you choose and the proxy type you purchase with the web Unblocker however you get access to more than 102 million IP addresses located in all 195 countries with the ability to get localized content on a country's City or even coordinate level in comparison a custom built web script it must use proxy servers to access different geolocations and finally all these different aspects directly affect the success rate of each solution a proxy server enables better success rates but lacks the power to bypass difficult anti-scraping systems a web scraper success solely depends on you and whether you integrate proxies and use anti-fingerprinting methods now the web Unblocker has all the power to overcome detection and provides much higher success rates when compared to proxies so why use the weapon blocker it's simple to significantly ease the unblocking process and increase the success of your scraping operations the weapon blocker is especially a lifesaver in cases where you don't have the resources or knowledge to build a scraper to access websites that use sophisticated anti-scraping techniques as a matter of fact it may actually save you Financial Resources in the long run as you don't have to maintain a complex infrastructure you can just build a basic scraper in Python with the requests and beautiful soup and have the web Unblocker to the heavy lifting for you okay so now that we know that let's look at how to retrieve data from a site that uses a sophisticated antibot system okay so let's get to it first off I'm going to show you how to build a normal web scraper that will scrape pretty much anything apart from really difficult sites like warmer Amazon and Google because you will get blocked by their antibot systems so I'm going to show you that and show you how we are getting blocked and then show you how to get around it using the web Unblocker so let's do it let's head over to the oxylab dashboard and register account you can find the dashboard Link in the description below so just go ahead and click on that so we're at the same place on the overview page under the proxies tab select web on blocker and then click get started this will open the pricing page where you can click on the start free trial button read the terms and conditions accept them and continue this will bring you back to the overview page where you can select my products now create the username and password credentials that you will use to make the requests via web Unblocker and that's it now let's go back to the dashboard here is the dashboard that you are going to see so I'm just going to walk you through it you'll see all the products available and then you've also got your account where you can see the settings as well as more information on the products so great let's get to it no time to waste let's get up off code editors and our terminal so I'm going to create a project that's going to hold the python file so let's do it so first off I'm just going to create a new project I'm going to do it in my development directory so I'm just going to go into that and use the commander on Max to create a project which I'm going to call web on blocker now let's go into web Unblocker I'm just going to open up mvs code using the code dot command that I have pre-installed however you get your projects going please meet me at this point based on whatever code editor you are using or whatever operating system great so here we are now I'm just in the project and I'm just going to create a file just a simple script file so I'm going to call it script.py as we're going to be working with python so just make that a little bit bigger for you okay and now I'm going to import a package it's going to be called requests so just do the same and then the URL but we're going to specify the URL here so I'm going to come back to that as a string and next we are just going to Define some headers that we need to pass through into our web scraper so the first Hazard we're going to pass through well we're going to pass through the user agent and we're going to leave that blank for now because we're going to come back to this and the next one we're going to pass through the next attribute is accept language and again I'm going to come back to this so there we go that's all the headers that we need and now let's actually make the request so I'm going to save the response to the variable response and then I'm going to use requests so the import requests and it's going to be a get method and I'm just going to pass through the URL and the custom headers as the headers great just make sure to spell that correctly now I'm going to just print the response and get the text from it so oops let's just make sure that is spelled spelled correctly and wonderful so we are nearly there let's just pass through the accepted languages I'm going to put English the US version as well as English the UK version and then for the user agent I'm just going to paste this okay so here is what you need to pass through don't worry I'll be adding the code to this in the video description below in case you can't copy this out but for all of you copying from the video here it is you can type out please pause if you need and go back and forth in the video Until yours looks the same great so now let's go ahead and get the URL we want to scrape like I said we're going to be escaping Walmart so just head over to Walmart and I am going to choose to scrape games so in the search I'm going to write games and this constructs the URL that we need that we're going to essentially script okay of course you can scrape whatever you want I'm just choosing to skip games so now that we have that I'm just going to install that package using pip3 install hopefully you guys have set up your terminals to use Python so if you have this should work and if not please go ahead and set up your terminals to be able to use the PIP 3 command so there we go that has now imported the requests package and now if we run this script by pressing this little play button right here we should get all of the HTML from that site amazing okay so there we go so we have now built just a simple scraper that scrapes sites but will get blocked by certain bigger websites like Walmart if we make too many requests so if we go ahead and press the play button right here okay and do this a few times we should get blocked so how do we go about this well to go about this and the bypass anti-bot systems such as the ones Walmart Amazon and Google have we're going to use the web Unblocker and it's super simple we're just going to add a few more lines of code to what we have written so far okay so let's do it I'm just going to write an object I'm going to save it under the variable proxies and the first attribute is going to be for the HTTP address and it's just going to be HTTP s and we're going to get our username and password so back on the dashboard under my products just go on to web Unblocker and under users you should have a username and a password now you can change your password here if you have forgotten it but I have not so that is where you'd find your username and password let's just go back to here and paste the username followed by the colon and then the password that you have and then at unblock.oxylabs.io 60 000. comma and then just copy the whole thing and do the same but for https okay so just add in the Esther and we are good to go great so that's what it looks like let's continue so now let's also pass through the proxies into the request so just pass it through above here so I'm just going to space this out so proxies and then verify equals false and we are golden so now let's run this so I'm just going to run that script again okay so just press that play button here and amazing we get all of the HTML and we are not getting blocked great now I'm just going to take this tutorial step further and show you how to actually get certain values out of this HTML I'm going to show you how to do it just with one title and then hopefully you can use the same approach in order to get all the information that you need so in order to do this we are going to use another package called bs4 so I'm just going to first offrite the code for this so we're going to write a variable called soup and then use the bs4 package and a method from it called Beautiful soup okay and then just pause through the response and the text so everything we just saw in the terminal next I'm just going to pass through the string lxml okay now let's go ahead and get what we want out of the text so I'm just going to grab a product title just one product title so let's go ahead and Define product title and I'm going to use sup find in order to find it from all the HTML so the title we're going to look for is the first one here so let's just inspect the element that holds this title and the element that holds this title is in fact a let's have a look it is a span element so we're going to look for a span that also has a specific attribute so in this case it's the ID of product title that I'm going to be looking for and all of the HTML so let's look for a span and let's look for a Spam that has I think it was the ID let's go back to this the idea product title so that's what we are looking for and we're just going to essentially get that element that we saved as product title and get the text from inside it using the get text method so that's what we are going to do okay let's just go ahead and install PS4 the package that we are using so just like that which means we now need to import it into the file so I'm simply going to import bs4 like so okay so that's all I am doing and we also need to install lxml so let's go ahead and do that making sure it's pip3 so just install that too so that is the string that we wrote okay and great so now let's essentially let's look back at the code okay uh this should actually be this is a custom attribute not an ID as you can see here it's custom so in order to get a custom attribute we simply have to write ATT or S and then pass that through like so and now we can Define the custom attribute for that element and it was Data automation ID and just use get rid of that equal sign right there and replace it okay wonderful now let's run this code and ta-da we get the specific title so that's how you would get certain text out of the HTML please use this use the package bs4 do your own research on it you can find specific elements you can find all elements and so on just head over to the documentation right here so great we have now successfully scraped Walmart using python I'm going to show you how to scrape using node.js so JavaScript next so let's do it okay so this time I'm going to use a different code editor this is webstorm just to differentiate so first off I've just gone ahead and created a new directory again called Web Unblocker and now let's get up our terminal making sure that we are in web Unblocker and I'm just gonna type npm init to initialize a back end essentially to initialize a node.js project so by typing npm in it and just going enter through all the default questions it's going to spin up a package Json file for me so there it is okay this is just the default stuff we don't need to change much we just need to add a type so that we can use inputs in the file so type and then we're going to put modules and this will allow us to have Imports in the index.js file we are about to make okay so make sure that's there and now let's go ahead and create that file it's going to be a Javascript file which is going to be called index so there we go it's an index.js file now we can use the import keyword thanks to the types module and I'm going to import fetch from the package node fetch okay so that is something you would also need to do again I can use import thanks to the type module and now we're also going to import https proxy agent from HTTP proxy agent so those are two packages that you're going to need to install and if you go to package.json after they've installed you will see them there along with their versions so if anything is not working and you're watching this in the future it could be down to the package you are using just make sure to have yours the same as me great so now let's continue I'm going to define the username and password that we're going to need to pass through into the proxies just as we did before okay so I'm going to leave those empty and next let's define the agent so I'm going to use the import so make sure that is spelled correctly it's https proxy agent which we're importing from the package https proxy agent and now we're just going to pause through a few things into this Constructor so the things that we're going to pass through into this Constructor is a URL that I need to construct HTTP and we're going to use the username constant so making sure that obviously this is embacted so we can pick up the code and we Define this as code by using the dollar sign and Kylie braces then we get out of that code we use the colon and then password and then put at unblock dot oxylabs.io 60 000. okay so just like we did before we just constructed the same URL great now we just need to put in some code so process EnV no TLS reject and authorize and just put through a series this essentially makes TLS connections and https requests insecure by disabling certificate verification and now let's get our response so we're going to define the response as the const response and we're going to await fetch as it's an asynchronous method and we're going to just pass through the URL that we want to essentially scrape followed by an object which we're going to define the method as get even though we probably don't need to do this the fetch method already has a default action of get and then we're also going to pass through the agent that we just made so that we go wonderful so now let's console log out the response I'm just going to await it okay so a weight response and get its text from it so that's what we're going to do now let's get the URL that we want to scrape so we're going to scrape Google okay and again we are going to scrape Google for games so that is the URL that we're going to do so this is just the same as me going to Google and searching for games as you would in your browser like this okay that's what we're gonna scrape so let's do it okay before we move on though I'm just going to pass through the username and password it's the same that we had before so here is mine and here is my password please fill in yours here as mine will not work for you now let's run this script so I'm going to run this script by getting up the terminal and typing node index.js and ta-da we get the HTML for that page here we have it it's just the same as we did with python and if you want to pick stuff out of here you would do it with the same approach as we did for python okay so you look for certain elements in here and get the text from it and just to prove that we have scraped this HTML we're going to look for this piece of text so let's copy it and let's find it in here so I'm just going to search for that and there we go great so great hopefully now you know how to scrape Pages using web Unblocker and bypassing antibot systems in a super simple and easy way okay so I hope you've learned something useful today as a recap here is what we covered in this video we looked at what exactly a web Unblocker is we compared proxies to custom web scrapers to the web Unblocker and then we actually signed up and used the actual web Unblocker to scrape Walmart and Google using the oxylabs web Unblocker specifically if you would like to read up more about the web Unblocker we were using today in this video please do visit the developer documentation via the link below <--string value was this the nummber of key in the env is -->  2
random number generated is -> 0
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {"does_video_have_sponsorship":true, "sponsorship_subtitle":"now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video"}
formatted groq json is -->
 {"does_video_have_sponsorship":true, "sponsorship_subtitle":"now there are many ways to appear like an organic user and unblock sites but for the purpose of this tutorial I'm going to be using oxylab's web Unblocker so keep that in mind when I'm referring to the web Unblocker in this explainer as the features are specific to it we are going to use oxylabs as I am currently an official ambassador of the brand so by clicking on the link below in the description you are really helping out this channel as they can track the traffic from this video"} 

||6
555
got overboard, the text in prev one is(I think correct)--> anti-scraping measures by appearing like
this text is --> an organic user on a website now there
== now
the correct text is --> an organic user on a website now there
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
assesting -->firstWordPresentInNextIndex && secondWordPresentInNextIndex false
== now
correct ending text-- the link below
sponsershipSubtitlesStartIndex, sponsershipSubtitlesEndIndex, sponsershipSubtitlesEndIndex-- 1496 1984 605
 in the get_the_subtitles func
time taken in userKey decoding is -> 62  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 71773.166753 sec
in the english track
formatting the transctipt.subtitles.text to be utf-8
[start 0.659] If you find yourself scratching your head,
wondering about the ideal proxy or scraper [Duration: 4.841]
[start 5.5] provider for your projects, then you have
come to the right place. [Duration: 3.98]
[start 9.48] This quick video will put Oxylabs products
on your radar, showcasing the benefits you [Duration: 4.82]
[start 14.3] can gain, along with some examples of our
clients' successes. [Duration: 6.96]
[start 21.26] When you join Oxylabs, you're set to benefit
from these major pros: [Duration: 4.74]
[start 26] Business-grade proxy servers and web scrapers;
Market-leading quick response times; [Duration: 5.16]
[start 31.16] Ethically sourced proxies and strong KYC procedures;
Constantly maintained products that are frequently [Duration: 6.35]
[start 37.51] updated with new features;
and 24/7 professional support together with [Duration: 5.24]
[start 42.75] dedicated Account Managers. [Duration: 3.02]
[start 45.77] Due to the vastly different needs for web
intelligence spanning various industries and [Duration: 5.92]
[start 51.69] niches, we also offer different types of proxy
solutions for common use cases. [Duration: 6.029]
[start 57.719] When it comes to the most basic online projects,
Shared Datacenter Proxies take the lead here [Duration: 5.461]
[start 63.18] with their premium quality and extensive scalability
for a pocket-friendly price. [Duration: 5.84]
[start 69.02] If youre planning large-scale projects,
there are several options to choose from, [Duration: 4.38]
[start 73.4] each having their own advantages:
For fast and efficient tasks with more control [Duration: 4.88]
[start 78.28] over IP performance, Dedicated Datacenter
Proxies are the top choice for many businesses. [Duration: 6.019]
[start 84.299] For high-speed connections with the anonymity
of residential IP addresses, Rotating ISP [Duration: 6.051]
[start 90.35] Proxies prove to be the most successful. [Duration: 2.28]
[start 92.63] If you need likewise fast speeds and high
anonymity but much greater control, Static [Duration: 5.24]
[start 97.87] Residential Proxies will do the job with ease. [Duration: 3.12]
[start 100.99] Now, for highly localized data and complete
stealthiness online with zero blocks, two [Duration: 5.96]
[start 106.95] proxy choices come to mind:
For resembling web connections from residential [Duration: 4.279]
[start 111.229] areas in 195 countries without blocks, Residential
Proxies will serve you well. [Duration: 6.271]
[start 117.5] For localized data through mobile network
connections around the world with no blocks, [Duration: 4.71]
[start 122.21] Mobile Proxies will handle the task effectively. [Duration: 3.14]
[start 125.35] While proxy servers can do most of the heavy
lifting to overcome restrictions, there are [Duration: 5.06]
[start 130.41] countless anti-scraping measures websites
use where proxies arent enough. [Duration: 5.02]
[start 135.43] Thus, we offer an AI-powered proxy solution
called Web Unblocker that can bypass sophisticated [Duration: 6.029]
[start 141.459] anti-scraping systems. [Duration: 1.421]
[start 142.88] Its equipped with proxy servers, a headless
browser, a custom parser, and other neat features [Duration: 5.98]
[start 148.86] to help you scrape even the most difficult
publicly available websites. [Duration: 3.97]
[start 152.83] Lets see some examples where Oxylabs proxies
improved the operational efficiency of our [Duration: 5.65]
[start 158.48] customers:
The availability of different proxy types [Duration: 3.039]
[start 161.519] is fruitful for one of our clients in the
web scraping industry, allowing the company [Duration: 4.571]
[start 166.09] to choose whats best in specific situations. [Duration: 3.13]
[start 169.22] The reliability and high quality of Oxylabs
proxies ensures that their crawlers function [Duration: 6.129]
[start 175.349] seamlessly without any disruptions. [Duration: 3]
[start 178.349] According to the company, they managed to
save not only time and resources but also [Duration: 4.741]
[start 183.09] improve the accuracy of their data. [Duration: 2.7]
[start 185.79] Another client in the telecommunications industry,
with Web Unblocker under their hood, says [Duration: 5.279]
[start 191.069] they are able to bypass various access barriers,
such as anti-bot systems and geo-restrictions. [Duration: 6.381]
[start 197.45] The Headless Browser feature also allows them
to render JavaScript-heavy websites reliably. [Duration: 5.66]
[start 203.11] If you would like to see more testimonials,
take a look at customer stories on our website. [Duration: 5.93]
[start 209.04] You can find the link in the description below. [Duration: 2.809]
[start 211.849] While there are countless types of websites,
the most popular ones targeted in web scraping [Duration: 5.351]
[start 217.2] fall under a few categories. [Duration: 2.289]
[start 219.489] Thus, weve developed three distinct types
of web scrapers to extract public data on [Duration: 5.321]
[start 224.81] a large scale from the most popular website
categories. [Duration: 3.72]
[start 228.53] These scrapers easily bypass IP blocks and
CAPTCHAs with a pool of over 102 million proxy [Duration: 5.86]
[start 234.39] servers. [Duration: 1.26]
[start 235.65] Together with a maintenance-free infrastructure
and advanced features like JavaScript rendering, [Duration: 5.16]
[start 240.81] browser instructions, custom parser, and job
scheduler, scraping operations are more streamlined [Duration: 5.739]
[start 246.549] and cost-effective. [Duration: 1]
[start 247.549] So, lets see what kind of projects you
can do with Oxylabs Scraper APIs: [Duration: 5.791]
[start 253.34] For effortless and scalable extraction of
fresh SERP data, our SERP Scraper API delivers [Duration: 5.679]
[start 259.019] what it promises. [Duration: 1.551]
[start 260.57] It can provide highly localized public data
from 195 countries found on search engines [Duration: 6]
[start 266.57] like:
Google, Baidu, and Bing [Duration: 2.469]
[start 269.039] If you plan on scraping e-commerce websites,
doing so without a block-free solution that [Duration: 5.341]
[start 274.38] can supply localized and accurate public data
on a large scale may lead to operational inefficiencies. [Duration: 7.89]
[start 282.27] This is where Oxylabs E-Commerce Scraper API
comes in to save the day with stealthy scraping [Duration: 5.679]
[start 287.949] on a global scale and the ability to deliver
parsed results from e-commerce giants like: [Duration: 5.451]
[start 293.4] Amazon, Walmart, Google Shopping, and other
online marketplaces [Duration: 4.72]
[start 298.12] In case youre looking for a universal scraper
that can gather public data from any website [Duration: 4.76]
[start 302.88] without blocks and on a large scale, then
our Web Scraper API can suit you well. [Duration: 5.75]
[start 308.63] It delivers real-time data for any use case,
such as scraping: [Duration: 4.039]
[start 312.669] Real Estate websites like Zillow and Zoopla
Travel websites like Tripadvisor and Airbnb [Duration: 6.47]
[start 319.139] Job postings, automotive data, and more
We offer a 1-week free trial for all of our [Duration: 5.691]
[start 324.83] Scraper API products, so feel free to test
them out. [Duration: 3.619]
[start 328.449] You can find the link for registration in
the description below. [Duration: 3.631]
[start 332.08] Our clients have been kind enough to voice
their opinions about their experience with [Duration: 4.27]
[start 336.35] Oxylabs Scraper API products, so lets shine
some light on their successes: [Duration: 5.67]
[start 342.02] A couple of customers have noted how SERP
Scraper API allows them to scrape search engine [Duration: 5.239]
[start 347.259] results on a large scale with ease;
In the case of E-Commerce Scraper API, our [Duration: 6.051]
[start 353.31] client in the retail industry mentioned that
Oxylabs has been by far the fastest and the [Duration: 5.35]
[start 358.66] most reliable service in their inventory;
For another Oxylabs customer, Web Scraper [Duration: 5.25]
[start 363.91] API proved to be instrumental in scaling their
business and meeting the data needs of their [Duration: 5.74]
[start 369.65] clients. [Duration: 1]
[start 370.65] They were able to make thousands of requests
to multiple targets without blocks or network [Duration: 5.049]
[start 375.699] throttling, including sites that are difficult
to scrape. [Duration: 3.551]
[start 379.25] In the list of advantages, Oxylabs dashboard
may easily be at the forefront. [Duration: 4.849]
[start 384.099] Its the place where you can find details
about our products, see your usage statistics [Duration: 5.481]
[start 389.58] and invoices, and manage your acquired products. [Duration: 4.33]
[start 393.91] Another useful feature of the dashboard is
the Scraper APIs playground, where you can [Duration: 5.14]
[start 399.05] quickly test out the capabilities of our Scraper
APIs and see which one fits your needs the [Duration: 5.94]
[start 404.99] best. [Duration: 1.03]
[start 406.02] Another advantage of Oxylabs is our committed
support to each and every client. [Duration: 4.369]
[start 410.389] If you ever run into any issues while using
our products, you can rest assured that our [Duration: 4.59]
[start 414.979] 24/7 professional support team is here to
aid you through any difficulties. [Duration: 4.671]
[start 419.65] Depending on the purchased plan, we also dedicate
a personal Account Manager as a first contact [Duration: 5.229]
[start 424.879] for any inquiries. [Duration: 1.57]
[start 426.449] Now, if you want to stay ahead in your dynamic
industry and boost your expertise, Oxylabs [Duration: 6.381]
[start 432.83] resources offer plenty of valuable information. [Duration: 3.149]
[start 435.979] From blog posts, YouTube videos, and Scraping
Experts lessons to OxyCon conferences, youll [Duration: 5.09]
[start 441.069] find countless tutorials, hot topics, news,
and discussions. [Duration: 4.111]
[start 445.18] Moreover, you can join our Discord community
to connect with other scraping enthusiasts [Duration: 5.109]
[start 450.289] and code your way to success. [Duration: 2.451]
[start 452.74] Speaking of initiatives, Oxylabs goes beyond
industry standards. [Duration: 4.19]
[start 456.93] As a founding member of the Ethical Web Data
Collection Initiative and through our pro [Duration: 4.489]
[start 461.419] bono collaboration, Project 4, Oxylabs is
at the forefront of positive impact. [Duration: 6.24]
[start 467.659] We integrate economic, social, and environmental
objectives in our strategy, creating long-term [Duration: 7.021]
[start 474.68] value for the company, the planet, and the
people. [Duration: 3.549]
[start 478.229] Hence, when you join Oxylabs, you contribute
to our vision and make it possible. [Duration: 4.881]
[start 483.11] Thanks for tuning into this brief exploration
of Oxylabs. [Duration: 4.309]
[start 487.419] If you enjoyed the insights, show some love
by liking and subscribing for exclusive content. [Duration: 5.62]
[start 493.039] For a deeper dive into our products, feel
free to check out our other videos or reach [Duration: 4.25]
[start 497.289] us via live chat or email. [Duration: 2.78]
[start 500.069] Thanks for watching, stay curious, and until
next time! [Duration: 1.91]

 string value is this --> If you find yourself scratching your head,
wondering about the ideal proxy or scraper provider for your projects, then you have
come to the right place. This quick video will put Oxylabs products
on your radar, showcasing the benefits you can gain, along with some examples of our
clients' successes. When you join Oxylabs, you're set to benefit
from these major pros: Business-grade proxy servers and web scrapers;
Market-leading quick response times; Ethically sourced proxies and strong KYC procedures;
Constantly maintained products that are frequently updated with new features;
and 24/7 professional support together with dedicated Account Managers. Due to the vastly different needs for web
intelligence spanning various industries and niches, we also offer different types of proxy
solutions for common use cases. When it comes to the most basic online projects,
Shared Datacenter Proxies take the lead here with their premium quality and extensive scalability
for a pocket-friendly price. If youre planning large-scale projects,
there are several options to choose from, each having their own advantages:
For fast and efficient tasks with more control over IP performance, Dedicated Datacenter
Proxies are the top choice for many businesses. For high-speed connections with the anonymity
of residential IP addresses, Rotating ISP Proxies prove to be the most successful. If you need likewise fast speeds and high
anonymity but much greater control, Static Residential Proxies will do the job with ease. Now, for highly localized data and complete
stealthiness online with zero blocks, two proxy choices come to mind:
For resembling web connections from residential areas in 195 countries without blocks, Residential
Proxies will serve you well. For localized data through mobile network
connections around the world with no blocks, Mobile Proxies will handle the task effectively. While proxy servers can do most of the heavy
lifting to overcome restrictions, there are countless anti-scraping measures websites
use where proxies arent enough. Thus, we offer an AI-powered proxy solution
called Web Unblocker that can bypass sophisticated anti-scraping systems. Its equipped with proxy servers, a headless
browser, a custom parser, and other neat features to help you scrape even the most difficult
publicly available websites. Lets see some examples where Oxylabs proxies
improved the operational efficiency of our customers:
The availability of different proxy types is fruitful for one of our clients in the
web scraping industry, allowing the company to choose whats best in specific situations. The reliability and high quality of Oxylabs
proxies ensures that their crawlers function seamlessly without any disruptions. According to the company, they managed to
save not only time and resources but also improve the accuracy of their data. Another client in the telecommunications industry,
with Web Unblocker under their hood, says they are able to bypass various access barriers,
such as anti-bot systems and geo-restrictions. The Headless Browser feature also allows them
to render JavaScript-heavy websites reliably. If you would like to see more testimonials,
take a look at customer stories on our website. You can find the link in the description below. While there are countless types of websites,
the most popular ones targeted in web scraping fall under a few categories. Thus, weve developed three distinct types
of web scrapers to extract public data on a large scale from the most popular website
categories. These scrapers easily bypass IP blocks and
CAPTCHAs with a pool of over 102 million proxy servers. Together with a maintenance-free infrastructure
and advanced features like JavaScript rendering, browser instructions, custom parser, and job
scheduler, scraping operations are more streamlined and cost-effective. So, lets see what kind of projects you
can do with Oxylabs Scraper APIs: For effortless and scalable extraction of
fresh SERP data, our SERP Scraper API delivers what it promises. It can provide highly localized public data
from 195 countries found on search engines like:
Google, Baidu, and Bing If you plan on scraping e-commerce websites,
doing so without a block-free solution that can supply localized and accurate public data
on a large scale may lead to operational inefficiencies. This is where Oxylabs E-Commerce Scraper API
comes in to save the day with stealthy scraping on a global scale and the ability to deliver
parsed results from e-commerce giants like: Amazon, Walmart, Google Shopping, and other
online marketplaces In case youre looking for a universal scraper
that can gather public data from any website without blocks and on a large scale, then
our Web Scraper API can suit you well. It delivers real-time data for any use case,
such as scraping: Real Estate websites like Zillow and Zoopla
Travel websites like Tripadvisor and Airbnb Job postings, automotive data, and more
We offer a 1-week free trial for all of our Scraper API products, so feel free to test
them out. You can find the link for registration in
the description below. Our clients have been kind enough to voice
their opinions about their experience with Oxylabs Scraper API products, so lets shine
some light on their successes: A couple of customers have noted how SERP
Scraper API allows them to scrape search engine results on a large scale with ease;
In the case of E-Commerce Scraper API, our client in the retail industry mentioned that
Oxylabs has been by far the fastest and the most reliable service in their inventory;
For another Oxylabs customer, Web Scraper API proved to be instrumental in scaling their
business and meeting the data needs of their clients. They were able to make thousands of requests
to multiple targets without blocks or network throttling, including sites that are difficult
to scrape. In the list of advantages, Oxylabs dashboard
may easily be at the forefront. Its the place where you can find details
about our products, see your usage statistics and invoices, and manage your acquired products. Another useful feature of the dashboard is
the Scraper APIs playground, where you can quickly test out the capabilities of our Scraper
APIs and see which one fits your needs the best. Another advantage of Oxylabs is our committed
support to each and every client. If you ever run into any issues while using
our products, you can rest assured that our 24/7 professional support team is here to
aid you through any difficulties. Depending on the purchased plan, we also dedicate
a personal Account Manager as a first contact for any inquiries. Now, if you want to stay ahead in your dynamic
industry and boost your expertise, Oxylabs resources offer plenty of valuable information. From blog posts, YouTube videos, and Scraping
Experts lessons to OxyCon conferences, youll find countless tutorials, hot topics, news,
and discussions. Moreover, you can join our Discord community
to connect with other scraping enthusiasts and code your way to success. Speaking of initiatives, Oxylabs goes beyond
industry standards. As a founding member of the Ethical Web Data
Collection Initiative and through our pro bono collaboration, Project 4, Oxylabs is
at the forefront of positive impact. We integrate economic, social, and environmental
objectives in our strategy, creating long-term value for the company, the planet, and the
people. Hence, when you join Oxylabs, you contribute
to our vision and make it possible. Thanks for tuning into this brief exploration
of Oxylabs. If you enjoyed the insights, show some love
by liking and subscribing for exclusive content. For a deeper dive into our products, feel
free to check out our other videos or reach us via live chat or email. Thanks for watching, stay curious, and until
next time! <--string value was this the nummber of key in the env is -->  2
random number generated is -> 0
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {"does_video_have_sponsorship":true, "sponsorship_subtitle":"If you find yourself scratching your head, wondering about the ideal proxy or scraper provider for your projects, then you have come to the right place. This quick video will put Oxylabs products on your radar, showcasing the benefits you can gain, along with some examples of our clients' successes. When you join Oxylabs, you're set to benefit from these major pros: Business-grade proxy servers and web scrapers; Market-leading quick response times; Ethically sourced proxies and strong KYC procedures; Constantly maintained products that are frequently updated with new features; and 24/7 professional support together with dedicated Account Managers. Due to the vastly different needs for web intelligence spanning various industries and niches, we also offer different types of proxy solutions for common use cases. ... (rest of the text)" }
formatted groq json is -->
 {"does_video_have_sponsorship":true, "sponsorship_subtitle":"If you find yourself scratching your head, wondering about the ideal proxy or scraper provider for your projects, then you have come to the right place. This quick video will put Oxylabs products on your radar, showcasing the benefits you can gain, along with some examples of our clients' successes. When you join Oxylabs, you're set to benefit from these major pros: Business-grade proxy servers and web scrapers; Market-leading quick response times; Ethically sourced proxies and strong KYC procedures; Constantly maintained products that are frequently updated with new features; and 24/7 professional support together with dedicated Account Managers. Due to the vastly different needs for web intelligence spanning various industries and niches, we also offer different types of proxy solutions for common use cases. ... (rest of the text)" } 

||6
555
subtitle is not there
--== can't find the subtitles
 message in the--> Something is wrong on our side, error getting subtitles timming 
error in result_for_subtitles.err -->  can't find the subtitles
 in the get_the_subtitles func
time taken in userKey decoding is -> 61  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 70003.528239 sec
formatting the transctipt.subtitles.text to be utf-8
[start 0.08]          [Duration: 4.8]
[start 2.56]          [Duration: 4.64]
[start 4.88]       [Duration: 4.639]
[start 7.2]     18 [Duration: 4.399]
[start 9.519]           [Duration: 5.12]
[start 11.599]         [Duration: 4.801]
[start 14.639]           [Duration: 4.4]
[start 16.4]         [Duration: 4.639]
[start 19.039]          [Duration: 3.841]
[start 21.039]          [Duration: 3.281]
[start 22.88]         [Duration: 5.2]
[start 24.32]            [Duration: 7.039]
[start 28.08]          [Duration: 5.28]
[start 31.359]          [Duration: 3.681]
[start 33.36]         [Duration: 3.76]
[start 35.04]           [Duration: 3.76]
[start 37.12]         [Duration: 3.759]
[start 38.8]        [Duration: 3.68]
[start 40.879]        [Duration: 4]
[start 42.48]         [Duration: 5.04]
[start 44.879]           [Duration: 4.641]
[start 47.52]           [Duration: 4.16]
[start 49.52]          [Duration: 4]
[start 51.68]          [Duration: 3.76]
[start 53.52]        [Duration: 3.44]
[start 55.44]         [Duration: 3.04]
[start 56.96]         [Duration: 4.079]
[start 58.48]         [Duration: 5.6]
[start 61.039]    ,    ? [Duration: 5.44]
[start 64.08]       [Duration: 4.48]
[start 66.479]        [Duration: 4.32]
[start 68.56]        [Duration: 4]
[start 70.799]       ?  [Duration: 3.441]
[start 72.56]           [Duration: 4.08]
[start 74.24]            [Duration: 4.16]
[start 76.64]        [Duration: 3.6]
[start 78.4]         [Duration: 3.92]
[start 80.24]          [Duration: 4.239]
[start 82.32]         [Duration: 5.04]
[start 84.479]         [Duration: 4.96]
[start 87.36]          [Duration: 4.24]
[start 89.439]           [Duration: 4.401]
[start 91.6]          [Duration: 4.159]
[start 93.84]  ?       [Duration: 4.08]
[start 95.759]          [Duration: 5.201]
[start 97.92]        [Duration: 5.28]
[start 100.96]  ?       [Duration: 4.159]
[start 103.2]        [Duration: 4.4]
[start 105.119]    70 80    [Duration: 4.801]
[start 107.6]   Instagram       [Duration: 4.64]
[start 109.92]          [Duration: 4.559]
[start 112.24]            [Duration: 3.919]
[start 114.479]          [Duration: 3.92]
[start 116.159]         [Duration: 3.761]
[start 118.399]          [Duration: 3.601]
[start 119.92]        [Duration: 3.92]
[start 122]          [Duration: 5.64]
[start 123.84]     [Duration: 3.8]

 string value is this -->                             18                                                                                                                                                                                                                    ,    ?                           ?                                                                                            ?                        ?                 70 80      Instagram                                                                         <--string value was this the nummber of key in the env is -->  2
random number generated is -> 1
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
formatted groq json is -->
 {"does_video_have_sponsorship":false, "sponsorship_subtitle":""} 

||6
555
 in the get_the_subtitles func
time taken in userKey decoding is -> 107  Microseconds
resultForUserKeyChannel: {"account_id":"107305043822082831943","email":"monishsharma010@gmail.com","user_name":"Monish","is_user_paid":false,"user_tier":"free tier","version":0,"check_for_key_update_on":1746454995,"id_primary_key":78}
----++-- in the func to see if we should tell user to update the key
Time remaining until key update: 70001.838821 sec
formatting the transctipt.subtitles.text to be utf-8
[start 0.08]          [Duration: 4.8]
[start 2.56]          [Duration: 4.64]
[start 4.88]       [Duration: 4.639]
[start 7.2]     18 [Duration: 4.399]
[start 9.519]           [Duration: 5.12]
[start 11.599]         [Duration: 4.801]
[start 14.639]           [Duration: 4.4]
[start 16.4]         [Duration: 4.639]
[start 19.039]          [Duration: 3.841]
[start 21.039]          [Duration: 3.281]
[start 22.88]         [Duration: 5.2]
[start 24.32]            [Duration: 7.039]
[start 28.08]          [Duration: 5.28]
[start 31.359]          [Duration: 3.681]
[start 33.36]         [Duration: 3.76]
[start 35.04]           [Duration: 3.76]
[start 37.12]         [Duration: 3.759]
[start 38.8]        [Duration: 3.68]
[start 40.879]        [Duration: 4]
[start 42.48]         [Duration: 5.04]
[start 44.879]           [Duration: 4.641]
[start 47.52]           [Duration: 4.16]
[start 49.52]          [Duration: 4]
[start 51.68]          [Duration: 3.76]
[start 53.52]        [Duration: 3.44]
[start 55.44]         [Duration: 3.04]
[start 56.96]         [Duration: 4.079]
[start 58.48]         [Duration: 5.6]
[start 61.039]    ,    ? [Duration: 5.44]
[start 64.08]       [Duration: 4.48]
[start 66.479]        [Duration: 4.32]
[start 68.56]        [Duration: 4]
[start 70.799]       ?  [Duration: 3.441]
[start 72.56]           [Duration: 4.08]
[start 74.24]            [Duration: 4.16]
[start 76.64]        [Duration: 3.6]
[start 78.4]         [Duration: 3.92]
[start 80.24]          [Duration: 4.239]
[start 82.32]         [Duration: 5.04]
[start 84.479]         [Duration: 4.96]
[start 87.36]          [Duration: 4.24]
[start 89.439]           [Duration: 4.401]
[start 91.6]          [Duration: 4.159]
[start 93.84]  ?       [Duration: 4.08]
[start 95.759]          [Duration: 5.201]
[start 97.92]        [Duration: 5.28]
[start 100.96]  ?       [Duration: 4.159]
[start 103.2]        [Duration: 4.4]
[start 105.119]    70 80    [Duration: 4.801]
[start 107.6]   Instagram       [Duration: 4.64]
[start 109.92]          [Duration: 4.559]
[start 112.24]            [Duration: 3.919]
[start 114.479]          [Duration: 3.92]
[start 116.159]         [Duration: 3.761]
[start 118.399]          [Duration: 3.601]
[start 119.92]        [Duration: 3.92]
[start 122]          [Duration: 5.64]
[start 123.84]     [Duration: 3.8]

 string value is this -->                             18                                                                                                                                                                                                                    ,    ?                           ?                                                                                            ?                        ?                 70 80      Instagram                                                                         <--string value was this the nummber of key in the env is -->  2
random number generated is -> 1
and the random key picked by the logic is -->  gsk_  and the lenght is -> 56
I will give you subtitles of a youtube video,I need you to tell me wether it contians the sponsership and give me the text form the segment where the sponsership starts(starts and not mention, eg if the video mentions that it was sponsers by some xyz and then promotes then later in the video I want you to give me subtitle form the promotion part) till the end of sponsership, JSON response must adhere to the schema: '{"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
true http_response is not null
the json before removing is --> {"does_video_have_sponsorship":false, "sponsorship_subtitle":""}
formatted groq json is -->
 {"does_video_have_sponsorship":false, "sponsorship_subtitle":""} 

||6
555
